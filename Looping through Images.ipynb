{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.9-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (from pytesseract) (8.4.0)\n",
      "Collecting packaging>=21.3\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.4)\n",
      "Installing collected packages: packaging, pytesseract\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.0\n",
      "    Uninstalling packaging-21.0:\n",
      "      Successfully uninstalled packaging-21.0\n",
      "Successfully installed packaging-21.3 pytesseract-0.3.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text recognition\n",
    "import cv2\n",
    "import pytesseract\n",
    "import docx2txt\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytessercat\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:/Users/Samar/AppData/Local/Programs/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to get an image based on reasearch and return the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "#extract text \n",
    "text = docx2txt.process(r\"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test/Report_Samar_Jberi.docx\",r\"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test/Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page segmentation mode: default , OCR engine mode : default\n",
    "myconfig =r\" --psm 3 --oem 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business |»! Data\n",
      "understanding |_| understanding\n",
      "\n",
      "~~\n",
      "\n",
      "Data\n",
      "preparation\n",
      "\n",
      "Deployment t |\n",
      "\n",
      "Modeling\n",
      "\n",
      "Evaluation\n",
      "\n",
      "\n",
      "query found\n"
     ]
    }
   ],
   "source": [
    "#just to test\n",
    "text= pytesseract.image_to_string(PIL.Image.open(\"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test/Images/image2.png\"),config = myconfig)\n",
    "print(text)\n",
    "type(text)\n",
    "if \"Data\" in text:\n",
    "    print(\"query found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query found\n",
      "image14.png\n",
      "query found\n",
      "image15.png\n",
      "query found\n",
      "image2.jpg\n",
      "query found\n",
      "image21.png\n",
      "query found\n",
      "image3.jpg\n",
      "query found\n",
      "image4.png\n",
      "query found\n",
      "image5.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    " \n",
    "# get the path or directory\n",
    "folder_dir = \"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test/Images\"\n",
    "directory = 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test'\n",
    "for images in os.listdir(folder_dir):\n",
    " \n",
    "    # check if the image end swith png or jpg or jpeg\n",
    "    if (images.endswith(\".png\") or images.endswith(\".jpg\")\n",
    "        or images.endswith(\".jpeg\")):\n",
    "        # display\n",
    "        text= pytesseract.image_to_string(PIL.Image.open(os.path.join(folder_dir, images)),config = myconfig)\n",
    "        if \"Data\" in text:\n",
    "            print(\"query found\")\n",
    "            print(images)\n",
    "            #print(text)\n",
    "        #print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-47-0a5c98fe6475>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-47-0a5c98fe6475>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    text= pytesseract.image_to_string(PIL.Image.open(os.path.join(r\"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\", images)),config = myconfig)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# import required module\n",
    "import os\n",
    "import re\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "directory = 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if not filename.startswith('~$') or filename.endswith(\".docx\") or filename.endswith(\".doc\"):\n",
    "        f = os.path.join(directory, filename)\n",
    "        print(f)\n",
    "        X = docx2txt.process(f,r\"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\")\n",
    "\n",
    "        print(f)\n",
    "        \n",
    "pattern = re.compile(input(\"Enter_the_text_to_Search_here\"))\n",
    "for images in os.listdir(r\"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\"):\n",
    "    # check if the image end swith png or jpg or jpeg\n",
    "        if (images.endswith(\".png\") or images.endswith(\".jpg\") or images.endswith(\".jpeg\")):\n",
    "        # display\n",
    "        text= pytesseract.image_to_string(PIL.Image.open(os.path.join(r\"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\", images)),config = myconfig)\n",
    "            if pattern.search(text):\n",
    "                print(\"query found\")\n",
    "                print(f)\n",
    "                print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter_the_text_to_Search_herecomment\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "Package not found at 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\\Rapport_text_mining-.image1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-e0cefa299df6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# checking if it is a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdocument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\api.py\u001b[0m in \u001b[0;36mDocument\u001b[1;34m(docx)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \"\"\"\n\u001b[0;32m     24\u001b[0m     \u001b[0mdocx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default_docx_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdocx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdocx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mdocument_part\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_document_part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdocument_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWML_DOCUMENT_MAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtmpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"file '%s' is not a Word file, content type is '%s'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\opc\\package.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mpkg_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mpackage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mUnmarshaller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munmarshal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_reader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPartFactory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\opc\\pkgreader.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(pkg_file)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m|\u001b[0m\u001b[0mPackageReader\u001b[0m\u001b[1;33m|\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mloaded\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \"\"\"\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mphys_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPhysPkgReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mcontent_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ContentTypeMap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_xml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent_types_xml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mpkg_srels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_srels_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPACKAGE_URI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\opc\\phys_pkg.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mreader_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ZipPkgReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 raise PackageNotFoundError(\n\u001b[0m\u001b[0;32m     31\u001b[0m                     \u001b[1;34m\"Package not found at '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpkg_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 )\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: Package not found at 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\\Rapport_text_mining-.image1.png'"
     ]
    }
   ],
   "source": [
    "# import required module\n",
    "import os\n",
    "import re\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "# assign directory\n",
    "directory = 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "pattern = re.compile(input(\"Enter_the_text_to_Search_here\"))\n",
    "for filename in os.listdir(directory):\n",
    "    if not filename.startswith('~$') or  filename.endswith(\".docx\") or  filename.endswith(\".doc\"):\n",
    "        f = os.path.join(directory, filename)\n",
    "    \n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        document = Document(f)\n",
    "        print(f)\n",
    "        import re\n",
    "        \n",
    "        \n",
    "        for para in document.paragraphs: \n",
    "        \n",
    "        \n",
    "            if pattern.search(para.text):\n",
    "                print(\"Found the paragraph in this file\" ,filename)\n",
    "                print(para.text)\n",
    "                for run in para.runs:\n",
    "                    if para.text in run.text:\n",
    "                        run.font.highlight_color = WD_COLOR_INDEX.YELLOW\n",
    "                        document.save(f) \n",
    "                break\n",
    "       \n",
    "        else:\n",
    "                 print(\"Did not find the paragraph :(\")\n",
    "folder_dir = \"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\"\n",
    "# iterate over files in\n",
    "# that directory\n",
    "pattern = re.compile(input(\"Enter_the_text_to_Search_here\"))\n",
    "\n",
    "for images in os.listdir(folder_dir):\n",
    " \n",
    "    # check if the image end swith png or jpg or jpeg\n",
    "    if (images.endswith(\".png\") or images.endswith(\".jpg\")\n",
    "        or images.endswith(\".jpeg\")):\n",
    "        # display\n",
    "        text= pytesseract.image_to_string(PIL.Image.open(os.path.join(folder_dir, images)),config = myconfig)\n",
    "        if pattern.search(text):\n",
    "                print(\"query found\")\n",
    "                print(images)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "import os, re\n",
    "\n",
    "#  Third party packages need to be installed \n",
    "# pip install python-docx\n",
    " \n",
    "def get_pictures(word_path, result_path):\n",
    "    \"\"\"\n",
    "     Picture extraction \n",
    "    :param word_path: word route \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = docx.Document(word_path)\n",
    "        dict_rel = doc.part._rels\n",
    "        for rel in dict_rel:\n",
    "            rel = dict_rel[rel]\n",
    "            if \"image\" in rel.target_ref:\n",
    "                if not os.path.exists(result_path):\n",
    "                    os.makedirs(result_path)\n",
    "                img_name = re.findall(\"/(.*)\", rel.target_ref)[0]\n",
    "                word_name = os.path.splitext(word_path)[0]\n",
    "                if os.sep in word_name:\n",
    "                    new_name = word_name.split('\\\\')[-1]\n",
    "                else:\n",
    "                    new_name = word_name.split('/')[-1]\n",
    "                img_name = f'{new_name}-'+'.'+f'{img_name}'\n",
    "                with open(f'{result_path}/{img_name}', \"wb\") as f:\n",
    "                    f.write(rel.target_part.blob)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Get the word Document list , Path customization \n",
    "\n",
    "    os.chdir(\"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\")\n",
    "    spam=os.listdir(os.getcwd())\n",
    "    for i in spam:\n",
    "        get_pictures(str(i),os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further More\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query found\n",
      "Rapport_text_mining-.image2.png\n",
      "query found\n",
      "Rapport_text_mining-.image27.png\n",
      "query found\n",
      "Rapport_text_mining-.image28.png\n",
      "query found\n",
      "Rapport_text_mining-.image7.png\n",
      "query found\n",
      "Rapport_text_mining-.image8.png\n",
      "query found\n",
      "Report_Samar_Jberi-.image14.png\n",
      "query found\n",
      "Report_Samar_Jberi-.image15.png\n",
      "query found\n",
      "Report_Samar_Jberi-.image2.jpg\n",
      "query found\n",
      "Report_Samar_Jberi-.image21.png\n",
      "query found\n",
      "Report_Samar_Jberi-.image3.jpg\n",
      "query found\n",
      "Report_Samar_Jberi-.image4.png\n",
      "query found\n",
      "Report_Samar_Jberi-.image5.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    " \n",
    "# get the path or directory\n",
    "folder_dir = \"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\"\n",
    "directory = 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test'\n",
    "for images in os.listdir(folder_dir):\n",
    " \n",
    "    # check if the image end swith png or jpg or jpeg\n",
    "    if (images.endswith(\".png\") or images.endswith(\".jpg\")\n",
    "        or images.endswith(\".jpeg\")):\n",
    "        # display\n",
    "        text= pytesseract.image_to_string(PIL.Image.open(os.path.join(folder_dir, images)),config = myconfig)\n",
    "        if \"Data\" in text:\n",
    "            print(\"query found\")\n",
    "            print(images)\n",
    "            #print(text)\n",
    "    os.remove(images)\n",
    "        #print(images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter_the_text_to_Search_heredata\n",
      "C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\\Rapport_text_mining.docx\n",
      "Found the paragraph in this file Rapport_text_mining.docx\n",
      "Pour ce projet,on a utilisé la méthodologie CRISP-DM qui signifie \"cross-industry process for data mining\". Elle fournit une approche structurée pour la planification d'un projet de data mining. Elle est composée essentiellement de 6 étapes :\n"
     ]
    },
    {
     "ename": "PackageNotFoundError",
     "evalue": "Package not found at 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\\Report_Samar_Jberi-.image1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-7fc79806eaf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# checking if it is a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdocument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\api.py\u001b[0m in \u001b[0;36mDocument\u001b[1;34m(docx)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \"\"\"\n\u001b[0;32m     24\u001b[0m     \u001b[0mdocx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default_docx_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdocx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdocx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mdocument_part\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_document_part\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdocument_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent_type\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWML_DOCUMENT_MAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtmpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"file '%s' is not a Word file, content type is '%s'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\opc\\package.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mpkg_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mpackage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mUnmarshaller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munmarshal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_reader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPartFactory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\opc\\pkgreader.py\u001b[0m in \u001b[0;36mfrom_file\u001b[1;34m(pkg_file)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m|\u001b[0m\u001b[0mPackageReader\u001b[0m\u001b[1;33m|\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mloaded\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \"\"\"\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mphys_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPhysPkgReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mcontent_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ContentTypeMap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_xml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent_types_xml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mpkg_srels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackageReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_srels_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphys_reader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPACKAGE_URI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\opc\\phys_pkg.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, pkg_file)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mreader_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ZipPkgReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 raise PackageNotFoundError(\n\u001b[0m\u001b[0;32m     31\u001b[0m                     \u001b[1;34m\"Package not found at '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpkg_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 )\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: Package not found at 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\\Report_Samar_Jberi-.image1.png'"
     ]
    }
   ],
   "source": [
    "# import required module\n",
    "import os\n",
    "import re\n",
    "from docx.enum.text import WD_COLOR_INDEX\n",
    "\n",
    "# assign directory\n",
    "directory = 'C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "pattern = re.compile(input(\"Enter_the_text_to_Search_here\"))\n",
    "for filename in os.listdir(directory):\n",
    "    if not filename.startswith('~$') or  filename.endswith(\".docx\") or  filename.endswith(\".doc\"):\n",
    "        f = os.path.join(directory, filename)\n",
    "    \n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        document = Document(f)\n",
    "        print(f)\n",
    "        import re\n",
    "        \n",
    "        \n",
    "        for para in document.paragraphs: \n",
    "        \n",
    "        \n",
    "            if pattern.search(para.text):\n",
    "                print(\"Found the paragraph in this file\" ,filename)\n",
    "                print(para.text)\n",
    "                for run in para.runs:\n",
    "                    if para.text in run.text:\n",
    "                        run.font.highlight_color = WD_COLOR_INDEX.YELLOW\n",
    "                        document.save(f) \n",
    "                break\n",
    "       \n",
    "        else:\n",
    "                 print(\"Did not find the paragraph :(\")\n",
    "folder_dir = \"C:/Users/Samar/Desktop/5BI4/Stage PFE/essay/Test\"\n",
    "# iterate over files in\n",
    "# that directory\n",
    "pattern = re.compile(input(\"Enter_the_text_to_Search_here\"))\n",
    "\n",
    "for images in os.listdir(folder_dir):\n",
    " \n",
    "    # check if the image end swith png or jpg or jpeg\n",
    "    if (images.endswith(\".png\") or images.endswith(\".jpg\")\n",
    "        or images.endswith(\".jpeg\")):\n",
    "        # display\n",
    "        text= pytesseract.image_to_string(PIL.Image.open(os.path.join(folder_dir, images)),config = myconfig)\n",
    "        if pattern.search(text):\n",
    "                print(\"query found\")\n",
    "                print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PDFInfoNotInstalledError",
     "evalue": "Unable to get page count. Is poppler installed and in PATH?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdf2image\\pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LD_LIBRARY_PATH\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoppler_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\":\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LD_LIBRARY_PATH\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 951\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1421\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Das System kann die angegebene Datei nicht finden",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\XJS099~1\\AppData\\Local\\Temp/ipykernel_11452/1729276870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpdf_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpdfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpageNum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgBlob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdf2image\\pdf2image.py\u001b[0m in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mpoppler_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mpage_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdfinfo_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserpw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpoppler_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Pages\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;31m# We start by getting the output format, the buffer processing function and if we need pdftocairo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pdf2image\\pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[1;34m(pdf_path, userpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         raise PDFInfoNotInstalledError(\n\u001b[0m\u001b[0;32m    485\u001b[0m             \u001b[1;34m\"Unable to get page count. Is poppler installed and in PATH?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         )\n",
      "\u001b[1;31mPDFInfoNotInstalledError\u001b[0m: Unable to get page count. Is poppler installed and in PATH?"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import glob\n",
    "\n",
    "pdfs = glob.glob(r\"C:/Users/XJS09914403/Desktop/Files/ISO_26262-11_Dez.-2018.pdf\")\n",
    "\n",
    "for pdf_path in pdfs:\n",
    "    pages = convert_from_path(pdf_path, 500)\n",
    "\n",
    "    for pageNum,imgBlob in enumerate(pages):\n",
    "        text = pytesseract.image_to_string(imgBlob,lang='eng')\n",
    "\n",
    "        with open(f'{pdf_path[:-4]}_page{pageNum}.txt', 'w') as the_file:\n",
    "            the_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypiwin32\n",
      "  Downloading pypiwin32-223-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: pywin32>=223 in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (from pypiwin32) (228)\n",
      "Installing collected packages: pypiwin32\n",
      "Successfully installed pypiwin32-223\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypiwin32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = win32com.client.Dispatch(\"Word.Application\")\n",
    "word.visible = 1\n",
    "# set the visible to 0, if you dont want to see the word application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordObj = word.Documents.Open(\"C:/Users/XJS09914403/Desktop/Files/ISO_26262-11_Dez.-2018.pdf\")\n",
    "wordObj.SaveAs(\"C:/Users/XJS09914403/Desktop/Files/sample.docx\", FileFormat=16)\n",
    "# File format 16 refers to word file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (1.27.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (1.16.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (from pdf2image) (8.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdf2image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (0.3.9)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (from pytesseract) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\xjs09914403\\anaconda3\\lib\\site-packages (from packaging>=21.3->pytesseract) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import PyPDF2\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\xc2\\xa9 ISO 2018\\nRoad vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94\\nPart 11: \\nGuidelines on application of ISO \\n26262 to semiconductors\\nV\\xc3\\xa9hicules routiers \\xe2\\x80\\x94 S\\xc3\\xa9curit\\xc3\\xa9 fonctionnelle \\xe2\\x80\\x94\\nPartie 11: Lignes directrices sur l'application de l'ISO 26262 aux semi-\\nconducteurs\\nINTERNATIONAL \\nSTANDARD\\nISO\\n26262-11\\nFirst edition\\n2018-12\\nReference number\\nISO 26262-11:2018(E)\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n\"\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nii \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nCOPYRIGHT PROTECTED DOCUMENT\\n\\xc2\\xa9  ISO 2018\\nAll rights reserved. Unless otherwise specified, or required in the context of its implementation, no part of this publication may \\nbe reproduced or utilized otherwise in any form or by any means, electronic or mechanical, including photocopying, or posting \\non the internet or an intranet, without prior written permission. Permission can be requested from either ISO at the address \\nbelow or ISO\\xe2\\x80\\x99s member body in the country of the requester.\\nISO copyright office\\nCP 401 \\xe2\\x80\\xa2 Ch. de Blandonnet 8\\nCH-1214 Vernier, Geneva\\nPhone: +41 22 749 01 11\\nFax: +41 22 749 09 47\\nEmail: copyright@iso.org\\nWebsite: www.iso.org\\nPublished in Switzerland\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nForeword ..........................................................................................................................................................................................................................................v\\nIntroduction ................................................................................................................................................................................................................................vi\\n1 \\nScope .................................................................................................................................................................................................................................1\\n2 \\nNormative references ......................................................................................................................................................................................1\\n3\\t\\nTerms\\tand\\tdefinitions .....................................................................................................................................................................................1\\n4 \\nA semiconductor component and its partitioning ............................................................................................................2\\n4.1 \\nHow to consider semiconductor components ............................................................................................................. 2\\n4.1.1 \\nSemiconductor component development ..................................................................................................2\\n4.2 \\nDividing a semiconductor component in parts ........................................................................................................... 2\\n4.3 \\nAbout hardware faults, errors and failure modes .....................................................................................................3\\n4.3.1 \\nFault models......................................................................................................................................................................... 3\\n4.3.2 \\nFailure modes ..................................................................................................................................................................... 4\\n4.3.3 \\nThe distribution of base failure rate across failure modes ..........................................................4\\n4.4 \\nAbout adapting a semiconductor component safety analysis to system level .................................5\\n4.5 \\nIntellectual Property (IP) ............................................................................................................................................................... 6\\n4.5.1 \\nAbout IP ................................................................................................................................................................................... 6\\n4.5.2 \\nCategory and safety requirements for IP ....................................................................................................7\\n4.5.3 \\nIP lifecycle .............................................................................................................................................................................. 9\\n4.5.4 \\nWork products for IP .................................................................................................................................................11\\n4.5.5 \\nIntegration of black-box IP ...................................................................................................................................14\\n4.6 \\nBase failure rate for semiconductors ................................................................................................................................15\\n4.6.1 \\nGeneral notes on base failure rate estimation .....................................................................................15\\n4.6.2 \\nPermanent base failure rate calculation methods ...........................................................................20\\n4.7 \\nSemiconductor dependent failure analysis .................................................................................................................41\\n4.7.1 \\nIntroduction to DFA ....................................................................................................................................................41\\n4.7.2 \\nRelationship between DFA and safety analysis ..................................................................................42\\n4.7.3 \\nDependent failure scenarios ...............................................................................................................................42\\n4.7.4 \\nDistinction between cascading failures and common cause failures ..............................45\\n4.7.5 \\nDependent failure initiators and mitigation measures................................................................45\\n4.7.6 \\nDFA workflow ..................................................................................................................................................................51\\n4.7.7 \\nExamples of dependent failures analysis .................................................................................................54\\n4.7.8 \\nDependent failures between software element and hardware element .......................55\\n4.8 \\nFault injection .......................................................................................................................................................................................55\\n4.8.1 \\nGeneral...................................................................................................................................................................................55\\n4.8.2 \\nCharacteristics or variables of fault injection ......................................................................................55\\n4.8.3 \\nFault injection results ...............................................................................................................................................57\\n4.9 \\nProduction and Operation ..........................................................................................................................................................57\\n4.9.1 \\nAbout Production .........................................................................................................................................................57\\n4.9.2 \\nProduction Work Products ...................................................................................................................................58\\n4.9.3 \\nAbout service (maintenance and repair), and decommissioning .......................................58\\n4.10 \\nInterfaces within distributed developments ..............................................................................................................58\\n4.11 \\nConfirmation measures ................................................................................................................................................................59\\n4.12 \\nClarification on hardware integration and verification ....................................................................................59\\n5\\t\\nSpecific\\tsemiconductor\\ttechnologies\\tand\\tuse\\tcases ....................................................................................................60\\n5.1 \\nDigital components and memories.....................................................................................................................................60\\n5.1.1 \\nAbout digital components .....................................................................................................................................60\\n5.1.2 \\nFault models of non-memory digital components ...........................................................................60\\n5.1.3 \\nDetailed fault models of memories ...............................................................................................................61\\n5.1.4 \\nFailure modes of digital components ..........................................................................................................62\\n5.1.5 \\nExample of failure mode definitions for common digital blocks .........................................62\\n5.1.6 \\nQualitative and quantitative analysis of digital component ....................................................66\\n5.1.7 \\nNotes on quantitative analysis of digital components ..................................................................67\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\niii\\nContents \\nPage\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\n5.1.8 \\nExample of quantitative analysis ....................................................................................................................69\\n5.1.9 \\nExample of techniques or measures to detect or avoid systematic failures \\nduring design of a digital component .........................................................................................................70\\n5.1.10 Verification using fault injection simulation .........................................................................................74\\n5.1.11 Example of safety documentation for a digital component .....................................................75\\n5.1.12 Examples of safety mechanisms for digital components and memories .....................76\\n5.1.13 Overview of techniques for digital components and memories ..........................................77\\n5.2 \\nAnalogue/mixed signal components ................................................................................................................................80\\n5.2.1 \\nAbout analogue and mixed signal components ..................................................................................80\\n5.2.2 \\nAnalogue and mixed signal components and failure modes ...................................................82\\n5.2.3 \\nNotes about safety analysis .................................................................................................................................91\\n5.2.4 \\nExamples of safety mechanisms ......................................................................................................................94\\n5.2.5 \\nAvoidance of systematic faults during the development phase ...........................................97\\n5.2.6 \\nExample of safety documentation for an analogue/mixed-signal component ....100\\n5.3 \\nProgrammable logic devices .................................................................................................................................................101\\n5.3.1 \\nAbout programmable logic devices ...........................................................................................................101\\n5.3.2 \\nFailure modes of PLD .............................................................................................................................................105\\n5.3.3 \\nNotes on safety analyses for PLDs ..............................................................................................................106\\n5.3.4 \\nExamples of safety mechanisms for PLD ..............................................................................................112\\n5.3.5 \\nAvoidance of systematic faults for PLD ..................................................................................................113\\n5.3.6 \\nExample of safety documentation for a PLD ......................................................................................116\\n5.3.7 \\nExample of safety analysis for PLD ............................................................................................................116\\n5.4 \\nMulti-core components..............................................................................................................................................................116\\n5.4.1 \\nTypes of multi-core components .................................................................................................................116\\n5.4.2 \\nImplications of ISO 26262 series of standards for multi-core components ...........117\\n5.5 \\nSensors and transducers ..........................................................................................................................................................119\\n5.5.1 \\nTerminology of sensors and transducers .............................................................................................119\\n5.5.2 \\nSensors and transducers failure modes .................................................................................................120\\n5.5.3 \\nSafety analysis for sensors and transducers ......................................................................................125\\n5.5.4 \\nExamples of safety measures for sensors and transducers ..................................................126\\n5.5.5 \\nAbout avoidance of systematic faults for sensors and transducers ...............................130\\n5.5.6 \\nExample of safety documentation for sensors and transducers.......................................131\\nAnnex A (informative) Example on how to use digital failure modes for diagnostic coverage \\nevaluation .............................................................................................................................................................................................................132\\nAnnex B (informative) Examples of dependent failure analysis .......................................................................................136\\nAnnex C (informative) Examples of quantitative analysis for a digital component ......................................150\\nAnnex D (informative) Examples of quantitative analysis for analogue component ..................................155\\nAnnex E (informative) Examples of quantitative analysis for PLD component .................................................169\\nBibliography .........................................................................................................................................................................................................................175\\niv \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b\" \\nISO 26262-11:2018(E)\\nForeword\\nISO (the International Organization for Standardization) is a worldwide federation of national standards \\nbodies (ISO member bodies). The work of preparing International Standards is normally carried out \\nthrough ISO technical committees. Each member body interested in a subject for which a technical \\ncommittee has been established has the right to be represented on that committee. International \\norganizations, governmental and non-governmental, in liaison with ISO, also take part in the work. \\nISO collaborates closely with the International Electrotechnical Commission (IEC) on all matters of \\nelectrotechnical standardization.\\nThe procedures used to develop this document and those intended for its further maintenance are \\ndescribed in the ISO/IEC Directives, Part 1. In particular, the different approval criteria needed for the \\ndifferent types of ISO documents should be noted. This document was drafted in accordance with the \\neditorial rules of the ISO/IEC Directives, Part 2 (see www .iso .org/directives).\\nAttention is drawn to the possibility that some of the elements of this document may be the subject of \\npatent rights. ISO shall not be held responsible for identifying any or all such patent rights. Details of \\nany patent rights identified during the development of the document will be in the Introduction and/or \\non the ISO list of patent declarations received (see www .iso .org/patents).\\nAny trade name used in this document is information given for the convenience of users and does not \\nconstitute an endorsement.\\nFor an explanation on the voluntary nature of standards, the meaning of ISO specific terms and \\nexpressions related to conformity assessment, as well as information about ISO's adherence to the \\nWorld Trade Organization (WTO) principles in the Technical Barriers to Trade (TBT) see the following \\nURL: www .iso .org/iso/foreword .html.\\nThis document was prepared by Technical Committee ISO/TC 22 Road vehicles Subcommittee SC 32 \\nElectrical and electronic components and general system aspects.\\nAny feedback or questions on this document should be directed to the user\\xe2\\x80\\x99s national standards body. A \\ncomplete listing of these bodies can be found at www .iso .org/members .html.\\nA list of all parts in the ISO 26262 series can be found on the ISO website.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\nv\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n\"\n",
      "b' \\nISO 26262-11:2018(E)\\nIntroduction\\nThe ISO 26262 series of standards is the adaptation of IEC 61508 series of standards to address the \\nsector specific needs of electrical and/or electronic (E/E) systems within road vehicles.\\nThis adaptation applies to all activities during the safety lifecycle of safety-related systems comprised \\nof electrical, electronic and software components.\\nSafety is one of the key issues in the development of road vehicles. Development and integration of \\nautomotive functionalities strengthen the need for functional safety and the need to provide evidence \\nthat functional safety objectives are satisfied.\\nWith the trend of increasing technological complexity, software content and mechatronic \\nimplementation, there are increasing risks from systematic failures and random hardware failures, \\nthese being considered within the scope of functional safety. ISO 26262 series of standards includes \\nguidance to mitigate these risks by providing appropriate requirements and processes. \\nTo achieve functional safety, the ISO 26262 series of standards:\\na) provides a reference for the automotive safety lifecycle and supports the tailoring of the activities \\nto be performed during the lifecycle phases, i.e., development, production, operation, service and \\ndecommissioning;\\nb) provides an automotive-specific risk-based approach to determine integrity levels [Automotive \\nSafety Integrity Levels (ASILs)];\\nc) \\nuses ASILs to specify which of the requirements of ISO 26262 are applicable to avoid unreasonable \\nresidual risk;\\nd) provides requirements for functional safety management, design, implementation, verification, \\nvalidation and confirmation measures; and\\ne) provides requirements for relations between customers and suppliers.\\nThe ISO 26262 series of standards is concerned with functional safety of E/E systems that is achieved \\nthrough safety measures including safety mechanisms. It also provides a framework within which \\nsafety-related systems based on other technologies (e.g. mechanical, hydraulic and pneumatic) can be \\nconsidered.\\nThe achievement of functional safety is influenced by the development process (including such \\nactivities as requirements specification, design, implementation, integration, verification, validation \\nand configuration), the production and service processes and the management processes.\\nSafety is intertwined with common function-oriented and quality-oriented activities and work \\nproducts. The ISO 26262 series of standards addresses the safety-related aspects of these activities and \\nwork products.\\nFigure 1 shows the overall structure of the ISO 26262 series of standards. The ISO 26262 series of \\nstandards is based upon a V-model as a reference process model for the different phases of product \\ndevelopment. Within the figure: \\n\\xe2\\x80\\x94 the shaded \\xe2\\x80\\x9cV\\xe2\\x80\\x9ds represent the interconnection among ISO 26262-3, ISO 26262-4, ISO 26262-5, \\nISO 26262-6 and ISO 26262-7;\\n\\xe2\\x80\\x94 for motorcycles:\\n\\xe2\\x80\\x94 ISO 26262-12:2018, Clause 8 supports ISO 26262-3;\\n\\xe2\\x80\\x94 ISO 26262-12:2018, Clauses 9 and 10 support ISO 26262-4; \\n\\xe2\\x80\\x94 the specific clauses are indicated in the following manner: \\xe2\\x80\\x9cm-n\\xe2\\x80\\x9d, where \\xe2\\x80\\x9cm\\xe2\\x80\\x9d represents the number \\nof the particular part and \\xe2\\x80\\x9cn\\xe2\\x80\\x9d indicates the number of the clause within that part.\\n \\nvi \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nEXAMPLE \\n\\xe2\\x80\\x9c2-6\\xe2\\x80\\x9d represents ISO 26262-2:2018, Clause 6.\\nFigure 1 \\xe2\\x80\\x94 Overview of the ISO 26262 series of standards\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\nvii\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b'Normen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nRoad vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94\\nPart 11: \\nGuidelines on application of ISO 26262 to semiconductors\\n1 Scope\\nThis document is intended to be applied to safety-related systems that include one or more electrical \\nand/or electronic (E/E) systems and that are installed in series production road vehicles, excluding \\nmopeds. This document does not address unique E/E systems in special vehicles such as E/E systems \\ndesigned for drivers with disabilities. \\nNOTE \\nOther dedicated application-specific safety standards exist and can complement the ISO 26262 series \\nof standards or vice versa.\\nSystems and their components released for production, or systems and their components already under \\ndevelopment prior to the publication date of this document, are exempted from the scope of this edition. \\nThis document addresses alterations to existing systems and their components released for production \\nprior to the publication of this document by tailoring the safety lifecycle depending on the alteration. \\nThis document addresses integration of existing systems not developed according to this document and \\nsystems developed according to this document by tailoring the safety lifecycle.\\nThis document addresses possible hazards caused by malfunctioning behaviour of safety-related E/E \\nsystems, including interaction of these systems. It does not address hazards related to electric shock, \\nfire, smoke, heat, radiation, toxicity, flammability, reactivity, corrosion, release of energy and similar \\nhazards, unless directly caused by malfunctioning behaviour of safety-related E/E systems.\\nThis document describes a framework for functional safety to assist the development of safety-\\nrelated E/E systems. This framework is intended to be used to integrate functional safety activities \\ninto a company-specific development framework. Some requirements have a clear technical focus to \\nimplement functional safety into a product; others address the development process and can therefore \\nbe seen as process requirements in order to demonstrate the capability of an organization with respect \\nto functional safety.\\nThis document does not address the nominal performance of E/E systems.\\nThis document has an informative character only. It contains possible interpretations of other \\nparts of ISO 26262 with respect to semiconductor development. The content is not exhaustive with \\nregard to possible interpretations, i.e., other interpretations can also be possible in order to fulfil the \\nrequirements defined in other parts of ISO 26262.\\n2 Normative references\\nThe following documents are referred to in the text in such a way that some or all of their content \\nconstitutes requirements of this document. For dated references, only the edition cited applies. For \\nundated references, the latest edition of the referenced document (including any amendments) applies.\\nISO 26262-1, Road vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94 Part 1: Vocabulary\\n3\\t Terms\\tand\\tdefinitions\\nFor the purposes of this document, the terms, definitions and abbreviated terms given in \\nISO 26262-1 apply.\\nINTERNATIONAL STANDARD \\nISO 26262-11:2018(E)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n1\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nISO and IEC maintain terminological databases for use in standardization at the following addresses:\\n\\xe2\\x80\\x94 IEC Electropedia: available at http: //www .electropedia .org/\\n\\xe2\\x80\\x94 ISO Online browsing platform: available at https: //www .iso .org/obp\\n4 A semiconductor component and its partitioning\\n4.1 How to consider semiconductor components\\n4.1.1 \\nSemiconductor component development\\nIf a semiconductor component is developed as a part of an item development compliant with the \\nISO 26262 series of standards, it is developed based on hardware safety requirements derived from the \\ntop-level safety goals of the item, through the technical safety concept. Targets for diagnostic coverages \\nfor relevant failure modes to meet hardware architectural metrics and Probabilistic Metric for random \\nHardware Failures (PMHF) or Evaluation of Each Cause of safety goal violation (EEC) are allocated to \\nthe item: in this case, the semiconductor component is just one of the elements. As mentioned in the \\nEXAMPLE of ISO 26262-5:2018 [66], 8.2, to facilitate distributed developments, target values can be \\nassigned to the semiconductor component itself, by either deriving target values for the SPFM, LFM and \\nPMHF at the item level or applying EEC to the HW part level. The safety analysis of a semiconductor \\ncomponent is performed based on the requirements and recommendations defined in ISO 26262-5:2018, \\n7.4.3 and in ISO 26262-9:2018 [70], Clause 8.\\nNOTE \\nIf an element has not been developed in compliance with the ISO 26262 series of standards, the \\nrequirements in ISO 26262-8:2018 [69], Clause 13 can be considered.\\nThe semiconductor component can be developed as a SEooC, as described in ISO 26262-10 [61]. In this \\ncase, the development is done based on assumptions on the conditions of the semiconductor component \\nusage (Assumptions of Use or AoU, see 4.4), and then the assumptions are verified at the next higher \\nlevel of integration considering the semiconductor component requirements derived from the safety \\ngoals of the item in which the semiconductor component is to be used.\\nThe descriptions and methods in this part are provided assuming the semiconductor component is \\na SEooC, but the described methods (e.g. the method for failure rate computation of a semiconductor \\ncomponent) are still valid if the semiconductor component is not considered as an SEooC. When \\nthose methods are conducted considering the stand-alone semiconductor component, appropriate \\nassumptions are made. Sub-clause 4.4 describes how to adapt and verify those methods and assumptions \\nat the system or element level. At the stand-alone semiconductor component level, the requirements of \\nISO 26262-2 [63], ISO 26262-5, ISO 26262-6[67], ISO 26262-7[68], ISO 26262-8 and ISO 26262-9 (e.g. \\nrelated to safety analyses, dependent failure analysis, verification, etc.) can be applied.\\n4.2 Dividing a semiconductor component in parts\\nAs shown in Figure 2 and according to the definitions in ISO 26262-1:2018, 3.21, a semiconductor \\ncomponent can be divided into parts: the whole semiconductor hierarchy can be seen as a component, \\nthe second level of hierarchy (e.g. a CPU) as a part, the following levels of hierarchy (e.g. the CPU register \\nbank) as subparts, till the elementary subparts (its internal registers and the related logic).\\nNOTE \\nThe level of detail (e.g. whether to stop at part level or go down to subpart or elementary subpart \\nlevel) as also the definition of the elementary subpart (e.g. flip-flop, analogue transistor) can depend on the safety \\nconcept, the stage of the analysis and on the safety mechanisms used (inside the semiconductor component or at \\nthe system or element level).\\n \\n2 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 2 \\xe2\\x80\\x94 A semiconductor, its parts and subparts\\n4.3 About hardware faults, errors and failure modes\\nRandom hardware faults and failure modes of an integrated circuit are linked together as shown in \\nFigure 3 below.\\nNOTE 1 \\nThe failure mode can be abstract or tailored to a specific implementation, e.g. related to a pin of a \\ncomponent, part or subpart.\\nIn general, failure modes are described in this document as functional failure modes. Further \\ncharacterisation of failure modes are possible.\\nEXAMPLE \\nAn example of failure modes for digital circuits is given in Annex A.\\nFaults and errors described in this document are related to the physical implementation of a given \\nsemiconductor component.\\nNOTE 2 \\nThe terms fault, error, and failure are used according to the ISO 26262-1 definitions, i.e. faults create \\nerrors which can lead to a failure. In many reliability modelling standards the terms fault and failure are used \\ninterchangeably.\\nFigure 3 \\xe2\\x80\\x94 Relationship between hardware faults and failure modes\\n4.3.1 \\nFault models\\nFault models are an abstract representation of physical faults.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n3\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nThe failure mode distribution is correlated with the fault models illustrated in Figure 3.\\nEXAMPLE \\nIf a failure mode is caused X % by stuck-at faults and Y % by shorts, and if a safety mechanism \\nonly covers stuck-at faults with a coverage of Z %, then the claimed diagnostic coverage is X % \\xc3\\x97 Z %.\\nIn the context of a semiconductor component, relevant fault models are identified based on the \\ntechnology and circuit implementation.\\nNOTE 1 \\nSee 5.1.2 for further details on fault models for digital components and 5.1.3 for memories.\\nNOTE 2 \\nTypically it is not possible to evaluate every possible physical fault individually due to the number of \\nfaults and required level of detail.\\n4.3.2 \\nFailure modes\\nA failure mode is described at a level of detail commensurate with the safety concept and the related \\nsafety mechanism.\\nEXAMPLE 1 \\nIn the case of a CPU with a hardware lock-step safety mechanism, the failure modes can be \\ndefined by looking at the CPU function as a whole.\\nEXAMPLE 2 \\nIn the case of a CPU with a structural software-based hardware test as safety mechanism, the \\nfailure modes for the CPU function are defined in more detail because the software test will cover different \\nfailure modes with different failure mode coverage.\\nEXAMPLE 3 \\nExamples of different level of detail for digital failure modes are given in Annex A.\\nTo define failure modes, keywords are used if applicable.\\nEXAMPLE 4 \\nExamples of keywords are: wrong program flow execution, data corruption, accessing unintended \\nlocations, deadlock, livelock, incorrect instruction execution.\\nIn special cases, failure modes closer to physical implementation could be more helpful.\\nEXAMPLE 5 \\nAnalogue failure mode (Table 36).\\nThe association between the identified failure modes and circuit implementation fault models is \\nsupported by evidence ensuring any failure mode is allocated to a part/subpart of the component, and \\nany relevant part/subpart has at least one failure mode.\\nNOTE \\nThe goal is to ensure that there are no gaps between circuit implementation and the listed failure modes.\\n4.3.3 \\nThe distribution of base failure rate across failure modes\\nThe base failure rate (see 4.6) is distributed across failure modes. The accuracy of that distribution is \\naligned with the level of detail of the analysis and the consideration of the relevant safety mechanisms \\navailable.\\nEXAMPLE 1 \\nIn the case of a CPU with a hardware lock-step safety mechanism, it is not necessary to have a \\ndetailed distribution of CPU failure modes.\\nEXAMPLE 2 \\nIn the case of a CPU with a structural software-based hardware test, the distribution is defined \\nin more detail because in this way it will be possible to estimate with enough accuracy the diagnostic coverage of \\nfailure modes.\\nIn case there is no data available to compute the distribution with the required accuracy, the failure \\nrate is distributed uniformly across the failure modes or an expert judgment is provided with related \\narguments.\\nNOTE \\nA sensitivity analysis to the distribution is done to evaluate the impact on the diagnostic coverage and \\nquantitative safety analysis results.\\n \\n4 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n4.4 About adapting a semiconductor component safety analysis to system level\\nThe adaptation of the semiconductor component safety analysis to system level is done by:\\n\\xe2\\x80\\x95 \\ntransforming the detailed failure modes of a semiconductor component into the high-level failure \\nmodes needed during the analysis at system level, as shown in Figure 4;\\n \\nFigure 4 \\xe2\\x80\\x94 Example of bottom-up approach to derive system level failure modes\\nNOTE 1 \\nBy combining top-down (e.g. FTA) and bottom-up methods (e.g. FMEA), it can be possible to identify \\nthe detailed semiconductor component failure modes and combine them up to the component level.\\nNOTE 2 \\nStarting from a low level of abstraction allows a quantitative and precise failure distribution for a \\nsemiconductor component that otherwise is based on qualitative distribution assumptions.\\nNOTE 3 \\nAs discussed in 4.2, the necessary level of detail can depend on the stage of the analysis and on the \\nsafety mechanisms used.\\n\\xe2\\x80\\x95 \\nthe diagnostic coverage computed at part or subpart level could be improved by measures at the \\npart, component level or system or item level; or\\nEXAMPLE 1 \\nA semiconductor component includes an ADC with no safety mechanisms implemented in \\nhardware. At the component stand-alone level, the diagnostic coverage was considered zero. At system level, \\nthe ADC is included in a closed-loop, and its faults are detected by a software-based consistency check. In \\nthis context, the diagnostic coverage of that subpart is increased due to the safety mechanism implemented \\nat system-level.\\n\\xe2\\x80\\x95 \\nthe diagnostic coverage computed at part or subpart level could have been calculated under certain \\nspecific assumptions (\\xe2\\x80\\x9cAssumptions of Use\\xe2\\x80\\x9d or AoU).\\nNOTE 4 \\nAt system level different safety mechanisms or failure masking can be present. This can be taken \\ninto consideration in safety analysis when a justification is possible.\\nEXAMPLE 2 \\nA semiconductor component includes a memory in which each single-error is corrected and \\nsignalled by the ECC to the CPU. At the component stand-alone level, it was assumed that a software driver \\nis implemented to handle this event. At system level, for performance reasons, this software driver is not \\nimplemented, and therefore the assumption is not fulfilled. The semiconductor component is programmed \\nto send the error correction flag directly to the outside world.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n5\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n4.5 Intellectual Property (IP)\\n4.5.1 \\nAbout IP\\n4.5.1.1 \\nUnderstanding IP\\nIn this sub-clause, IP refers to a reusable unit of logical design or physical design intended to be \\nintegrated into a design as a part or a component. The term \\xe2\\x80\\x9cIP integrator\\xe2\\x80\\x9d is used in reference to the \\norganization responsible for integrating IP designs from one or more sources into a design with safety \\nrequirements. The term \\xe2\\x80\\x9cIP supplier\\xe2\\x80\\x9d is used in reference to the organization responsible for designing \\nor developing the IP. The IP integrator and the IP supplier can be separate parties as well as the same \\ncompany or different organisations in the same company.\\nBased on the requirements in ISO 26262 series of standards, four possible approaches are identified \\nfor IP based designs. These approaches are shown in Figure 5. The IP integrator typically chooses \\nthe approach based on consideration of the information provided from the IP supplier as well as the \\nmaturity of the IP.\\nEXAMPLE \\nIf no supporting information is available from the IP supplier, possible approaches can be limited \\nto the \\xe2\\x80\\x9cproven in use\\xe2\\x80\\x9d argument, if applicable. If the proven in use argument is not applicable, then the role of the \\nIP in the safety architecture is treated differently, e.g. using diverse redundancy to reduce risk of systematic and \\nrandom hardware failures.\\nFigure 5 \\xe2\\x80\\x94 Possible approaches for using IP in safety-related designs\\nThe IP can be an existing design with a predefined set of features. In this case the IP integrator has \\nthe responsibility of identifying the set of features which are required to support the safety concept of \\nthe design. IP can also be designed based on an agreed set of safety requirements. In this case the IP \\nintegrator identifies the requirements for the IP which are necessary to support the safety concept of \\nthe design.\\nNOTE 1 \\nThe guidance in this sub-clause can be applied to newly developed IP, modified IP, and existing \\nunmodified IP.\\nNOTE 2 \\nA common approach is to assume the possible target usage as defined in ISO 26262-2:2018, 6.4.5.7. \\nThis option is described as SEooC in ISO 26262-10 [61]. Development of an SEooC relies on identification of \\nassumed use cases and safety requirements which are verified by the IP integrator.\\n4.5.1.2 \\nTypes of IP\\nCommonly used IP types are listed in Table 1. This is not an exhaustive list covering the possible IP \\ntypes. This document considers both the physical and the model representation types of IP as applied \\nto semiconductor designs.\\n \\n6 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 1 \\xe2\\x80\\x94 Types of IP\\nIP type\\nDescription\\nPhysical representation\\nA complete chip layout description, containing instantiations of standard cells \\nfor a specific cell library or analogue cells for a target manufacturing process.\\nEXAMPLE   ADC macro, PLL macro.\\nModel representation\\nA description of a design in terms of a hardware description language (HDL) \\nsuch as Verilog or VHDL, or analogue transistor level circuit schematic.\\nA logic design in model representation is synthesized into a list of gates con-\\nsisting of basic cells, followed by placement and routing to achieve a semicon-\\nductor design.\\nAnalogue circuit schematic components, such as transistors, diodes, resistors, \\nand capacitors, are mapped into target technology library components, fol-\\nlowed by placement and routing to achieve a semiconductor design.\\nEXAMPLE   Processor or memory controller design exchanged without mapping \\nto a particular technology, operational amplifier transistor level schematic.\\nNOTE 1   Physical representation IPs are also known as \\xe2\\x80\\x9chard IPs\\xe2\\x80\\x9d.\\nNOTE 2   Model representation IPs are also known as \\xe2\\x80\\x9csoft IPs\\xe2\\x80\\x9d.\\nNOTE 3   This classification is applicable to generic IP design including digital, analogue, mixed signal, PLD, Sensors and \\nTransducers.\\nNOTE 1 \\nIP in the form of logic design can also be configurable. In this case, the configuration options are \\nspecified by the IP integrator.\\nEXAMPLE 1 \\nConfiguration options to define interface bus width, memory size, and presence of fault detection \\nmechanisms.\\nNOTE 2 \\nIP can also be generated with dedicated tools (memory compilers, C to HDL compilers, network-on-\\nchip generators). In this case:\\n\\xe2\\x80\\x95 \\nconfidence in software tools can be demonstrated using the methods described in ISO 26262-8:2018, \\nClause 11, tailored based on the amount of verification performed on the generated IP;\\n\\xe2\\x80\\x95 \\nthe necessary verification activities to guarantee the correctness of the generated IP are performed by the \\nIP integrator or IP supplier as applicable (e.g. agreement in DIA);\\n\\xe2\\x80\\x95 \\nthe necessary work products, as listed in following clauses, are made available; and\\n\\xe2\\x80\\x95 \\nthe IP integrator verifies the correct integration of the IP in its context.\\n4.5.2 \\nCategory and safety requirements for IP\\nIn general, two categories of IP can be determined based on the allocation of safety requirements: IP \\nwith no allocated safety requirements, and IP with one or more allocated safety requirements. When \\nthe IP has no allocated safety requirements, no additional considerations are required for ISO 26262 \\nseries of standards unless identified during the safety analysis. In the case of coexistence of non-safety-\\nrelated IPs with safety-related elements, dependent failure(s) analysis is used to evaluate freedom from \\ninterference. For dependent failure analysis guidance, see ISO 26262-9:2018, Clause 7 together with the \\nadditional guidance in 4.7 of this document.\\nIf one or more safety requirements are allocated to the IP, the requirements of ISO 26262 series of \\nstandards are applicable. In particular requirements of ISO 26262-2, ISO 26262-4 [65], ISO 26262-5, \\nISO 26262-8, and ISO 26262-9 are often tailored to apply to IP designs. The following text gives \\nguidance for IP with allocated safety requirements, and how to consider these requirements for IP with \\nand without integrated safety mechanisms.\\nSafety-related IPs can be further classified based on the integration of safety mechanisms. Two \\npossible cases are illustrated in Figure 6, with subfigure (a) illustrating IP which has integrated safety \\nmechanisms, and subfigure (b) illustrating IP which has no integrated safety mechanisms.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n7\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 6 \\xe2\\x80\\x94 Types of IP with allocated safety requirements\\nNOTE 1 \\nIP safety mechanisms can be included for detection of failure modes of the IP, as well as failure modes \\nexternal to the IP.\\nNOTE 2 \\nSafety mechanisms implemented in the IP can provide full or partial diagnostic coverage of a defined \\nset of failure modes. It is also possible that only failure mode detection is performed by the IP, with failure mode \\ncontrol being provided by components external to the IP.\\nThe IP provider is responsible for providing the usage assumptions made during IP development in \\norder to allow the IP integrator to check consistency with safety requirements.\\nThe hardware features of the IP can be initially developed targeting its integration into a safety-related \\nhardware environment, by providing safety mechanisms based on assumed safety requirements that \\naim at controlling given failure modes. In this case the requirements of ISO 26262-2, ISO 26262-4, \\nISO 26262-5, ISO 26262-6 (in the case of software based safety mechanisms to cover hardware failures), \\nISO 26262-8, and ISO 26262-9, whenever applicable, can be used for the design of the safety mechanisms \\nduring the development of the IP.\\nEXAMPLE 1 \\nBus \\xe2\\x80\\x9cfabric\\xe2\\x80\\x9d with built-in bus supervisors including fault detection and notification logic (e.g. \\ninterrupt signals).\\nEXAMPLE 2 \\nVoltage regulator with monitoring (under-voltage and over-voltage detection), protection \\n(current limit or thermal protection) and self-diagnostics (monitoring and protection circuit built-in self-tests).\\nAlternatively the IP can be developed with no assumed safety requirements or specific safety \\nmechanisms to detect and control faults.\\nEXAMPLE 3 \\nBus \\xe2\\x80\\x9cfabric\\xe2\\x80\\x9d without built-in bus supervisors or error reporting logic.\\nEXAMPLE 4 \\nVoltage regulator without monitoring, protection or built-in monitoring or protection circuit \\ndiagnostics.\\nSafety analyses defined in ISO 26262-9:2018, Clause 8 can be applied to the IP. A qualitative safety \\nanalysis, and in some cases a quantitative analysis, can be provided to the IP integrator to justify the \\ncapabilities of the safety mechanisms to control given failure modes or to provide information on failure \\n \\n8 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nmodes and related failure mode distribution. Similarly a dependent failure analysis can be provided to \\ndemonstrate required independence or freedom from interference.\\nNOTE 3 \\nThe IP supplier includes example information concerning failure mode distribution in the safety \\nanalysis results, based on specific implementation assumptions. Documentation related to safety mechanisms \\ncan be provided with other safety-related documentation for the IP. This information can also be combined into a \\nsingle safety manual or safety application note as described in 5.1.11 (for digital components), 5.2.6 (for analogue \\nor mixed signal components), 5.3.6 (for PLD) and 5.5.6 (for sensors/transducers).\\nNOTE 4 \\nThe base failure rate depends on the actual implementation, including the technology, of the IP into \\nthe integrated circuit and the use condition of the integrated circuit, as described in 4.6. So the base failure rate \\ncan only be provided as a reference to the IP integrator who is responsible for recalculating the failure rate \\naccording to the actual use case.\\nNOTE 5 \\nThis information can be included within existing documentation (e.g. integration guidelines, technical \\nreference documents, application notes).\\nThe IP integrator can request additional information from the IP supplier in implementing safety \\nrequirements. The IP supplier can support the request by providing information concerning measures \\nused to avoid systematic faults, as well as safety analysis results. Safety analysis results can be used \\nto support the evaluation of hardware metrics for the integrated IP, as well as to demonstrate freedom \\nfrom interference and independence.\\nSince the IP will be integrated into a safety-related design, consideration of coexistence is important \\nto ensure that the integrated IP cannot have an adverse impact on other safety-related functions. In \\norder to claim freedom from interference, dependent failure analysis as described in ISO 26262-9:2018, \\nClause 6 and ISO 26262-9:2018, Clause 7 can be used, together with the additional guidance in 4.7 of \\nthis document.\\nIf the IP integrator determines that the fulfilment of safety requirements is not possible with the \\nsupplied IP, a change request to the supplier can be raised as described in ISO 26262-8:2018, 5.4.4 and, \\nin cases where the IP is an SEooC, ISO 26262-10 [61]. Alternatively, other measures by the IP integrator \\nto comply with safety requirements can be applied, such as additional safety mechanisms at integration \\nlevel. Safety mechanisms can be implemented in hardware, software, or a combination of both. If \\nevidence of a compliant development is missing, ISO 26262-8:2018, Clause 13 and ISO 26262-8:2018, \\nClause 14, can provide alternative means to argue compliance.\\nThe IP integrator is responsible for each integration and associated verification and testing activities \\nrelated to the allocated safety requirements and safety mechanisms, as applicable.\\nNOTE 6 \\nThe IP supplier is responsible for ensuring that the delivery complies with the specified properties and \\nfor avoidance of systematic faults in the generated IP. Moreover the IP supplier provides supporting information \\nto allow the IP integrator to conduct integration activities.\\n4.5.3 \\nIP lifecycle\\n4.5.3.1 \\nIntroduction\\nAvoidance and detection of systematic faults during the IP lifecycle are required to ensure that the \\nresulting design is suitable for use in applications with one or more allocated safety requirements. \\nRequirements for avoidance and detection of systematic faults are provided in ISO 26262-5:2018, \\nClause 7, in the context of hardware design. In this document, 5.1.9 (for digital components), 5.2.5 \\n(for analogue or mixed-signal components), 5.3.5.3 (for PLD) and 5.5.5 (for Sensors and Transducers) \\nprovide further guidance. This guidance can be used to determine the general methods that can be \\nused during IP development to avoid and detect systematic faults.\\nFor IP which exhibits programmable behaviour, ISO 26262-4:2018, 6.4.6.5 can be considered as well as \\nthe guidelines described in 5.3.\\nThe IP integrator is responsible for integrating the supplied IP. For the integration activities the \\nassumptions of use and integration guidelines described for the IP are considered. The impact of \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n9\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nassumptions of use which cannot be fulfilled by, or which are invalid for, the design into which the IP \\nis being integrated is analysed and considered with change management conducted as described in \\nISO 26262-8:2018, Clause 8. Figure 7 provides an example lifecycle based on SEooC development, as \\nalready provided in ISO 26262-10 [61].\\nFigure 7 \\xe2\\x80\\x94 IP lifecycle when IP is treated as SEooC\\nNOTE 1 \\nThe references shown in Figure 7 are related to the ISO 26262 series of standards.\\nNOTE 2 \\nIn Figure 7, ISO 26262-5:2018, Clause 10 is only partially the responsibility of the IP supplier because \\na number of the related requirements are not applicable to IP suppliers, such as ESD tests.\\nThe DIA can define work products (as listed in 4.5.4) to be provided by the IP supplier to support the IP \\nintegrator in IP integration activities.\\n4.5.3.2 \\nIP as SEooC\\nWhen developing an SEooC IP, applicable safety activities are tailored as described in ISO 26262-2:2018, \\n6.4.5.7. Such tailoring for the SEooC development does not imply that any step of the safety lifecycle \\ncan be omitted. In cases where certain steps are deferred during the SEooC development, they can be \\ncompleted during the item development.\\nIn cases where a mismatch exists between the SEooC ASIL capability (see ISO 26262-1:2018, 3.2) and \\nthe ASIL requirements specified by the IP integrator, the IP integrator can implement additional safety \\nmechanisms external to the IP. Additional safety measures for systematic failure avoidance are also \\nconsidered. It is possible to use ASIL decomposition as defined in ISO 26262-9:2018, Clause 5, provided \\nthat it can be shown that there are redundant and independent requirements, and the methods for \\nsystematic failure avoidance and control for the integrated IP are taken into account.\\n \\n10 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nAn SEooC is developed based on assumptions of the intended functionality and use context which \\nincludes external interfaces. These assumptions are set up in a way that addresses a superset of \\ncomponents into which the SEooC can be integrated, so that the SEooC can be used later in multiple \\ndifferent designs. The validity of these assumptions is established in the context of the actual component \\nintegrating the SEooC. In that context, IP developed as an SEooC can often be configured to target a \\nnumber of different designs. Configuration can be done before synthesis, after synthesis, or by fuse, \\nlaser cut, flash, or any other programming. In that case, the IP supplier provides information on the IP \\nconfigurations which have been covered by testing and verification activities.\\nEXAMPLE \\nConfiguration options to determine bus width for interconnects, internal cache memory sizes, \\nnumber of interrupts, memory maps.\\nNOTE 1 \\nIP configuration differs from configuration data for software: therefore ISO 26262-6:2018, Annex C is \\nnot directly applicable to IPs.\\nNOTE 2 \\nThe IP integrator performs the necessary verification activities to guarantee the correctness of \\nthe generated IP; the necessary work products, as listed in following clauses, are made available; and the IP \\nintegrator verifies the correct integration of the IP in its context.\\n4.5.3.3 \\nIP designed in context\\nWhen developing IP in context, the IP supplier tailors the safety activities as described in \\nISO 26262-2:2018, 6.4.5.1. For in context designs, the IP supplier can develop the IP with knowledge of \\nthe safety requirements.\\nEXAMPLE \\nAn analogue component designed in context of a specific safety requirement at the system level.\\n4.5.3.4 \\nIP use through evaluation of hardware element\\nIn cases where no SEooC or in-context information is available for the IP, evaluation of hardware \\nelements as described in ISO 26262-8:2018, Clause 13 can be used to increase confidence in the IP. \\nActivities foreseen for the evaluation of hardware elements can be applied to IP without pre-existing \\nsupporting information available (as described in 4.5.5).\\n4.5.3.5 \\nIP use through the \\xe2\\x80\\x9cproven in use\\xe2\\x80\\x9d argument\\nIf the evidence for systematic faults avoidance is not available, the \\xe2\\x80\\x9cproven in use\\xe2\\x80\\x9d argument as \\ndescribed in ISO 26262-8:2018, Clause 14 can provide a means for the IP integrator to demonstrate \\ncompliance with ISO 26262.\\nThe conditions surrounding the validity of the \\xe2\\x80\\x9cproven in use\\xe2\\x80\\x9d argument can be restricting. Ensuring \\nthat an effective field monitoring program described in ISO 26262-8:2018, 14.4.5.3 is in place can \\nbe challenging due to the typically limited field feedback from designs incorporating IP or due to \\ndifferences in IP configuration.\\n4.5.4 \\nWork products for IP\\n4.5.4.1 \\nList of work products for IP\\nExample work products are described in 5.1.11 (for digital components), 5.2.6 (for analogue or mixed \\nsignal components), 5.3.6 (for PLD) and 5.5.6 (for Sensors and Transducers). The following gives \\nguidance on contents of work products which can be provided for IP designs in general.\\nNOTE \\nThe DIA (see ISO 26262-8:2018, Clause 5) can be used to specify which documents are made available \\nto the IP integrator and what level of detail is included.\\n4.5.4.2 \\nSafety plan\\nFor IP with one or more allocated safety requirements, the safety plan is developed based on the \\nrequirements in ISO 26262-2:2018, 6.4.6. A single plan or multiple related plans can be used. Detailed \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n11\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nplans are included for applicable supporting processes as described in ISO 26262-8, covering \\nconfiguration management, change management, impact analysis and change requests, verification, \\ndocumentation management and software tool qualification.\\n4.5.4.3 \\nSafety requirements allocated to the IP design\\nThe hardware safety requirements can be allocated to the IP design as defined in ISO 26262-5:2018, \\nClause 6.\\nEXAMPLE \\nThe requirement for a safety mechanism in the IP is described, allowing the requirement \\nto be verified at an appropriate level of integration. The integration and test specifications can be linked to \\nrequirements defined in the technical safety concept.\\n4.5.4.4\\t\\nHardware\\tdesign\\tverification\\tand\\tverification\\treview\\tof\\tthe\\tIP\\tdesign\\nDefining criteria for design verification, in particular for environmental conditions (vibration, EMI, \\netc.), for an IP design which is provided in the form of logic design is not typically possible since the \\nphysical characteristics are highly dependent on the physical implementation of the design by the IP \\nintegrator.\\nNOTE \\nFor IP provided as a digital logical design, hardware design verification can be done using the \\ntechniques listed in 5.1.9.\\nA verification report includes results of the activities used to verify the IP design. Verification can \\nbe done as described in ISO 26262-8:2018, Clause 9, including planning, execution and evaluation of \\nverification activities.\\n4.5.4.5 \\nSafety analysis report\\nThe requirements for safety analysis in ISO 26262-9:2018, Clause 8 are applicable for IP designs. The \\nselection of appropriate safety analysis methods is based on ISO 26262-5:2018, Table 2.\\nFor qualitative analysis, the supplier provides the identified failure modes of the IP in order to support \\nits integration.\\nFor quantitative analysis, the data included supports the evaluation of hardware architectural \\nmetrics and evaluation of safety goal violations due to random hardware faults, as specified in \\nISO 26262-9:2018, 8.4.10.\\nEXAMPLE \\nData includes estimated failure rate and failure mode distribution information.\\nNOTE 1 \\nFor IP provided as logical design, such as Register Transfer Level (RTL), quantitative analysis relies \\non assumptions about failure rates and failure mode distributions, and can therefore not be representative of \\nactual physical designs. The IP integrator verifies the assumptions and quantitative safety analysis results for \\nthe specific implementation.\\nNOTE 2 \\nIn estimating the metrics, safety mechanisms embedded in the IP and their expected failure mode \\ncoverage (at a level that is applicable to the given IP) can be considered.\\nIn the case of configurable IP, the safety analyses can include information about the impact of \\nconfiguration options on the failure modes distribution.\\nNOTE 3 \\nAn analysis of the impact of configuration options on the implementation and diagnostic coverage of \\nsafety mechanisms is performed.\\nAdditional safety mechanisms realized by a combination of features internal and external to the IP, \\nas well as safety mechanisms implemented outside the IP can be defined. These additional safety \\nmechanisms can rely on assumptions of use for the SEooC design, which can be validated at the \\nappropriate level as described in ISO 26262-2:2018, 6.4.5.7.\\n \\n12 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n4.5.4.6 \\nAnalysis of dependent failures\\nDependent failure analysis for IP can be performed as described in ISO 26262-9:2018, Clause 7. \\nAdditional guidance on how to apply dependent failure analysis for semiconductor devices is included \\nin 4.7 of this document.\\n4.5.4.7\\t\\nConfirmation\\tmeasures\\nResults from conducted confirmation measures include evidence and arguments related to the IP \\ndevelopment process and about avoidance of systematic faults. Confirmation measures are described in \\nISO 26262-2:2018, Table 1. For semiconductor IP typical confirmation measure reports include:\\n\\xe2\\x80\\x95 \\nconfirmation review of the safety plan;\\n\\xe2\\x80\\x95 \\nconfirmation review of the safety analyses;\\n\\xe2\\x80\\x95 \\nconfirmation review of the completeness of the safety case; and\\n\\xe2\\x80\\x95 \\nfunctional safety audit and assessment reports.\\nExamples of techniques applicable to IP development activities for systematic fault avoidance are \\nincluded in 5.1.9 (for digital components), 5.2.5 (for analogue or mixed-signal components), 5.3.5.3 (for \\nPLD) and 5.5.5 (for Sensors and Transducers).\\n4.5.4.8 \\nDevelopment interface agreement\\nThe requirements for distributed development in ISO 26262-8:2018, Clause 5 are applicable to IP \\ndesigns. The DIA defines the exchanged work products for IP designs, and the roles and responsibilities \\nfor safety between the IP supplier and the IP integrator.\\n4.5.4.9 \\nIntegration documentation set\\nAn integration documentation set can include a safety manual or safety application note for IP developed \\nas an SEooC. The integration documentation set can also include the following information:\\n\\xe2\\x80\\x95 \\ndescription of the tailoring of the lifecycle for the IP development;\\n\\xe2\\x80\\x95 \\nassumptions of use for the IP, including for example:\\n\\xe2\\x80\\x95 \\nassumed safe states of the IP;\\n\\xe2\\x80\\x95 \\nassumptions on maximum fault handling time interval and Multiple Point Fault Detection \\nInterval (MPFDI), as applicable;\\n\\xe2\\x80\\x95 \\nassumptions on the integration environment for the IP, including interfaces; and\\n\\xe2\\x80\\x95 \\nrecommended IP configurations.\\n\\xe2\\x80\\x95 \\ndescription of the safety architecture, including:\\n\\xe2\\x80\\x95 \\nfault detection and control mechanisms;\\n\\xe2\\x80\\x95 \\nfault reporting capabilities;\\n\\xe2\\x80\\x95 \\nself-test capabilities and additional requirements for self-testing for potential latent faults, if \\napplicable;\\n\\xe2\\x80\\x95 \\nfault recovery mechanisms, if applicable; and\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n13\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b\" \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nimpact of configuration parameters on the above items if applicable.\\n\\xe2\\x80\\x95 \\nhardware-software interfaces required to support the IP safety mechanisms, and to control \\nfailures after detection;\\n\\xe2\\x80\\x95 \\nspecification of software-based test routines to detect faults of the IP component, if applicable. This \\ncould also be provided as source code or binary library;\\n\\xe2\\x80\\x95 \\ndescription of safety analysis results for the IP; and\\n\\xe2\\x80\\x95 \\ndescription of confirmation measures used for the IP.\\nIt is possible for the IP integrator to formally identify each hardware feature related to the safety \\nmechanisms so that a mapping with hardware safety requirements at the level of the IP integrator can \\nbe done, and the integration verification and validation activities that are the responsibility of the IP \\nintegrator can be identified.\\nNOTE 1 \\nThe IP safety mechanism requirements are specified in a way which allows them to be traceable to IP \\nintegrator\\xe2\\x80\\x99s requirements.\\nNOTE 2 \\nFor IP with no specific features for fault detection, providing the assumptions of use can be sufficient \\nto comply with the IP integrator\\xe2\\x80\\x99s requirements.\\nFor IP developed in-context, similar documentation is typically provided.\\nNOTE 3 \\nFor in-context IP, assumptions of use are not required, as the IP is designed with full context \\ninformation in place.\\n4.5.4.10 Applicability of work products to IP categories\\nThe applicability of the work products described in 4.5.4.1 to 4.5.4.9 depends on the classification of the \\nIP as described in 4.5.2. For intellectual properties without integrated safety mechanisms:\\n\\xe2\\x80\\x95 \\nthe safety analysis report is limited to the failure modes distribution of the IP. There is no estimation \\nof the hardware metrics because there are no integrated safety mechanisms. The failure mode \\ndistribution is needed to enable the IP integrator to perform safety analyses at the integration level;\\n\\xe2\\x80\\x95 \\nthe integration documentation set (not a specific work product but rather a collection of information \\nas described in 4.5.4.9) is limited to the description of the assumptions on the integration \\nenvironment for the IP, including interfaces;\\n\\xe2\\x80\\x95 \\nit does not typically include the analysis of dependent failures.\\n4.5.5 \\nIntegration of black-box IP\\nIn some developments the IP integrator can encounter a situation where it is necessary to integrate \\nan IP of which the contents are not fully disclosed. The IP to be integrated is a \\xe2\\x80\\x9cblack box\\xe2\\x80\\x9d from the \\nperspective of the IP integrator.\\nEXAMPLE 1 \\nIP integrator's customer requires use of their proprietary logic, such as a specific communications \\ninterface, timer peripheral, or similar logic.\\nEXAMPLE 2 \\nIP integrator is asked to integrate logic from a competitor, in order to facilitate a multi-source \\nsupply agreement.\\nBlack box IP can be integrated in many forms, including but not limited to:\\n\\xe2\\x80\\x95 \\npre-hardened, or handed off as a gate level layout or transistor level;\\n\\xe2\\x80\\x95 \\nas encrypted netlist, which cannot be meaningfully parsed except by trusted tools; and\\n\\xe2\\x80\\x95 \\nas obfuscated RTL source (where meaningful variable names are replaced with randomized \\ncharacter strings and any explanatory comments are removed).\\n \\n14 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n\"\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 1 \\nA black box integration approach can also be applied to cases in which no information is available \\nfrom the IP supplier.\\nWhen black box IP is integrated, the division of responsibility between IP supplier, IP integrator and \\nthe IP integrator\\xe2\\x80\\x99s customer can be defined through a development interface agreement as described in \\nISO 26262-8:2018, Clause 5.\\nEXAMPLE 3 \\nIn cases where the IP integrator is required to use black box IP, for example because of a \\nrequirement from their customer, the DIA can specify that it is the customer responsibility to evaluate and accept \\nthe suitability for the use of the black box IP in a safety-related context.\\nThe development interface agreement can also include details about the tailoring of the safety activities \\nas described in ISO 26262-2:2018, 6.4.5.7 and the exchange of documentation across the supply chain.\\nEXAMPLE 4 \\nA development interface agreement can specify that integration details are provided by the IP \\nsupplier in the form of an integration guide which also contains a set of validation tests. These tests can be used \\nto confirm proper integration.\\nUnless the IP has been developed specifically targeting the automotive market, it is possible that \\nspecific evidence is not available. In this case the responsibility for the acceptance of available evidence \\ncan be defined in the development interface agreement.\\nEXAMPLE 5 \\nIP developed according to other functional safety standards such as IEC 61508:2010 [14].\\nNOTE 2 \\nIn this case information on the development lifecycle and associated processes used to develop the \\nIP can be used to perform a gap analysis to evaluate the suitability of the IP for use in the context of ISO 26262 \\nseries of standards.\\nThe IP integrator does not always have enough data to evaluate the base failure rate of a black box \\nIP. Since this can affect the results of quantitative analysis, the development interface agreement can \\nspecify the responsibilities between the IP supplier, IP integrator and the IP integrator\\xe2\\x80\\x99s customer for \\nthe estimation of the base failure rate. The responsibilities for safety analysis of the black box IP can be \\ndefined in a similar way.\\nNOTE 3 \\nThe integration of black box IP into a hardware development has parallels in software development, \\nsuch as the case in which a developer integrates unit software from a third-party supplier as compiled object \\ncode. As such, the integrator of black box IP into a hardware development can find methods and techniques in \\n5.1.9.1 including the link with applicable tables of ISO 26262-6.\\nIn cases where the black box IP requires safety mechanisms, the IP integrator could not have enough \\ninformation to implement the safety mechanism outside of the IP. The development interface agreement \\nspecifies requirements for such safety mechanism in these cases.\\n4.6 Base failure rate for semiconductors\\n4.6.1 \\nGeneral notes on base failure rate estimation\\n4.6.1.1 \\nIntroduction\\nThe scope of this sub-clause is to give clarifications, guidelines and examples on how to calculate and \\nuse the base (or raw) failure rate. Base failure rate is a primary input for calculation of the quantitative \\nsafety analyses and metrics according to ISO 26262-5.\\nNOTE \\nQuantitative safety analysis in ISO 26262-5 focuses on random hardware failures and excludes \\nsystematic failures. Therefore the base failure rate used in the context of ISO 26262 series of standards focuses \\non random hardware failures only. See also 4.6.1.3.\\nEach technique available for base failure rate estimation makes assumptions about the failure \\nmechanisms to be considered. Differences in results obtained from different base failure rate estimation \\ntechniques are often due to a lack of consideration for the same set of failure mechanisms. Results from \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n15\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nthe use of different techniques applied to the same component are unlikely to be comparable without \\nharmonization on a common set of failure mechanisms.\\nEXAMPLE 1 \\nHarmonization can be done, for instance, by considering the same failure mechanisms and the \\nsame source of stresses.\\nFailure mechanisms for semiconductors are dependent on circuitry type, implementation technology, \\nand environmental factors. As semiconductor technology is rapidly evolving, it is difficult for published \\nrecognized industry sources for failure rates to keep pace with the state of the art, particularly for deep \\nsubmicron process technologies. Because of this, it is helpful to consider the publications of industry \\ngroups such as JEDEC (Joint Electron Device Engineering Council), International Roadmap for Devices \\nand Systems (IRDS), and the SEMATECH/ISMI Reliability Council to get a broad view of semiconductor \\nstate of the art.\\nEXAMPLE 2 \\nJEDEC publishes several documents which can be helpful in providing references to understand \\nspecific failure mechanisms and estimate failure rates:\\n\\xe2\\x80\\x95 \\nReference [16] summarises many different well understood and industry accepted failure mechanisms for \\nsilicon and packaging; it can also be used to provide a physics of failure mode for estimation of failure rates \\nfor the identified failure mechanisms;\\n\\xe2\\x80\\x95 \\nReference [53] provides guidance on developing a reliability evaluation methodology based on an \\napplication-specific use model (mission profile); and\\n\\xe2\\x80\\x95 \\nReference [17] summarises a number of transient fault mechanisms related to exposure to naturally \\noccurring radiation sources and provides guidance on how to experimentally derive failure rates for \\nsusceptibility to soft error.\\n4.6.1.2 \\nQuantitative target values and reliability prediction\\nQuantitative target values for the maximum probability of the violation of each safety goal at item \\nlevel due to random hardware failures (PMHF) are sometimes misunderstood as inputs for reliability \\nprediction. As stated in ISO 26262-5:2018, 9.4.2.2, NOTE 1, these quantitative target values do not \\nhave an absolute significance but are useful for comparing a new design with existing ones. They are \\nintended to make available design guidance and to make available evidence that the design complies \\nwith the safety goals. Therefore those values cannot be used \\xe2\\x80\\x9cas is\\xe2\\x80\\x9d in reliability prediction.\\n4.6.1.3 \\nDifference between systematic and random failures\\nISO 26262 series of standards makes a distinction between systematic and random failures. Most \\navailable techniques for base failure rate estimation are intended to provide reliability estimates \\nand make no such distinction. The result of such techniques can be excessively conservative due to \\ninclusion of factors which estimate systematic failures. For example, estimation techniques based on \\nobservations of field failures do not, in general, have appropriate sample size or observation quality \\nto differentiate between systematic and random failures. Similarly, models which include systematic \\ncapability as part of the base failure rate calculation can be challenging to use in the context of \\nISO 26262 series of standards (e.g. \\xcf\\x80pm and \\xcf\\x80process factors defined in Reference [9]).\\n4.6.1.4 \\nEffect of failure recovery mechanisms\\nA concern is the handling of diagnostics which can be used to enhance availability. This can lead to a \\nmix of base failure rate with diagnostics while the ISO 26262-5 requires separating them for the metrics \\ncomputation.\\nEXAMPLE \\nConsider a common SEC-DED (Single Error Correct-Dual Error Detect) ECC used in many state \\nof the art automotive functional safety electronics. A reported MTTF (mean time to failure) for an SRAM with \\nSEC-DED ECC cannot consider a fault which results in a correctable error \\xe2\\x80\\x94 thus mixing effects of base failure \\nrate and diagnostics, which is separated for calculation of ISO 26262-5 metrics.\\n \\n16 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b' \\nISO 26262-11:2018(E)\\n4.6.1.5 \\nConsiderations about non-constant failure rates\\nMany standardised models make use of a \\xe2\\x80\\x9cbathtub curve\\xe2\\x80\\x9d simplification, which assumes that \\xe2\\x80\\x9cearly life\\xe2\\x80\\x9d \\n(infant mortality) defects have been effectively screened by the supplier and that \\xe2\\x80\\x9cwear out\\xe2\\x80\\x9d (end-of-\\nlife) failure mechanisms, such as electro-migration, time-dependent dielectric breakdown, hot carriers, \\nor negative bias temperature instability will effectively occur at negligible rates during useful mission \\nlifetime.\\nIn some cases, the failure rate distribution from reliability models does not fit the constant failure \\nrate of the \"bathtub curve\" simplification. Using a non-constant failure rate is not compatible with the \\ncomputation of hardware architectural metrics as described in ISO 26262-5.\\nOne possibility is to simplify non-constant failure rate distributions by using approximations of \\nconstant failure rate.\\nEXAMPLE 1 \\nA constant failure rate is conservatively assumed at the maximum failure rate of the reliability \\nmodel failure rate distribution.\\nEXAMPLE 2 \\nDepending on the distribution, it can be possible to limit the operating lifespan of the product \\nsuch that a constant failure rate approximation is more appropriate. This case often applies when an end-of-life \\nmechanism becomes dominant in the overall failure rate distribution.\\nNOTE 1 \\nIf an exponential model is used, reaching the end of the bathtub within the product lifetime is a \\nsystematic issue when failure rate targets are exceeded. If this is acceptable or not is not evaluated within the \\nhardware metrics of ISO 26262-5:2018 Clause 8 and Clause 9. This is evaluated separately, for example based on \\nthe results of the qualification of an integrated circuit according to AEC-Q100 [62].\\nFigure 8 \\xe2\\x80\\x94 Bathtub curve \\xe2\\x80\\x94 Evolution of failure rate over time\\nNOTE 2 \\nIn Figure 8, the real bath tub curve can be approximated by the \\xe2\\x80\\x98Constant value during the useful life \\nof the product\\xe2\\x80\\x99 or calculated by the exponential model with the confidence level of 70 %.\\nIf the overall failure rate distribution is a result of integrating multiple fault models, separation of \\nfailure modes can result in the ability to simplify safety analysis by evaluating the impact of each failure \\nmode separately using different (but constant) failure rate approximations, as recommended in 5.1.7.2 \\nfor consideration of transient faults.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n17\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n4.6.1.6 \\nTechniques and sources for base failure rate estimation\\nThere are many different techniques which can be utilised for base failure rate estimation. In general \\nthese techniques can be summarised as follows:\\n\\xe2\\x80\\x94 failure rates derived from experimental testing, such as:\\n\\xe2\\x80\\x94 temperature, bias and operating life test (TBOL), also known as High Temp Operational Life \\n(HTOL) testing or extended life test (ELT) for intrinsic product operating reliability,\\n\\xe2\\x80\\x94 reliability test chip and/or on-chip test structures to assess intrinsic reliability of the silicon \\ntechnology,\\n\\xe2\\x80\\x94 soft error testing based on exposure to radiation sources, or\\nNOTE 1 \\nJEDEC standards such as JESD89 [17] give guidance for soft error testing.\\n\\xe2\\x80\\x94 convergence characteristic of acceleration test for screening.\\n\\xe2\\x80\\x95 \\nfailure rates derived from observation of field incidents, such as analysis of material returned as \\nfield failures;\\nNOTE 2 \\nFor permanent faults: data provided by semiconductor industries can be based on the number of \\n(random) failures divided by equivalent device hours. These are obtained from field data or from accelerated \\nlife testing (as defined in standards such as JEDEC and AEC) scaled to a mission profile (e.g. temperature, on/\\noff periods) with the assumption of a constant failure rate (random failures, exponential distribution). The \\nnumbers can be used as inputs for the estimation of the failure rate, provided as a maximum failure rate \\nbased on a sampling statistics confidence level.\\n\\xe2\\x80\\x95 \\nfailure rates estimated by application of industry reliability data books or derived from them and \\ncombined with expert judgment;\\nEXAMPLE 1 \\nIEC 61709 [15], SN 29500 [38] or FIDES Guide [9].\\nEXAMPLE 2 \\nModel for reliability prediction of electronics components (former IEC TR 62380) as \\ndescribed in 4.6.2.1.1.\\nNOTE 3 \\nThe actual failure rate achieved is expected to be lower than the failure rate derived from those \\nmethods.\\nEXAMPLE 3 \\nReliability estimations via physics of failure methods as in ISO 26262-5:2018, 8.4.3, Notes \\n6 and 7.\\n\\xe2\\x80\\x95 \\nThe documents maintained by the International Roadmap for Devices and Systems (IRDS) such as \\nthe International Technology Roadmap for Semiconductor (ITRS [41]) provide projected values for \\nthe soft error rate for each generation so that this information is useful for a first estimation and \\nrefined when technology data is available.\\n4.6.1.7 \\nDocumentation on the assumptions for base failure rate calculation\\nWhen calculating the base failure rate the supplier provides documentation describing the assumptions \\nmade and supporting rationale.\\nEXAMPLE \\nAssumptions can be:\\n\\xe2\\x80\\x95 \\nthe selected method to calculate the failure rate (e.g. industry source or field data),\\n\\xe2\\x80\\x95 \\nthe assumed mission profile,\\n\\xe2\\x80\\x95 \\nthe confidence level of the used failure rate data (e.g. in case of field data or testing based data),\\n\\xe2\\x80\\x95 \\nany scaling or de-rating applied to the failure rate data,\\n\\xe2\\x80\\x95 \\nhow the non-operating time and solder joint were taken into account, or\\n \\n18 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nthe model used for failure rate derived from field data (Weibull or exponential models).\\nThis information can be used by the integrator at element or item level to evaluate, understand, judge, \\ncompare and possibly harmonize failure rates from different suppliers and components.\\n4.6.1.8\\t\\nTransient\\tfault\\tquantification\\nAs described in 5.1.2, soft errors are a typical example of transient faults.\\nTransient faults caused by soft errors initiated by internal or external \\xce\\xb1, \\xce\\xb2, neutron, or \\xce\\xb3 radiation \\nsources are random hardware failures that can be quantified with a probabilistic method supported by \\nmeasured data.\\nTransient faults caused by EMI or cross-talk are not quantified. Even if they can lead to the same effects \\nas other transient faults, they are mostly related to systematic causes. These can be avoided with \\nproper techniques and methods during the design phase (e.g. cross-talk analysis during component \\ndevelopment back-end).\\nISO 26262-5:2018, 8.4.7, NOTE 2 specifies that transient faults are considered when shown to be \\nrelevant due, for instance, to the technology used. Therefore, depending on the impact of the faults and \\nwhen applicable, they can be considered in the safety analysis. The analysis for transient faults and \\npermanent faults is done separately. This holds for qualitative or quantitative analysis.\\nEach elementary subpart type (e.g. flip flops, latches, memory elements, analogue devices) is \\ninvestigated if it is susceptible to soft errors, specifically with respect to direct or induced alpha \\nparticles and neutrons. The susceptibility to those phenomena depends on the semiconductor front end \\ntechnology and the materials on top of the die\\xe2\\x80\\x99s surface including the package, e.g. the mould compound \\nand the solder material (flip chip) can influence the soft error rate.\\nEXAMPLE 1 \\nBase failure rate for alpha particles can be influenced by the type of package, e.g. low alpha (LA) \\nor ultra-low alpha (ULA) emitting semiconductor assembly materials.\\nDepending on factors such as the technology and on the operating frequency, transient fault models like \\nsingle event upset (SEU), multiple-bit upset (MBU) and single event transient (SET) are considered as in \\nReferences [2] and [22].\\nNOTE 1 \\nDestructive single event effects like Single Event Latch-up (SEL), Single Event Burnout (SEB), and \\nSingle Event Gate Rupture (SEGR) are not considered as transient faults because these faults lead to permanent \\neffects.\\nNOTE 2 \\nSee 5.1.2 for more details on digital fault models.\\nJESD89 [17] is considered as the main reference related to measurement and reporting of alpha particle \\nand terrestrial cosmic ray-induced soft errors in semiconductors. In that context, the base failure rate \\nfor soft errors is provided together with the conditions in which it has been computed or measured.\\nNOTE 3 \\nConditions such as neutron particle flux, altitude, temperature, and supply voltage are relevant to \\ntransient failure rate estimation of soft errors. JESD89 [17] is used to understand those conditions.\\nISO 26262-5:2018, 8.4.3, NOTE 2 states that in applying a selected industry source the following \\nconsiderations are appropriate to avoid artificial reduction of the calculated base failure rate: mission \\nprofile, the applicability of the failure modes with respect to the operating conditions, or the failure \\nrate unit (per operating hour or per calendar hour).\\nEXAMPLE 2 \\nIn case of soft errors, reducing the base failure rate by only considering the operating time of the \\nvehicle leads to an excessive and therefore artificial reduction of the average probability per hour.\\nNOTE 4 \\nIf the semiconductor provider delivers a de-rated soft error rate, information about the de-rating \\nfactor is made available for example in the Safety Manual as defined in 5.1.11 (for digital components), 5.2.6 (for \\nanalogue or mixed signal components), 5.3.6 (for PLD) and 5.5.6 (for Sensors and Transducers).\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n19\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nMoreover, the base failure rate for soft errors is provided without de-rating it with respect to \\n\\xe2\\x80\\x9carchitectural vulnerability factors\\xe2\\x80\\x9d or the effect of safety mechanisms such as ECC.\\nNOTE 5 \\nArchitectural vulnerability factor (AVF) is the probability that a fault in a design structure will \\nresult in a visible error in the final output of the function as, for example, described for processor designs in \\nReference[25].\\nNOTE 6 \\nVulnerability factors are taken into account when considering the number of safe faults, as described \\nin 5.1.7.2.\\n4.6.1.9 \\nNotes on component package failure rate\\nIn the estimation of a hardware component failure rate, the semiconductor providers consider the \\nfailures relating to the silicon die, to the enclosure/encapsulation (e.g. case) and to the connection \\npoints (e.g. pins). The connections between the connection points to the board (e.g. solder joints) are \\nconsidered as board failures and are typically considered by the system integrator during the safety \\nanalysis at the system or element level.\\nNOTE 1 \\nAccording to Reference [59], the package failure rate \\xce\\xbbpackage as calculated in the model described \\nin Figure 9 corresponds to the fault models inside of the package itself (including e.g. the connection between \\nthe die and the lead frame) but it also includes the failure rate related to the connection between the package \\nconnection points and the board (solder joints).\\nNOTE 2 \\nThe failure rate of the hardware component calculated in SN 29500-2 includes the fault models related \\nto the die and to the package however unlike the model described in 4.6.2.1.1 it does not include the failure rate of \\nthe connection between the package connection points and the board which is treated separately in SN 29500-5.\\nNOTE 3 \\nFIDES Guide provides separate failure rates for package (cases) and solder joints due to thermal \\ncycling.\\nNOTE 4 \\nIn reality, the failure rate of the connection between the package connection points and the board \\nis dependent on many factors involving the specific design of the circuit board and how the board is packaged \\ninside of a protective housing. These factors are constantly changing as both electronic components and circuit \\nboard material technologies rapidly evolve.\\n4.6.1.10 Consideration of power-up time and power-down time\\nAccording to ISO 26262-5:2018, 8.4.3, NOTE 2, in applying a selected industry source the following \\nconsiderations are appropriate to avoid artificial reduction of the calculated base failure rate:\\n\\xe2\\x80\\x95 \\nmission profile;\\n\\xe2\\x80\\x95 \\nthe applicability of the failure modes with respect to the operating conditions; and\\n\\xe2\\x80\\x95 \\nthe failure rate unit (per operating hour or per calendar hour).\\nThe base failure rate is provided along with the mission profile used. If the power-up and power-down \\ntimes are defined in the mission profile then they can be considered for the computation of stress \\nfactors as described by the method described in 4.6.2.1.1 (\\xcf\\x84on and \\xcf\\x84off) and in SN 29500 (\\xcf\\x80w).\\n4.6.2 \\nPermanent base failure rate calculation methods\\n4.6.2.1 \\nPermanent base failure rate calculation using or based on industry sources\\n4.6.2.1.1 \\nModel for reliability prediction of electronics components (former IEC TR 62380)\\nThe former IEC TR 62380 [40] is used in this document as the basis for a model for reliability prediction \\nof electronics components.\\nThe mathematical model used in this sub-clause is described in Figure 9.\\n \\n20 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 9 \\xe2\\x80\\x94 Mathematical model for reliability prediction\\nIn the model described in Figure 9, several parameters are used to determine the failure rate:\\n\\xe2\\x80\\x95 \\na parameter per transistor per type of technology used (\\xce\\xbb1). A \\xce\\xbb1 value is provided for different \\ntypes of integrated circuit families as shown in Figure 10;\\n\\xe2\\x80\\x95 \\na parameter related to the mastering of the technology and valid for the whole component \\nregardless the number of integrated elements (\\xce\\xbb2), as shown in Figure 10;\\n\\xe2\\x80\\x95 \\na parameter related to the number of transistors of the hardware component (N);\\n\\xe2\\x80\\x95 \\na parameter related to the difference between the year of manufacturing or technology release/\\nupdate and the reference year (1998) (\\xce\\xb1);\\n\\xe2\\x80\\x95 \\na parameter related to the operating and non-operating phases seen by the hardware component \\n(\\xcf\\x84i, \\xcf\\x84on and \\xcf\\x84off);\\n\\xe2\\x80\\x95 \\na parameter related to a temperature stress factor [(\\xcf\\x80t)i] applicable to the die part of the component;\\n\\xe2\\x80\\x95 \\nparameters related to the possible exposure of the integrated circuit to electrical overstress (\\xcf\\x80l \\nand \\xce\\xbbEOS) as shown in Figure 11;\\n\\xe2\\x80\\x95 \\na parameter related to the number and the amplitude of the temperature cycling seen by the \\nhardware component (ni and \\xce\\x94Ti) as shown in Figure 11;\\n\\xe2\\x80\\x95 \\na parameter related to the mismatch between the thermal coefficients of the board and the package \\nmaterial (\\xce\\xb1S and \\xce\\xb1C), as shown in Figure 11 and Figure 12; and\\n\\xe2\\x80\\x95 \\na parameter related to the package (\\xce\\xbb3), either as a function of type of the package and its pin \\nnumber S (as shown in Figure 14) or as a function of the package diagonal D for surface mounted \\nintegrated circuits packages (as shown in Figure 15).\\nSelection of parameters can be done based on the process technology and type of circuitry utilised by \\nthe design.\\nNOTE 1 \\nIn Figure 10, the \\xe2\\x80\\x9cactual number\\xe2\\x80\\x9d corresponds to the real number of transistors regardless the sizes \\nof those transistors.\\nNOTE 2 \\nTo calculate the digital component die failure rate for the whole device, the number of equivalent \\ngates is used. The number of effective equivalent transistors is computed by multiplying the equivalent gate \\ncount by the representative number of transistors per gate. When calculating the microcontroller die failure rate \\ndue to Complementary Metal Oxide Semiconductor (CMOS) digital logic, the contribution of each digital logic of \\nthe modules (e.g. CPU, CAN, Timer, FlexRay, Serial Peripheral Interface or \\xe2\\x80\\x9cSPI\\xe2\\x80\\x9d) is included in N.\\nNOTE 3 \\nThe process maturity de-rating factor was introduced considering Moore\\xe2\\x80\\x99s law and the fact that \\ndevice failure rates are more or less constant. If the failure rate per transistor would have stayed the same, the \\nfailure rate would have increased according to Moore\\xe2\\x80\\x99s law. This was not observed. Therefore, the transistor \\nfailure cannot stay constant when changing process nodes. One option is to use the manufacturing date. Another \\noption, to reflect process technology changes, the year of first introduction of this particular technology node \\ncan be used instead of its year of manufacturing. To achieve independence from the silicon vendor, the year from \\nthe ITRS[41] can be used.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n21\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 4 \\nFor analogue parts or for the digital component built primarily on analogue process technologies, \\nthe \"Linear Circuits\" entry of Figure 10 can be used, unless more precise data are provided by the \\nsemiconductor vendor.\\nNOTE 5 \\nIf supported by adequate justification, data specific to the technology under consideration can be used \\nin replacement of the parameters described above to achieve a more accurate estimation of base failure rate.\\nFigure 10 \\xe2\\x80\\x94 Values of \\xce\\xbb1 and \\xce\\xbb2 for integrated circuits families\\n \\n22 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 11 \\xe2\\x80\\x94 Temperature and overstress factors\\nFigure\\t12\\t\\xe2\\x80\\x94\\tThermal\\texpansion\\tcoefficients\\t\\xce\\xb1s and \\xce\\xb1c\\nFigure 13 \\xe2\\x80\\x94 Climates\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n23\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 14 \\xe2\\x80\\x94 \\xce\\xbb3 values for integrated circuits as a function of S\\n \\n24 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 15 \\xe2\\x80\\x94 \\xce\\xbb3 values for surface mounted integrated circuits packages\\nOnce the base FIT rate of the component die has been generated, a de-rating factor is applied based on \\nthermal effects and operating time. The de-rating factor is determined based on:\\n\\xe2\\x80\\x95 \\njunction temperature of the component die, which is calculated based on:\\n\\xe2\\x80\\x95 \\npower consumption of the component die; and\\n\\xe2\\x80\\x95 \\npackage thermal resistance, based on package type, number of package pins and airflow;\\n\\xe2\\x80\\x95 \\nan application profile which defines 1 to Y usage phases, each of which is composed of an application \\n\\xe2\\x80\\x9con-time\\xe2\\x80\\x9d as a percentage of total device lifetime, and an ambient temperature; and\\nEXAMPLE \\nTwo examples for possible automotive profiles: \\xe2\\x80\\x9cmotor control\\xe2\\x80\\x9d and \\xe2\\x80\\x9cpassenger \\ncompartment\\xe2\\x80\\x9d as shown in Figure 16.\\n \\nFigure\\t16\\t\\xe2\\x80\\x94\\tExamples\\tof\\tmission\\tprofiles\\tfor\\tautomotive\\n\\xe2\\x80\\x95 \\nactivation energy and frequency per technology type to complete the Arrhenius equation.\\nNOTE 6 \\nData specific to the product under consideration, such as package thermal characteristics, \\nmanufacturing process, Arrhenius equation, etc., could be used in replacement of the general factors \\ndescribed above to achieve a more accurate estimation of base failure rate.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n25\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n4.6.2.1.1.1 \\nHow to combine \\xce\\xbb1 and \\xce\\xbb2\\nWith respect to the method described in Figure 9, multiple options exist about how to combine \\xce\\xbb1 and \\n\\xce\\xbb2 in the case of circuit elements with different technologies (CPU, memories, etc.) implemented in the \\nsame device.\\nIn one option, each circuit element inherits the \\xce\\xbb1 and \\xce\\xbb2 of the respective technologies, so basically the \\n\\xce\\xbb1 and \\xce\\xbb2 are summed \\xe2\\x80\\x94 as shown in Table 2.\\nNOTE \\nThe \\xce\\xbb2 values are weighted, for example with the transistor counts of the individual circuit elements \\nas shown in the Equation (1).\\n\\xce\\xbb\\n\\xce\\xbb\\n\\xce\\xbb\\ndie\\n1,element\\nelement\\n-0,35\\nelement\\ntotal\\n=\\n\\xc3\\x97\\n\\xc3\\x97\\n+\\n\\xc3\\x97\\n\\xc3\\x97\\nN\\ne\\nN\\nN\\na\\nelemen\\n2,\\nt\\nt\\ni\\ny\\ni\\ni\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xc3\\x97\\n(\\n) \\xc3\\x97\\n+\\n=\\n\\xe2\\x88\\x91\\n\\xe2\\x88\\x91\\n\\xcf\\x80\\n\\xcf\\x84\\n\\xcf\\x84\\n\\xcf\\x84\\n,element\\non\\noff\\nelements\\n1\\n (1)\\nIn this example, we assume a CMOS technology based Micro Controller Unit (MCU) which consumes \\n0,5 W power. The digital component die is packaged in a 144 pin quad flat package and cooled by natural \\nconvection. The MCU is exposed to the \\xe2\\x80\\x9cmotor control\\xe2\\x80\\x9d temperature profile. The resulting increase of the \\njunction temperature \\xce\\x94Tj is 26,27 \\xc2\\xb0C. An activation energy of 0,3 eV is assumed for the Arrhenius equation. \\nUsing the model in Figure 9, this results in a de-rating factor (i.e. the second factor of \\xce\\xbbdie) of 0,17.\\nTable 2 \\xe2\\x80\\x94 Digital component example with summed \\xce\\xbb2\\nCircuit \\nElement\\n\\xce\\xbb1 \\n(FIT)\\nN \\n(transistors)\\n\\xce\\xb1\\n\\xce\\xbb2 \\n(FIT)\\nBase \\nfailure \\nrate (FIT)\\nDe-rating \\nfor temp\\nEffective \\nfailure \\nrate (FIT)\\n50 k gate CPU\\n3,4 \\xc3\\x97 10\\xe2\\x88\\x926\\n200 000 \\n(4 transistors/gate)\\n10\\n1,7\\n1,73\\n0,17\\n0,06\\n16 kB SRAM\\n1,7 \\xc3\\x97 10\\xe2\\x88\\x927\\n786 432 \\n(6 transistors/ \\nbit for a low-power \\nconsumption SRAM)\\n10\\n8,8\\n8,80\\n0,17\\n1,18\\nDie failure rate (FIT)\\n1,25\\nAs an alternative approach, it is possible (see Table 3) to use the Equation (2) with a single (conservative) \\nmaximum \\xce\\xbb2 as representative value:\\n\\xce\\xbb\\n\\xce\\xbb\\n\\xcf\\x80\\n\\xcf\\x84\\n\\xcf\\x84\\ndie\\n1,element\\nelement\\n-0,35\\n,element\\non\\n=\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n= (\\n)\\n\\xe2\\x88\\x91\\nN\\ne\\na\\nt\\ni\\ny\\ni\\ni\\n1\\n+\\n+\\n\\xc3\\x97\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n(\\n)\\n(\\n)\\n\\xe2\\x88\\x91\\n\\xcf\\x84\\n\\xce\\xbb\\n\\xcf\\x80\\noff\\n2,element\\nelements\\n,element\\nM\\nMax\\nt\\ni\\nax\\n=\\n\\xe2\\x88\\x91\\n\\xc3\\x97\\n+\\n1\\ny\\ni\\ni\\n\\xcf\\x84\\n\\xcf\\x84\\n\\xcf\\x84\\non\\noff\\n \\n(2)\\nTable 3 \\xe2\\x80\\x94 Mixed signal example with max of \\xce\\xbb2\\nCircuit \\nElement\\n\\xce\\xbb1 \\n(FIT)\\nN \\n(transistors)\\n\\xce\\xb1\\nBase failure \\nrate without \\n\\xce\\xbb2 \\n(FIT)\\n\\xce\\xbb2 \\n(FIT)\\nDe-rat-\\ning \\nfor \\ntemp\\nEffective \\nfailure \\nrate (FIT)\\nDigital \\ncircuits\\n1,0 \\xc3\\x97 10\\xe2\\x88\\x926\\n28 000\\n10\\n8,5 \\xc3\\x97 10\\xe2\\x88\\x924\\n1,7\\n \\nLinear/digital \\ncircuits low \\nvoltage (<6 V)\\n2,7 \\xc3\\x97 10\\xe2\\x88\\x924\\n30 000\\n10\\n0,25\\n20\\nDie failure rate (FIT)\\n0,25\\nMax(20,1,7) = 20\\n0,17\\n3,44\\n \\n26 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nIn the following example the integrated circuit consists of three elements. Its composition and the \\ncorresponding \\xce\\xbb1 and \\xce\\xbb2 values from Figure 10 are shown in Table 4.\\nTable 4 \\xe2\\x80\\x94 Composition of the example IC in BiCMOS technology\\nelement 1\\nDigital circuits\\n\\xce\\xbb1 [FIT]\\n1,00 \\xc3\\x97 10\\xe2\\x88\\x926\\nN 100 000\\n\\xce\\xbb2 [FIT]\\n1,70\\nelement 2\\nLinear circuits LV\\n\\xce\\xbb1 [FIT]\\n2,70 \\xc3\\x97 10\\xe2\\x88\\x924\\nN 5 000\\n\\xce\\xbb2 [FIT]\\n20\\nelement 3\\nLinear circuits HV\\n\\xce\\xbb1 [FIT]\\n2,70 \\xc3\\x97 10\\xe2\\x88\\x923\\nN 2 000\\n\\xce\\xbb2 [FIT]\\n20\\nUsing the motor control profile (from Figure 16) as mission profile and 2018 as the manufacturing year, \\nthe \\xce\\xbb1 related term of the die failure rate is computed as in the Equations (3) to (8).\\n\\xce\\xbb1,element1\\nelement1\\n,\\n,\\n 0\\n\\xc3\\x97\\n\\xc3\\x97\\n=\\n\\xc3\\x97\\n\\xc3\\x97\\n(\\n) \\xc3\\x97\\n\\xe2\\x88\\x92\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n\\xe2\\x88\\x92\\n\\xc3\\x97\\nN\\ne\\ne\\na\\n0 35\\n6\\n0 35\\n2\\n1 0\\n10\\n100\\n00\\n,\\n018 1998\\n5\\n9 12\\n10\\n\\xe2\\x88\\x92\\n(\\n)\\n\\xe2\\x88\\x92\\n=\\n\\xc3\\x97\\n,\\n FIT \\n(3)\\n          \\xcf\\x80\\n\\xcf\\x84\\nt,element1\\n(\\n) \\xc3\\x97\\n=\\n\\xc3\\x97\\n=\\n\\xe2\\x88\\x92\\n+\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n1\\n1\\n3 480\\n1\\n328\\n1\\n273 32\\n0 020\\n8\\ne\\n,\\n,99\\n10 3\\n\\xc3\\x97\\n\\xe2\\x88\\x92  \\n(4)\\n          \\xcf\\x80\\n\\xcf\\x84\\nt,element1\\n \\n(\\n) \\xc3\\x97\\n=\\n\\xc3\\x97\\n=\\n\\xe2\\x88\\x92\\n+\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n2\\n2\\n3 480\\n1\\n328\\n1\\n273 60\\n0 015\\n1\\ne\\n,\\n,76\\n10 2\\n\\xc3\\x97\\n\\xe2\\x88\\x92  \\n(5)\\n          \\xcf\\x80\\n\\xcf\\x84\\nt,element1\\n \\n(\\n) \\xc3\\x97\\n=\\n\\xc3\\x97\\n=\\n\\xe2\\x88\\x92\\n+\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n3\\n3\\n3 480\\n1\\n328\\n1\\n273 85\\n0 023\\n5\\ne\\n,\\n,60\\n10 2\\n\\xc3\\x97\\n\\xe2\\x88\\x92  \\n(6)\\n          \\n\\xcf\\x80\\n\\xcf\\x84\\nt,element1\\n(\\n) \\xc3\\x97\\n=\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n=\\xe2\\x88\\x91\\ni\\ni\\ni\\n8 25\\n10 2\\n1\\n3\\n,\\n \\n(7)\\n\\xce\\xbb\\n\\xcf\\x80\\n\\xcf\\x84\\n1,element1\\nelement1\\n,\\n,element1\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n(\\n) \\xc3\\x97\\n=\\n\\xe2\\x88\\x92\\n\\xc3\\x97\\n=\\xe2\\x88\\x91\\nN\\ne\\na\\nt\\ni\\ni\\ni\\n0 35\\n1\\n3\\n7 53\\n,\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n10 6  FIT \\n(8)\\nAn analog calculation provides for the other elements following results:\\n          \\n\\xcf\\x80\\n\\xcf\\x84\\nt,element2\\n(\\n) \\xc3\\x97\\n=\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n=\\xe2\\x88\\x91\\ni\\ni\\ni\\n8 25\\n10 2\\n1\\n3\\n,\\n \\n(9)\\n\\xce\\xbb\\n\\xcf\\x80\\n\\xcf\\x84\\n1,element2\\nelement2\\n,\\nelement2\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\xef\\xbf\\xbd \\xc3\\x97\\n=\\n\\xe2\\x88\\x92\\n\\xc3\\x97\\n=\\xe2\\x88\\x91\\nN\\ne\\na\\nt\\ni\\ni\\ni\\n0 35\\n1\\n3\\n,\\n1 02\\n10 4\\n,\\n\\xc3\\x97\\n\\xe2\\x88\\x92  FIT \\n(10)\\n          \\n\\xcf\\x80\\n\\xcf\\x84\\nt,element3\\n(\\n) \\xc3\\x97\\n=\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n=\\xe2\\x88\\x91\\ni\\ni\\ni\\n1 01\\n10 1\\n1\\n3\\n,\\n \\n(11)\\n\\xce\\xbb\\n\\xcf\\x80\\n\\xcf\\x84\\n1,element3\\nelement3\\n,\\n,element3\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n(\\n) \\xc3\\x97\\n=\\n\\xe2\\x88\\x92\\n\\xc3\\x97\\n=\\xe2\\x88\\x91\\nN\\ne\\na\\nt\\ni\\ni\\ni\\n0 35\\n1\\n3\\n4 96\\n,\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n10 4  FIT \\n(12)\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n27\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xce\\xbb\\n\\xcf\\x80\\n\\xcf\\x84\\n1,element\\nelement\\n,\\n,element\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n(\\n) \\xc3\\x97\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xe2\\x88\\x92\\n\\xc3\\x97\\n=\\xe2\\x88\\x91\\nN\\ne\\na\\nt\\ni\\ni\\ni\\n0 35\\n1\\n3\\nelement\\n FIT \\n= 6,05 \\n \\n=\\n\\xe2\\x88\\x92\\n\\xe2\\x88\\x92\\n\\xe2\\x88\\x92\\n\\xe2\\x88\\x91\\n=\\n\\xc3\\x97\\n+\\n\\xc3\\x97\\n+\\n\\xc3\\x97\\n(\\n)\\n\\xc3\\x97\\n1\\n3\\n6\\n4\\n4\\n7 53\\n10\\n1 02\\n10\\n4 96\\n10\\n,\\n,\\n,\\n10\\nFIT\\n\\xe2\\x88\\x924\\n \\n(13)\\nFor the \\xce\\xbb2 related term of the die failure rate we get:\\nMax \\xce\\xbb\\n\\xce\\xbb\\n\\xce\\xbb\\n2,element\\n2,element\\n2,element3\\n FIT\\n(\\n) = (\\n) = (\\n) =\\n2\\n20\\n \\n(14)\\nMax\\nt\\ni\\ni\\ni\\ny\\nt\\ni\\ni\\n\\xcf\\x80\\n\\xcf\\x84\\n\\xcf\\x80\\n\\xcf\\x84\\n,element\\nelement\\n,element3\\n(\\n) \\xc3\\x97\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n=\\n(\\n) \\xc3\\x97\\n=\\n=\\xe2\\x88\\x91\\n1\\n1 01\\n10 1\\n1\\n3\\n,\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n=\\xe2\\x88\\x91\\ni\\n \\n(15)\\nMax\\nMax\\nt\\ni\\ni\\ni\\ny\\n\\xce\\xbb\\n\\xcf\\x80\\n\\xcf\\x84\\n2,element\\n,element\\nelement\\n(\\n) \\xc3\\x97\\n(\\n) \\xc3\\x97\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n\\xef\\xbf\\xbd\\n=\\n=\\xe2\\x88\\x91\\n1\\n20 \\xc3\\x97\\n\\xc3\\x97\\n=\\n\\xe2\\x88\\x92\\n1 01\\n10\\n2 01\\n1\\n,\\n,\\n FIT\\n FIT \\n(16)\\nThis results in an overall die failure rate of:\\n\\xce\\xbbdie\\n FIT\\n FIT\\n FIT\\n=\\n\\xc3\\x97\\n+\\n=\\n\\xe2\\x88\\x92\\n6 05\\n10\\n2 01\\n2 01\\n4\\n,\\n,\\n,\\n \\n(17)\\nTo simplify calculation, if the user can identify a match between its product and one of the integrated \\ncircuit family types listed in Figure 10 then \\xe2\\x80\\x94 as shown in Table 5 below \\xe2\\x80\\x94 the user can directly apply \\nthe failure rate calculation method as described in Figure 9.\\nTable 5 \\xe2\\x80\\x94 Digital component example with matching device type\\nCircuit Ele-\\nment\\n\\xce\\xbb1\\n(FIT)\\nN\\n(transistors)\\n\\xce\\xb1\\n\\xce\\xbb2\\n(FIT)\\nBase failure \\nrate (FIT)\\nDe-rating \\nfor temp\\nEffective fail-\\nure rate\\n(FIT)\\n50 k gate CPU\\n3,4 \\xc3\\x97 10\\xe2\\x88\\x926\\n200 000\\n(4 transistors/gate)\\n10\\n1,7\\n1,80\\n0,17\\n0,31\\n16 kB SRAM\\n786 432\\n(6 transistors/ \\nbit for a low-consump-\\ntion SRAM)\\nDie failure rate (FIT)\\n0,31\\n4.6.2.1.1.2 \\nTemperature de-rating\\nThe model in Figure 9 to calculate the temperature de-rating factor \\xce\\xb4T uses the following parameters:\\n\\xe2\\x80\\x95 \\n(\\xcf\\x80t)i: ith temperature factor related to the ith junction temperature of the integrated circuit mission \\nprofile;\\n\\xe2\\x80\\x95 \\n\\xcf\\x84i: ith working time ratio of the integrated circuit for the ith junction temperature of the mission \\nprofile;\\n\\xe2\\x80\\x95 \\n\\xcf\\x84on: total working time ratio of the integrated circuit, with \\xcf\\x84\\n\\xcf\\x84\\non =\\n=\\xe2\\x88\\x91\\ni\\ni\\ny\\n1\\n;\\n\\xe2\\x80\\x95 \\n\\xcf\\x84off: time ratio for the integrated circuit being in storage (or dormant);\\n\\xe2\\x80\\x95 \\n\\xcf\\x84on + \\xcf\\x84off = 1.\\n \\n28 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFor the calculation of a conservative temperature de-rating factor, the off time \\xcf\\x84off can be set to zero, \\nresulting in a slightly modified version of \\xce\\xb4T for the temperature de-rating factor \\xce\\xb4T,conservative:\\n\\xce\\xb4\\n\\xcf\\x80\\n\\xcf\\x84\\n\\xcf\\x84\\nT,conservative\\non\\n=\\n(\\n) \\xc3\\x97\\n=\\xe2\\x88\\x91\\nt\\ni\\ni\\ni\\ny\\n1\\n \\n(18)\\nIn Table 2, Table 3 and Table 4, the de-rating factor is calculated after considering the \\xcf\\x84on and \\xcf\\x84off time. \\nIn the above digital component example of Table 5, setting the \\xcf\\x84off to zero gives a de-rating factor of \\n2,91, therefore the effective failure rate value changes from 0,31 to 5,24 FIT.\\n4.6.2.1.1.3 \\nPackage base failure rate calculation\\nThe package failure rate \\xce\\xbbpackage as calculated in Figure 9 corresponds to the failure modes inside of \\nthe package itself (including e.g. the connection between the die and the lead frame) but it also includes \\nthe failure rate related to the connection between the package connection points and the board \\n(solder joints) which represents approximately 20 % of the overall \\xce\\xbbpackage FIT rate as described in \\nReference [54]. The semiconductor provider could then use 80 % of \\xce\\xbbpackage value for the distribution of \\nthe hardware component package FIT rate.\\nAs already described in 4.6.2.1.1, the package failure rate calculation takes into account the following \\nparameters:\\n\\xe2\\x80\\x95 \\n\\xcf\\x80\\xce\\xb1: influence factor related to the thermal expansion coefficients difference between the mounting \\nsubstrate and the package material;\\n\\xe2\\x80\\x95 \\n(\\xcf\\x80n)i: ith influence factor related to the annual cycles number of thermal variations seen by the \\npackage, with the amplitude \\xce\\x94Ti;\\n\\xe2\\x80\\x95 \\n\\xce\\x94Ti: ith thermal amplitude variation of the mission profile; and\\n\\xe2\\x80\\x95 \\n\\xce\\xbb3: base failure rate of the integrated circuit package.\\nTable 6 \\xe2\\x80\\x94 Package base failure rate calculation example\\nPackage type\\n\\xce\\x94Tj\\n(\\xc2\\xb0C)\\nS\\n(Number of pins)\\nD\\n(mm)\\n\\xcf\\x80\\xce\\xb1\\n\\xce\\xbb3\\n(FIT)\\nDe-rating for \\ntemperature \\ncycling\\nEffective \\nfailure rate\\n(FIT)\\nPQFP 144\\n26,27\\n144\\n26,58\\n1,05\\n11,87\\n6 009\\n206\\nPackage failure rate including solder joints between package and board (FIT)\\n206\\nTotal package failure rate without solder joints between package and board (FIT)\\n166\\nThe influencing factor \\xcf\\x80\\xce\\xb1 is calculated using the formula shown in Figure 11, with \\xce\\xb1s, \\xce\\xb1c being the linear \\nthermal expansion coefficients for the substrate and for the component respectively. In this example, \\nwe assume FR4 as mounting substrate and a plastic package for which Figure 12 delivers the values \\n\\xce\\xb1s = 16 and \\xce\\xb1c = 21,5.\\nFor an automotive profile with number of cycles/year \\xe2\\x89\\xa4 8 760, the parameter (\\xcf\\x80n)i is calculated using \\nthe formula in Figure 11, with ni: Annual number of cycles with the amplitude \\xce\\x94Ti.\\nTo calculate \\xce\\xbb3 in FIT, the formula for peripheral connections packages is used, using a width of 20 mm \\nand a pitch of 0,5 mm as shown in Figure 15. Using the \\xe2\\x80\\x9cmotor control\\xe2\\x80\\x9d temperature profile shown in \\nFigure 16, this results in a total failure rate for the package without solder joints of:\\n\\xce\\xbbpackage = 166 FIT.\\nThe package failure rate is assumed to be equally distributed among the pins, leading to a pin failure \\nrate of:\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n29\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xce\\xbbpin = 1,15 FIT.\\nNOTE 1 \\nThe package in the example is a 144 pin quad flat package and cooled by natural convection. The \\npower consumption is 0,5 W leading to an increase of the junction temperature \\xce\\x94Tj of 26,27 \\xc2\\xb0C. The value of D and \\n\\xce\\xbb3 are computed using Figure 15 on the basis of the following values: pitch = 0,5 mm and width = 20 mm.\\nNOTE 2 \\nNot all packages are covered by the tables in Figure 14 or Figure 15. In this case expert judgment can \\nbe used to estimate the contribution of the package to the overall failure rate.\\nEXAMPLE 1 \\nPackage failure rate estimation is based on the knowledge of the construction and thermal \\ncharacteristics of the device package and the system\\xe2\\x80\\x99s printed circuit board.\\nNOTE 3 \\nEqual probability for pins can be used in this example but not for all cases.\\nEXAMPLE 2 \\nIn BGAs, certain locations can have higher distribution than other locations.\\n4.6.2.1.1.4 \\nExample of failure rate resulting from electrical overstress\\nThe failure rate for the whole device due to electrical overstress can be calculated using the formula \\nshown in Figure 9. If the device has a direct connection to the external environment, i.e. the device is \\nan interface, \\xcf\\x80I is equal to one. If the device is not an interface, i.e. it has no direct connection to the \\nexternal environment, \\xcf\\x80I is equal to zero.\\nFigure 11 shows different \\xce\\xbbEOS for various electrical environments. Unfortunately, an automotive \\nelectrical environment is not given. Instead the \\xe2\\x80\\x9ccivilian avionics (on board calculators)\\xe2\\x80\\x9d can be chosen:\\n\\xce\\xbbEOS = 20 FIT.\\nThis results in a failure rate due to electrical overstress for the whole device of either\\n\\xce\\xbboverstress = 20 FIT, if the device has a direct contact to the external environment, or\\n\\xce\\xbboverstress = 0 FIT in every other case.\\nTo forecast the impact of electrical overstress on the device is non-trivial. If no particular impact can be \\nargued, then \\xce\\xbboverstress can be added to \\xce\\xbbdie to increase the overall die failure rate of the whole device.\\nNOTE \\nElectrical over-stress can be considered a systematic failure mode and reduced to zero FIT for \\ncalculation of random hardware failure metrics.\\n4.6.2.1.2 \\nSN 29500\\nThe SN 29500 follows a table look up approach. Expected values for failure rates under specified \\nreference conditions are given. Values are to be looked up in tables using product type, technology and \\ntransistor count as an input. If the integrated circuits are operated under conditions different from the \\nreference conditions a calculation from reference to operating conditions is to be used. The calculation \\ntakes into consideration temperature, voltage and drift (for analogue elements). For the temperature \\npart of the calculation to operating conditions a modified Arrhenius equation is used.\\n4.6.2.1.2.1 \\nExample of computation for a semiconductor component\\nParameters required for the calculation of the failure rate with SN 29500:\\n\\xe2\\x80\\x95 \\nN, the number of equivalent transistors;\\n\\xe2\\x80\\x95 \\n\\xce\\xbbref , the basic failure rate for the hardware component, based on the process technology;\\n\\xe2\\x80\\x95 \\n\\xce\\x94Tj, the junction temperature increase; and\\n\\xe2\\x80\\x95 \\nthe mission profile of the hardware component.\\n \\n30 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 1 \\nIn cases where the number of equivalent transistors N is not listed in the failure rates families tables \\n1, 2 or 3 of SN 29500-2:2010 and when possible the user can use an interpolation or extrapolation method to \\ndetermine the equivalent \\xce\\xbbref and \\xce\\xb8vj,1 (virtual junction temperature) values.\\nEXAMPLE \\nFor \"microprocessors and peripherals, microcontrollers and signal processors\" family as defined \\nin SN 29500-2:2010, Table 2, the following interpolation example is done to determine \\xce\\xbbref and \\xce\\xb8vj,1 values.\\nAssuming a microcontroller with 500 K gates the calculation of the \\xce\\xbbref could be done using the \\nfollowing steps:\\n\\xe2\\x80\\x95 \\n1st step: translating \\xce\\xbbref values from Table 2 to a same virtual reference temperature qvj,1 for \\nexample 90 \\xc2\\xb0C by using the temperature dependent factor \\xcf\\x80T:\\n\\xcf\\x80 T\\nref\\nref\\n=\\n\\xc3\\x97\\n+\\n\\xe2\\x88\\x92\\n(\\n) \\xc3\\x97\\n\\xc3\\x97\\n+\\n\\xe2\\x88\\x92\\n(\\n) \\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\nA\\ne\\nA\\ne\\nA\\ne\\nA\\ne\\nE\\nz\\nE\\nz\\nE\\nz\\nE\\nz\\na\\na\\na\\na\\n1\\n2\\n1\\n2\\n1\\n1\\n \\n(19)\\nSN 29500\\xe2\\x80\\x932:2010, Table 2 \\xe2\\x80\\x95 CMOS\\n(19)\\n1k\\n10k\\n100k\\n1M\\n10M\\n100M\\n\\xce\\xb8vj,1\\n\\xce\\xbbref (50\\xc2\\xb0C)\\n25\\n50 \\xc2\\xb0C\\n\\xce\\xbbref (60 \\xc2\\xb0C)\\n30\\n60 \\xc2\\xb0C\\n\\xce\\xbbref (80 \\xc2\\xb0C)\\n50\\n80 \\xc2\\xb0C\\n\\xce\\xbbref (90 \\xc2\\xb0C)\\n80\\n120\\n150\\n90 \\xc2\\xb0C\\n\\xcf\\x80T (90 \\xc2\\xb0C)\\n5,18\\n3,47\\n1,53\\n1\\n1\\n1\\n\\xe2\\x80\\x95\\n\\xce\\xbbref (90 \\xc2\\xb0C)\\n130\\n105\\n76\\n80\\n120\\n150\\nFIT\\n\\xe2\\x80\\x95 \\n2nd step: linear interpolation of \\xce\\xbbref at 90 \\xc2\\xb0C for desired complexity, i.e. 500 K transistors:\\n\\xce\\xbbref (90 \\xc2\\xb0C)\\nGates\\n1k\\n10k\\n100k\\n1M\\n10M\\n100M\\n\\xce\\xb8vj,1\\n\\xce\\xbbref (90 \\xc2\\xb0C)\\n130\\n105\\n76\\n80\\n120\\n150\\nFIT\\n\\xce\\xbb\\n\\xce\\xbb\\n\\xce\\xbb\\nref\\n K\\n C\\nref\\n K\\n C\\nref\\n M\\no\\no\\n K\\n K\\n500\\n90\\n100\\n90\\n1\\n500\\n100\\n@\\n@\\n@\\n(\\n)\\n(\\n)\\n=\\n+\\n+\\n(\\n) \\xc3\\x97\\n90\\n100\\n90\\n1\\n100\\n76\\n400\\n80\\n75\\n900\\n C\\nref\\n K\\n C\\no\\no\\n \\n \\n \\n \\n(\\n)\\n(\\n)\\n\\xe2\\x88\\x92\\n\\xe2\\x88\\x92\\n=\\n+\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n(\\n) =\\n\\xce\\xbb\\n@\\nM\\nK\\nK\\nK\\n78 2\\n,\\n FIT\\n (20)\\n\\xe2\\x80\\x95 \\n3rd step: linear Interpolation of \\xce\\xb8vj,1 for the desired complexity i.e. 500 K transistors:\\n\\xce\\xb8\\n\\xce\\xb8\\n\\xce\\xb8\\n\\xce\\xb8\\nvj\\nvj\\nvj\\nvj\\n,\\n,\\n,\\n,\\n1 500\\n1 100\\n1 1\\n1 10\\n500\\n100\\n K\\n K\\n M\\n K\\n K\\n(\\n)\\n(\\n)\\n(\\n)\\n=\\n+\\n\\xe2\\x88\\x92\\n(\\n) \\xc3\\x97\\n\\xe2\\x88\\x92\\n0\\n1\\n100\\n80\\n400\\n90\\n80\\n900\\n84 4\\n K\\n M\\n K\\n K\\n K\\n C\\n(\\n)\\n\\xe2\\x88\\x92\\n=\\n+\\n\\xc3\\x97\\n\\xe2\\x88\\x92\\n(\\n) =\\n,\\n\\xef\\x81\\xaf  \\n(21)\\n\\xe2\\x80\\x95 \\n4th and final step: translate \\xce\\xbbref(500K@90 \\xc2\\xb0C) to \\xce\\xb8vj,1(500K) using the temperature dependent factor \\xcf\\x80T:\\n\\xcf\\x80T(90 \\xc2\\xb0C ==>84,4 \\xc2\\xb0C) = 0,79 \\n(22)\\n\\xce\\xbbref(500K@84,4\\xc2\\xb0C) =\\xce\\xbbref(500K@90\\xc2\\xb0C) \\xc3\\x97 \\xcf\\x80T(90\\xc2\\xb0C ==> 84,4 \\xc2\\xb0C) = 78,2 \\xc3\\x97 0,79=62 FIT \\n(23)\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n31\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nSN 29500\\xe2\\x80\\x932:2010, Table 2 \\xe2\\x80\\x95 CMOS\\nGates\\n1k\\n10k\\n100k\\n1M\\n10M\\n100M\\n\\xce\\xb8vj,1\\n\\xce\\xbbref (50 \\xc2\\xb0C)\\n25\\n50 \\xc2\\xb0C\\n\\xce\\xbbref (60 \\xc2\\xb0C)\\n30\\n60 \\xc2\\xb0C\\n\\xce\\xbbref (80 \\xc2\\xb0C)\\n50\\n80 \\xc2\\xb0C\\n\\xce\\xbbref (90 \\xc2\\xb0C)\\n80\\n120\\n150\\n90 \\xc2\\xb0C\\nNOTE 2 \\nThe values regarding mission profiles are only examples. The requirements for all semiconductors \\nwithin an ECU are aligned with the requirements of the respective ECU specifications.\\n4.6.2.1.2.2 \\nFailure rate calculation for the semiconductor component example without non-\\noperating phase\\nFor the digital component example described in previous clauses, in CMOS technology with 500 k to \\n5 million transistors we get 80 FIT at 90 \\xc2\\xb0C reference temperature condition. The following parameters \\nare listed in Table 7 and Table 8:\\n\\xe2\\x80\\x95 \\nA, constant;\\n\\xe2\\x80\\x95 \\nEa1, Ea2, constant activation energy in eV.\\nTable 7 \\xe2\\x80\\x94 Parameters required for failure rate calculation example with SN 29500\\nN\\n(transistors)\\nTechnology and \\nfamily\\n\\xce\\xbbref\\n(FIT)\\n\\xce\\x94Tj\\n(\\xc2\\xb0C)\\nTemperature \\ndependent refer-\\nence (Zref)\\n(1/eV)\\nA\\nEa1\\n(eV)\\nEa2\\n(eV)\\n986 432 \\n(Digital + SRAM)\\nCMOS, micropro-\\ncessor\\n80\\n26,27\\n5,11\\n0,9\\n0,3\\n0,7\\nAssuming 500 working hours per year and using the motor control mission profile as defined in \\nFigure 16, we have the result of Table 8.\\nTable 8 \\xe2\\x80\\x94 Digital component failure rate calculation example with SN 29500\\nAmbient temper-\\nature\\n\\xce\\xb8U\\n(\\xc2\\xb0C)\\nWorking time\\n(h)\\nJunction temper-\\nature\\n\\xce\\xb8j,2\\n(\\xc2\\xb0C)\\nDependence factor\\nZ\\n(1/eV)\\nTemperature depend-\\nence factor\\n\\xcf\\x80T(\\xce\\xb8u)\\n32\\n172,4\\n58,27\\n2,04\\n0,27\\n60\\n129,3\\n86,27\\n4,77\\n0,85\\n85\\n198,3\\n111,27\\n6,87\\n2,51\\nOverall Temperature Dependent Factor \\xcf\\x80T\\n1,31\\nEffective failure rate for the overall hardware component (FIT)\\n105\\n4.6.2.1.2.3 \\nFailure rate calculation for the semiconductor component example with non-\\noperating phase\\nThere is a difference between the model described in 4.6.2.1.1 and SN 29500 in the way the non-\\noperating phases are considered. In the model described in 4.6.2.1.1 the non-operating hours are by \\ndefault included in the mission profile of the product whereas in SN 29500 only the operating hours are \\nby default considered. As described in 4.6.2.1.1.2, an alternative approach for calculating failure rate is \\nsetting \\xcf\\x84off time to zero.\\n \\n32 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nIn a similar way, operating and non-operating phases can also be taken into account in SN 29500 for the \\ncalculation of the failure rate. This is done by applying a stress factor \\xcf\\x80\\xcf\\x89 described in SN 29500-2:2010, \\n4.4. Using the motor control mission profile as defined in Figure 16 and an average temperature of \\n10,5 \\xc2\\xb0C gives a stress factor value of 0,06. Applying the calculated stress factor to the digital component \\nexample failure rate gives the results of Table 9.\\nTable 9 \\xe2\\x80\\x94 SN 29500 failure rate calculation with or without non-operating phases\\nN\\n(transistors)\\nTechnology and \\nFamily\\n\\xce\\xbbref\\n(FIT)\\n\\xce\\xbb\\nWithout non-oper-\\nating phase (FIT)\\nStress \\nFactor\\n\\xce\\xbb\\nWith non-operating \\nphase (FIT)\\n986 432 \\n(Digital + SRAM)\\nCMOS, microprocessor\\n80\\n104,65\\n0,06\\n6,3\\nNOTE \\nThe non-operating average temperature is obtained from the average worldwide night and day-light \\ntemperatures (respectively 5 \\xc2\\xb0C and 15 \\xc2\\xb0C) as defined in Figure 13 and considering a 50 % ratio between night \\nand day.\\n4.6.2.1.2.4 \\nMethod to split SN 29500 overall failure rate into die and package failure rates\\nAs stated by the maintainer of SN 29500, the base failure rate value calculated with SN 29500 is valid \\nfor the whole hardware component only and does not provide a method to split between package failure \\nrate and die failure rate. Therefore, the ratio of die failure rate and package failure rate is estimated \\nbased on expert judgement, if required.\\nEXAMPLE \\nAs example of expert judgment, an estimation of the split of package and die failure rates from \\nan SN 29500 base failure rate could be calculated by using the same ratio as determined by method 4.6.2.1.1 or \\nbased on other industry sources which provide such data or from field data statistics when available.\\n4.6.2.1.3 \\nFIDES Guide\\nThe following is an example of the estimation of hardware failure rate as needed to support quantitative \\nanalysis using the methods detailed in the FIDES guide [9]. The failure rate model for a semiconductor \\nper FIDES guide considers the failure rate of the device to be a factor of:\\n\\xe2\\x80\\x95 \\nphysical contributions (\\xce\\xbbPhysical);\\n\\xe2\\x80\\x95 \\nprocess contributions (\\xcf\\x80Process); and\\n\\xe2\\x80\\x95 \\npart manufacturing contributions (\\xcf\\x80PM).\\nThe first is an additive construction term comprising physical and technological contributing factors \\nto reliability. The second is a multiplicative term including the quality and technical control over the \\ndevelopment, manufacturing and the usage process for the product containing the device. The third \\nfactor represents for example the quality of the manufacturing site and the experience of the supplier. \\n\\xcf\\x80Process and \\xcf\\x80PM are set to 1 as these factors are related to systematic issues.\\nThe physical contribution is composed of stress acceleration factors due to usage conditions and an \\ninduced (i.e. unexpected overstress) multiplicative term inherent to the application of the product \\ncontaining the device. However for the sake of simplicity, in the current example this induced \\nmultiplicative factor is set to 1. When actually applying it, the value based upon placement, usage \\ncontrols and sensitivity to over stresses of the component is determined.\\nThe models used in the FIDES guide for integrated circuits include the following physical stress families:\\n\\xe2\\x80\\x95 \\nthermal;\\n\\xe2\\x80\\x95 \\ntemperature cycling;\\n\\xe2\\x80\\x95 \\nmechanical; and\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n33\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nhumidity.\\nNOTE \\nFor the sake of keeping the examples simple, the following calculations do not include mechanical and \\nhumidity related failure modes. These additional failure modes are considered in a real application.\\nTo compute the digital component die and package base failure rates (i.e. before application of de-rating \\nfor operating conditions), it is necessary to consider the following elements:\\n\\xe2\\x80\\x95 \\n\\xce\\xbb0TH, the basic failure rate associated with the type of device and process technology; and\\n\\xe2\\x80\\x95 \\nphysical stress parameters a and b associated with the type of package.\\nThose factors are combined using FIDES. Parameters selection can be based on the process technology, \\ntype of circuitry and package utilised by the design. Values are available related to Microprocessor, \\nMicrocontroller, DSP and SRAM, and PQFP package with 144 pins.\\nTable 10 and Table 11 below show the computation of the failure rates used in the quantitative example \\nof a CMOS technology based MCU which consumes 0,5 W power. The digital component die is packaged \\nin a 144 pin quad flat package and cooled by natural convection and low-conductivity board.\\nTable 10 \\xe2\\x80\\x94 Base failure rate of the die from UTE FIDES\\nCircuit element\\n\\xce\\xbb0TH \\n(FIT)\\n50 k gate CPU\\n0,08\\n16 kB SRAM\\n0,06\\nSum\\n0,13\\nTable 11 \\xe2\\x80\\x94 Base failure rate of the package from UTE FIDES\\nPackage\\n\\xce\\xbb0TCy_Case\\n\\xce\\xbb0TCy_Solderjoints\\na\\nb\\n\\xce\\xbb0TCy_Case\\n(FIT)\\na\\nb\\n\\xce\\xbb0TCy_Solder-\\njoints\\n(FIT)\\n144 pin PQFP\\n12,41\\n1,46\\n0,01\\n10,80\\n1,46\\n0,03\\nOnce the base failure rate for the digital component die and package has been generated, a de-rating \\nfactor is applied based on thermal effects and operating time. The de-rating factor takes into account:\\n\\xe2\\x80\\x95 \\njunction temperature of the digital component die, which is calculated based on:\\n\\xe2\\x80\\x95 \\npower consumption of the digital component die; and\\n\\xe2\\x80\\x95 \\npackage thermal resistance, based on package type, number of package pins and airflow.\\n\\xe2\\x80\\x95 \\nan application profile which defines 1 to Y usage phases, each of which is composed of an application \\n\\xe2\\x80\\x9con-time\\xe2\\x80\\x9d, \\xe2\\x80\\x9ccycle time\\xe2\\x80\\x9d, \\xe2\\x80\\x9ccycle delta temperature\\xe2\\x80\\x9d, and \\xe2\\x80\\x9ccycle max temperature\\xe2\\x80\\x9d, and \\xe2\\x80\\x9cambient \\ntemperature\\xe2\\x80\\x9d.\\nNOTE \\nThe profile for use in the model considers more/other parameters than those provided in the profile \\nof Reference [40].\\nAt first, the simplified mission profile example shown in Table 12 is considered.\\n \\n34 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable\\t12\\t\\xe2\\x80\\x94\\tSimplified\\tmission\\tprofile\\texample\\nThermal\\nThermal cycling\\nPHASE\\nOn/ \\nOff\\nTannu-\\nal-phase \\n(hours)\\nTambient \\n(\\xc2\\xb0C)\\n\\xce\\x94Tcycling \\n(\\xc2\\xb0C)\\n\\xce\\xb8cy \\n(hours)\\nNcy-an-\\nnual \\n(hours)\\nTmax-cy-\\ncling \\n(\\xc2\\xb0C)\\nNon-operational day\\nOff\\n720\\n15\\n10\\n24,0\\n30\\n20\\nNight start\\nOn\\n168\\n60\\n55\\n0,25\\n670\\n60\\nDay start\\nOn\\n335\\n60\\n45\\n0,25\\n1 340\\n60\\nOff-operational day\\nOff\\n7,538\\n15\\n10\\n22,5\\n30\\n20\\nThe die base failure rate with de-rating factors is computed as in Table 13.\\nTable 13 \\xe2\\x80\\x94 Die base failure rate with temperature de-rating factor\\nCircuit element\\n\\xce\\xbb0TH\\n(FIT)\\nDerating for tem-\\nperature\\nEffective failure \\nrate (FIT)\\n50 k gate CPU\\n0,08\\n5,79\\n0,43\\n16 kB SRAM\\n0,06\\n5,79\\n0,32\\nSum\\n0,13\\n \\n0,75\\nFor evaluating these de-rating factors, the junction temperature, i.e. \\xe2\\x88\\x86Tj due to self-heating is calculated \\nas 18 K, using the parameters and formula described in FIDES (see Table 14).\\nTable 14 \\xe2\\x80\\x94 Package base failure rate with temperature cycling de-rating factor\\n\\xce\\xbbTCy_case\\n\\xce\\xbbTCy_solderjoints\\nPackage\\n\\xce\\xbb0TCy_case\\n(FIT)\\nDerating \\nfor cycling\\nEffective failure \\nrate (FIT)\\n\\xce\\xbb0TCy_sol-\\nderjoints \\n(FIT)\\nDerating \\nfor cycling\\nEffective failure \\nrate (FIT)\\n144 pin PQFP\\n0,01\\n130\\n0,75\\n0,03\\n10\\n0,28\\nThen, the elaborated mission profile example shown in Table 15 is considered. The de-rating factors are \\nlisted in Table 16.\\nTable\\t15\\t\\xe2\\x80\\x94\\tElaborated\\tmission\\tprofile\\texample\\nThermal\\nThermal cycling\\nPHASE\\nOn/ \\nOff\\ntannual-phase\\n(hours)\\nTambient\\n(\\xc2\\xb0C)\\n\\xce\\x94Tcycling\\n(\\xc2\\xb0C)\\nTeta cy\\n(hours)\\nNcy-annual\\n(hours)\\nTmax-cycling\\n(\\xc2\\xb0C)\\nNon-operational day\\nOff\\n720\\n14\\n10\\n24,0\\n30\\n19\\nNight start\\nOn\\n117\\n32\\n22\\n0,0\\n670\\n32\\nDay start\\nOn\\n58\\n32\\n18\\n0,0\\n1 340\\n32\\nFull load operation\\nOn\\n201\\n85\\n53\\n1,0\\n335\\n85\\nHighway operation\\nOn\\n131\\n60\\n28\\n4,0\\n30\\n60\\nOff-operational day\\nOff\\n7,532\\n14\\n10\\n23,0\\n30\\n19\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n35\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 16 \\xe2\\x80\\x94 Effective failure rate\\nCircuit element\\n\\xce\\xbb0TH (FIT)\\nDerating for tempera-\\nture\\nEffective failure \\nrate (FIT)\\n50 k gate CPU\\n0,08\\n12,44\\n0,93\\n16 kB SRAM\\n0,06\\n12,44\\n0,68\\nSum (FIT)\\n0,13\\n \\n1,61\\nFor evaluating these de-rating factors, the junction temperature, i.e. \\xe2\\x88\\x86Tj, due to self-heating is \\ncalculated as 18 K, using the parameters and formula described in FIDES. As shown in Table 17, the \\ncomponent package failure rate is then 0,25 FIT. The solder joints failure rate value in Table 17 is given \\nas information only and is not considered as part of the package failure rate.\\nTable 17 \\xe2\\x80\\x94 Package and solder joints failure rate\\n\\xce\\xbbTCy_case\\n(FIT)\\n\\xce\\xbbTCy_solderjoints\\n(FIT)\\nPackage\\n\\xce\\xbb0TCy_case \\n(FIT)\\nDerating \\nfor cycling\\nEffective failure \\nrate (FIT)\\n\\xce\\xbb0TCy_sol-\\nderjoints \\n(FIT)\\nDerating for \\ncycling\\nEffective failure \\nrate (FIT)\\n144 pin PQFP\\n0,01\\n42\\n0,25\\n0,03\\n4\\n0,12\\n4.6.2.2\\t\\nPermanent\\tbase\\tfailure\\trate\\tcalculation\\tusing\\tfield\\tdata\\tstatistics\\nIt is important to use field data statistics with care, as it is very difficult to get an appropriate estimation. \\nA thorough analysis of the field return process is performed and the result of the analysis is used for \\nthe quantitative evaluations. In particular the following topics are evaluated:\\n\\xe2\\x80\\x95 \\nhow does the field return process handle known quality issues;\\n\\xe2\\x80\\x95 \\nwhat kind of information is available about the real mission profile; and\\n\\xe2\\x80\\x95 \\nwhat is the effectiveness of the field monitoring process.\\nBecause the methodology used to calculate the failure rate from field data has an influence on the \\nconfidence level of the resulting failure rate value, the following points are taken into account by the \\nsemiconductor suppliers:\\n\\xe2\\x80\\x95 \\na proper field data collection system as required in ISO 26262-2:2018, 7.4.2.3, NOTE is put in place;\\n\\xe2\\x80\\x95 \\nthe goal of the method is not to approximate as close as possible the real failure rate, but to provide \\na failure rate value for which there is a high confidence that it is above the real failure rate value;\\n\\xe2\\x80\\x95 \\nsignificant source of systematic faults are only removed from the field statistics if the source of the \\nsystematic faults has been mitigated;\\nEXAMPLE 1 \\nAn example of a major source of systematic faults is EOS.\\nNOTE 1 \\nEvidence of mitigation of the source of the systematic fault is documented.\\n\\xe2\\x80\\x95 \\nbecause the semiconductor suppliers could not be aware of all failures in the field, a correction factor \\n(CF) can be applied to the total number of returns. That factor can depend on many parameters \\nsuch as the application and the device population used to estimate the field based failure rate;\\nNOTE 2 \\nRationale is provided from those semiconductor suppliers who estimate failure rate based on \\nfield returns.\\n\\xe2\\x80\\x95 \\nan acceleration factor (AF) corresponding to the temperature stress or to the thermal cycling \\nstress effects can be respectively calculated using applicable, validated thermal strain or brittle \\nfracture model.\\n \\n36 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nEXAMPLE 2 \\nCoffin-Manson or Englemaier-Clech methods.\\n\\xe2\\x80\\x95 \\nthe total operating time of the products in the field can be estimated using the mission profiles of \\nthe products when available. The variability in car usage from the drivers can also be taken into \\naccount by estimating the quantity of hours spent in field using for example a mean of 500 hours a \\nyear with a standard deviation of 145 hours; and\\n\\xe2\\x80\\x95 \\nthe mission profile of the field data is documented and considered appropriately in the quantitative \\nevaluations.\\n4.6.2.2.1 \\nExponential model method\\nThe exponential model can be used in general to determine a constant failure rate from field returns. \\nIn this model, \\xcf\\x872 (chi-square) statistical function gives a good approximation of the failure rate. It is \\nproposed to use an interval estimator with a one-sided upper interval estimation at, at least, 70 % \\nconfidence level instead of using a point estimator for the failure rate. That means that with 70 % \\nprobability, the real value of the failure rate is below that value. The failure rate can be calculated using \\nthe formula below:\\nFIT\\ncumulative operational hours\\nAF\\n=\\n\\xc3\\x97\\n\\xc3\\x97\\n\\xc3\\x97\\n+\\n\\xcf\\x87CL\\nn\\n;2\\n2\\n2\\n9\\n10\\n2\\n \\n(24)\\nwhere\\n \\nn\\nnumber of failures multiplied by the correction factor;\\n \\nCL confidence level value (typically 70 %);\\n \\nAF acceleration factor.\\nNOTE \\nThe acceleration factor is used to adapt failure rate values from one mission profile to another one as \\ndescribed in 4.6.2.2.2.\\n4.6.2.2.2 \\nCalculation example of hardware component failure rate\\nIn this sub-clause an example of a die failure rate calculation using field data statistics is given using \\nthe exponential model method. In this example we assume that the semiconductor supplier is collecting \\nstatistics from three products in the field as described in Table 18 below.\\nTable\\t18\\t\\xe2\\x80\\x94\\tMission\\tprofile\\tand\\tequivalent\\tjunction\\ttemperature\\tTj,eq\\nTj (\\xc2\\xb0C)\\nChip 1 \\nPhase Duration \\n(hours)\\nTj (\\xc2\\xb0C)\\nChip 2 \\nPhase Duration \\n(hours)\\nTj (\\xc2\\xb0C)\\nChip 3 \\nPhase Duration \\n(hours)\\n\\xe2\\x88\\x9220\\n1 000\\n\\xe2\\x88\\x9225\\n100\\n\\xe2\\x88\\x9220\\n500\\n10\\n2 000\\n10\\n500\\n15\\n800\\n30\\n1 500\\n35\\n10 000\\n45\\n6 000\\n45\\n6 000\\n55\\n8 000\\n80\\n4 200\\n70\\n1 000\\n90\\n1 000\\n100\\n600\\n100\\n1 300\\n100\\n200\\n120\\n300\\n130\\n200\\n120\\n200\\n150\\n100\\nTj,eq (\\xc2\\xb0C)\\n55,1\\nTj,eq\\n51,4\\nTj,eq\\n67,4\\nTotal duration\\n13 000\\nTotal duration\\n20 000\\nTotal duration\\n12 500\\nNOTE 1 \\nThe mission profile equivalent temperature Tj,eq corresponds to the temperature that would have the \\nsame effect as the whole mission profile from a temperature stress perspective. Tj,eq can be calculated using the \\nArrhenius equation. In the above example an activation energy Ea of 0,3 eV was assumed.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n37\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 2 \\nThe device operating hours of the different devices can be summed up together if they are referred \\nto the same reference temperature Tref. In this example Tref is 55 \\xc2\\xb0C and the equivalent devices hours at Tref are \\ncalculated using Arrhenius equation associated with an activation energy Ea of 0,3 eV.\\nNOTE 3 \\nAs shown in Table 19, the failure rate per mm2 value at the reference temperature Tref is calculated \\nusing the \\xcf\\x872 statistical function from the total number of failures and the total number of die area hours. In this \\nexample an upper confidence level of 70 % has been used.\\nTable 19 \\xe2\\x80\\x94 Calculation of failure rate per mm2 at reference temperature Tref\\nProduct \\nName\\nDie \\nsize\\nmm2\\nMission \\nprofile\\t\\nequivalent \\ntemp Tj,eq \\n(\\xc2\\xb0C)\\nTotal \\nDevice \\nOperating \\nhours (in \\nmillion de-\\nvice hours)\\nArrhenius \\nAcceleration \\nFactor\\nEquivalent \\nOperating \\nhours at a Tref \\nof 55 \\xc2\\xb0C (in \\nmillion de-\\nvice hours)\\nEquivalent \\ndie area \\nhours at a \\nTref of 55 \\xc2\\xb0C \\n(in million \\nmm2 hours)\\nNb of \\nfailures \\nduring \\nwarranty \\nperiod\\nNb of fail-\\nures with \\nCF = 5\\nChip1\\n30\\n55,1\\n7 000\\n1,00\\n7 022,67\\n210 680\\n1\\n5\\nChip2\\n25\\n51,4\\n10 200\\n0,89\\n9 066,96\\n226 674\\n1\\n5\\nChip3\\n50\\n67,4\\n5 000\\n1,47\\n7 359,25\\n367 963\\n2\\n10\\nTotal die area hours\\n805 317\\nTotal nb of \\nfailures\\n20\\nFIT/mm2 at Tref of 55 \\xc2\\xb0C\\n0,029\\n \\n \\nAs explained in Figure 17 below, the failure rate per mm2 at Tref derived from the field data statistics \\ncan then be used to calculate the failure rate of the target product under design (see Table 20).\\nFigure\\t17\\t\\xe2\\x80\\x94\\tDie\\tfailure\\trate\\tcalculation\\tmethod\\tusing\\tfield\\tdata\\tstatistics\\n \\n38 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 20 \\xe2\\x80\\x94 Final chip failure rate calculation\\nMission \\nprofile\\tEquiv.\\t\\nTemp Tj,eq\\n(\\xc2\\xb0C)\\nDie size \\n(mm2)\\nFIT/mm2 \\nat Tref\\nArrhenius \\nAccelera-\\ntion Factor\\nFIT/mm2 at \\nEquiv. Temp Tj,eq\\nDie base \\nfailure rate \\n(FIT)\\nTarget Chip \\nunder design\\n75\\n23\\n0,03\\n1,84\\n0,05\\n1,22\\nNOTE 4 \\nSame method is applied to calculate package failure rate but the acceleration factor is calculated using \\nCoffin-Manson or Norris-Landzberg model (as discussed in Reference [15] sub-clause 5.2.7.10 \"Failure Modes\", \\nReference [16] sub-clause 5.14 and Reference [9] sub-clause 2.5.1 \"Physics of failures and models\") instead of \\nArrhenius model. Figure 18 gives an overview of the methods used to calculate the package failure rate using \\nfield data statistics.\\nFigure\\t18\\t\\xe2\\x80\\x94\\tPackage\\tfailure\\trate\\tcalculation\\tmethod\\tusing\\tfield\\tdata\\tstatistics\\nNOTE 5 \\nIn case that the field data analysis does not distinguish between die and package (as it is the case for \\nexample in SN 29500 [38]) then the Arrhenius law can be used to calculate the hardware component (die and \\npackage) failure rate using the mission profile temperatures and reference temperature Tref as in Figure 18.\\n4.6.2.3 \\nBase failure rate calculation using accelerated life tests\\nTo de-rate from the temperature at which the life test is carried out to the maximum operating \\ntemperature an acceleration factor is applied. This calculation uses Arrhenius equation with activation \\nenergy of 0,7 eV. It is recommended to estimate and verify activation energy associated with desired \\nfailure mechanism.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n39\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nThe number of faults obtained from the sample is used in the \\xcf\\x872 distribution function with a certain \\nconfidence level to obtain the number of faults that would occur over the entire population tested.\\nVoltage acceleration is also taken into account when determining the life of devices. For CMOS, this \\nis calculated by taking the gate oxide thickness into consideration and de-rating from the stress test \\nvoltage to the life operating voltage.\\nAFv = exp (\\xce\\xb2) \\xc3\\x97 [Vt \\xe2\\x88\\x92 Vo] \\n(25)\\nwhere\\n \\nAFv\\nvoltage acceleration factor;\\n \\nVo\\ngate voltage under typical operating conditions (in Volts);\\n \\nVt\\ngate voltage under accelerated test conditions (in Volts);\\n \\n\\xce\\xb2\\nvoltage acceleration coefficient (in 1/Volts).\\n4.6.2.4 \\nFailure rate distribution methods\\nThe previous sub-clauses detail several methods to determine the base failure rate for the \\nsemiconductor component. Depending on the methods, the overall semiconductor component failure \\nrate can be available as a single value or combination of package failure rate and die failure rate. During \\nthe safety analysis the semiconductor component failure rate is allocated to the failure modes of \\nelements composing the semiconductor component.\\nDifferent distribution methods can be applied:\\n\\xe2\\x80\\x95 \\nfailure rate distribution of the die part of the component (i.e. digital blocks, analogue blocks and \\nmemories). Two methods can be considered to extract or obtain the distribution:\\n\\xe2\\x80\\x95 \\nthe first method consists of using a failure rate per mm2 value obtained by dividing the die \\nfailure rate or the whole hardware component failure rate (if not separated into package and \\ndie contributions) by the die area of the hardware component. The failure rate distribution is \\ndone by multiplying the part or subpart area related to the failure mode under analysis by the \\nfailure rate per mm2 value; and\\n\\xe2\\x80\\x95 \\nthe second method is based on base failure rates and elementary subparts. This is done by \\nmaking an estimation of the number of equivalent gates (or number of transistors) for each \\npart, subpart or basic/elementary subpart related to the failure mode under analysis.\\n\\xe2\\x80\\x95 \\nfailure rate distribution of the package. This can be derived only when the failure rate of the \\npackage is available. In such a case, for pins that are safety-related, the distribution of the failure \\nrate can be done using a failure rate per pin value which is obtained by dividing the package failure \\nrate by the total number of pins of the package (safety-related or not).\\nNOTE \\nThe selection of the method used can be based on the layout (or planned layout) of the circuit under \\nanalysis or on the analysis of how failure modes are shared between the hardware elements.\\n \\n40 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 19 \\xe2\\x80\\x94 Failure rate distribution\\n4.6.2.5 \\nBase Failure Rate for MCM\\nThe base failure rate for Multi Chip Modules (MCM) is evaluated with care. If industry sources (or a \\nmodel such as the one described in 4.6.2.1.1) are used to estimate that failure rate, arguments are to be \\nprovided to justify the applicability or the customisation of that industry source.\\n4.7 Semiconductor dependent failure analysis\\n4.7.1 \\nIntroduction to DFA\\nThe goal of this sub-clause is to provide guidelines for the identification and analysis of possible \\ncommon cause and cascading failures between given elements, the assessment of their risk of violating \\na safety goal (or derived safety requirements) and the definition of safety measures to mitigate such \\nrisk if necessary. This is done to evaluate potential safety concept weaknesses and to provide evidence \\nof the fulfilment of requirements concerning independence resulting from ASIL decomposition (see \\nISO 26262-9:2018, Clause 5) or freedom from interference identified during coexistence analysis (see \\nISO 26262-9:2018, Clause 6).\\nThe scope of this sub-clause is the Dependent Failure Analysis (DFA) between hardware elements \\nimplemented within one silicon die and between hardware and software elements. The elements under \\nconsideration are typically hardware-elements and their safety mechanisms (specified during the \\nactivities of ISO 26262-5).\\nThe scope, analysis method(s) and the necessary safety measures can depend on the nature of the given \\nelements (e.g. only software elements, only hardware elements or a mix of hardware and software \\nelements) and the nature of the involved safety requirements (e.g. fail safe).\\nAs defined in ISO 26262-1:2018, 3.30, the Dependent Failure Initiator (DFI) is the single root cause \\nthat leads multiple elements to fail through coupling factors. A list of DFI is provided as a starting \\npoint, considering different systematic, environmental and random hardware issues (Table 21 to \\nTable 26). Some random hardware DFI, e.g. shared resources or interfering elements of the elements \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n41\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nunder consideration, can be considered within the standard safety analysis once the dependencies \\nare identified and can be classified as either residual faults, single-point faults or multiple-point faults \\n(ISO 26262-5:2018, 9.4.2.4, NOTE 1). The DFA addresses those DFI, which are not addressable within \\nthe standard safety analysis, in a qualitative way.\\nEXAMPLE \\nInterfering elements have the capability to corrupt resources of other hardware elements as \\na consequence of a random hardware fault or systematic fault: e.g. a DMA (direct memory access peripheral) \\nwrites to a wrong address and silently corrupts safety-related data.\\nThe list of DFI also contains some typical safety measures used to address these. The necessary safety \\nmeasures can depend on the nature of the safety requirement. One requirement could be to minimise \\nthe occurrence of the dependent failures in the field, another could be to ensure that dependent failures \\ndo not violate a safety goal.\\n4.7.2 \\nRelationship between DFA and safety analysis\\nThe elements for which a DFA is relevant, can already be identified from the safety analyses done in \\naccordance to ISO 26262-5:2018, 7.4.3.\\nThese can be:\\n\\xe2\\x80\\x94 dual-point failure scenarios such as:\\n\\xe2\\x80\\x94 functions and their safety mechanisms (including the fault reaction path \\xe2\\x80\\x94 the chain of elements \\nand/or tasks that are required to implement the fault reaction); and\\n\\xe2\\x80\\x94 functional redundancies (e.g. two current drivers or two A/D converters).\\n\\xe2\\x80\\x94 and single-point (residual) failure scenarios of shared elements that belong to the semiconductor \\ninfrastructure like:\\n\\xe2\\x80\\x94 clock generation;\\n\\xe2\\x80\\x94 embedded voltage regulators; and\\n\\xe2\\x80\\x94 any shared hardware resource used by the aforementioned elements.\\nThe safety analysis primarily focuses on identifying single-point faults and dual/multiple-point faults \\nto evaluate the targets for the ISO 26262-5 metrics and define safety mechanisms to improve the \\nmetrics if required. The DFA complements the analysis by ensuring that the effectiveness of the safety \\nmechanisms is not affected by dependent failures initiators. As mentioned in ISO 26262-5:2018, 7.4.3, the \\nsafety analysis can first be used to support the specification of the hardware design and subsequently \\nfor the verification of the hardware design. The DFA can be applied during the specification of the \\nhardware design (e.g. to specify safety mechanisms for the shared elements that have been identified) \\nand also to verify that the assumptions taken during the specification are realised and reach the \\nintended effectiveness.\\n4.7.3 \\nDependent failure scenarios\\nIn Figure 20, Element A and Element B are elements that have the potential to fail due to an external \\nroot cause. The root cause can be related to a random hardware fault or to a systematic fault.\\n \\n42 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 20 \\xe2\\x80\\x94 Schematic representation of a dependent failures and its DFI\\nTypical situations related to a random hardware fault can include failure of shared resources or single \\nphysical root cause. For these situations a failure rate could be quantified and could be considered in \\nthe safety analysis according to ISO 26262-5:2018, Clauses 8 and 9.\\nNOTE 1 \\nIn this case, the risk resulting from this DFI is evaluated within the quantitative safety analysis. \\nTherefore, no separate argument is necessary.\\nTypical situations related to systematic faults can include environmental faults, development faults, \\netc.. For these situations it is generally not possible to make a quantitative analysis. Additionally the \\nroot cause can be located inside the semiconductor element under consideration or located outside, \\npropagating into the semiconductor element through signal or power supply interfaces for instance.\\nFigure 20 refers to a coupling mechanism intended to characterise some exemplary properties of the \\ndisturbances created by a given root cause. Such properties can help to specify the mitigation measures \\nand also to define the adequate models that can be used to verify the effectiveness of the mitigation \\nmeasures (see 4.7.5.2). They are now introduced:\\n\\xe2\\x80\\x94 coupling mechanism: this characterizes the means by which a root cause induces a disturbance. \\nKnown coupling mechanisms are:\\n\\xe2\\x80\\x94 conductive coupling (electrical or thermal) that occurs when the coupling path between the \\nsource and the receiver is formed by direct contact with a conducting body, for example a \\ntransmission line, wire, cable, Printed-Circuit Board or \\xe2\\x80\\x9cPCB\\xe2\\x80\\x9d trace or metal enclosure; and\\n\\xe2\\x80\\x94 near field coupling that occurs where the source and receiver are separated by a short distance \\n(typically less than a wavelength). Strictly, \"Near field coupling\" can be of two kinds, electrical \\ninduction and magnetic induction. It is common to refer to electrical induction as capacitive \\ncoupling, and to magnetic induction as inductive coupling:\\n\\xe2\\x80\\x94 capacitive coupling that occurs when a varying electrical field exists between two adjacent \\nconductors typically less than a wavelength apart, inducing a change in voltage across the \\ngap; and\\n\\xe2\\x80\\x94 inductive coupling or magnetic coupling that occurs when a varying magnetic field exists \\nbetween two conductors in close proximity, typically less than a wavelength apart, inducing \\na change in voltage along the receiving conductor.\\n\\xe2\\x80\\x94 mechanical coupling occurs when mechanical force or stress is transferred from the source to \\nthe receiver via a physical medium.\\nEXAMPLE This can be relevant for MEMS, where a particular shock with a particular resonance and \\nwaveform might force the comb structures in an accelerometer to stick (also known as stiction). See \\n5.5.3.2 for more details.\\n\\xe2\\x80\\x95 \\nradiative coupling or electromagnetic coupling occurs when source and receiver are separated \\nby a large distance, typically more than a wavelength. Source and receiver act as radio antennas: \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n43\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nthe source emits or radiates an electromagnetic wave which propagates across the open space \\nin between and is picked up or received by the receiver.\\n\\xe2\\x80\\x94 propagation medium: this characterizes the coupling path the disturbance uses through the \\nsemiconductor element. Typically it can be:\\n\\xe2\\x80\\x95 \\nsignal lines;\\n\\xe2\\x80\\x95 \\nclock network;\\n\\xe2\\x80\\x95 \\npower supply network;\\n\\xe2\\x80\\x95 \\nsubstrate;\\n\\xe2\\x80\\x95 \\npackage; and\\n\\xe2\\x80\\x95 \\nair.\\n\\xe2\\x80\\x95 \\nlocality: this characterizes if the disturbance has the potential to affect multiple elements or is \\nlimited to a single element. In the latter case the affected element is assumed to produce a wrong \\noutput that propagates to multiple elements connected to it (cascading effects);\\n\\xe2\\x80\\x95 \\ntiming: this characterizes some properties of the disturbance related to its propagation delay (e.g. \\nfor propagation of temperature gradient) or its timing behaviour like periodicity (e.g. in the case of \\nripple noise over power supply), etc.\\nIn order to illustrate the aforementioned properties two examples are given in Figure 21 and Figure 22.\\nFigure 21 \\xe2\\x80\\x94 Dependent failures by physical coupling\\nIn Figure 21 Element A1 provides the outcomes used by Element C for implementing a safety function. \\nElement A1 and Element A2 are used as redundant elements compared by Element B hardware \\nComparator and in the case of mismatch (Failure A1 or Failure A2), the \\xe2\\x80\\x9chardware error\\xe2\\x80\\x9d signal is \\nactivated. In this example, the Element A1 and Element A2 can produce identical erroneous outputs \\n(Error A1 and Error A2) if both elements are affected by a fault that results from a same root cause. \\nThe presence of this possible dependent failure cannot be differentiated by Element B at the time that \\nElement A1 and A2 are compared.\\nNOTE 2 \\nIt is assumed for simplification that Element B itself is not affected by the disturbance. Taking into \\naccount the assumption that Element B is operational it is further assumed that as long as Error A1 and Error \\nA2 present some temporal or spatial dissimilarity, the dependent failures situation can be controlled. Such \\ndissimilarity can be the consequence of differences in the manner the disturbance propagates to both elements \\n(e.g. different propagation delay of a signal glitch that takes different physical routes to reach boundaries of \\nElement A1 and Element A2) or in differences in the effect (e.g. if the effect is a signal timing violation, it can have \\ndifferent effect on the respective logic of Element A1 and Element A2).\\n \\n44 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 22 \\xe2\\x80\\x94 Dependent failures due to resource sharing\\nFigure 22 extends Figure 21 where Element A1 and Element A2 produce erroneous outputs caused by \\nan erroneous output of the shared Element X that is affected by a fault that results from a root cause \\nexternal to the element itself. The erroneous output of Element X propagates to both Element A1 and \\nElement A2. Element X is representative of the dependent failures initiators that fall into the category \\n\\xe2\\x80\\x9cShared Resources\\xe2\\x80\\x9d.\\n4.7.4 \\nDistinction between cascading failures and common cause failures\\nDependent failures analysis addresses both common cause failures and cascading failures. While in \\nsome cases this differentiation is necessary (such as for ISO 26262-9:2018, Clause 7), in other cases \\n(such as for semiconductor devices) the exact differentiation between a cascading failure and a common \\ncause failure in a given failure scenario is not always possible or useful. In this case, the two failure \\nscenarios are not differentiated any further.\\nIf the focus of the DFA is to provide evidence of freedom from interference (coexistence) between two \\ngiven elements (e.g. Element A and Element B) as required in ISO 26262-9:2018, Clause 7, the following \\napproach can be used:\\n\\xe2\\x80\\x94 identify the failure modes of Element A that can have an impact on Element B;\\n\\xe2\\x80\\x94 identify if these failure modes lead to possible violation of the safety goal due to Element B failure;\\n\\xe2\\x80\\x94 if necessary define appropriate safety measures to mitigate the risk (e.g. for a DMA specify a safety \\nmechanism that monitors the addresses generated by the DMA); and\\n\\xe2\\x80\\x94 if necessary repeat this analysis with switched roles.\\n4.7.5 \\nDependent failure initiators and mitigation measures\\n4.7.5.1 \\nList of dependent failure initiators and related mitigation measures\\nThe following classification of DFI can be used:\\n\\xe2\\x80\\x94 failure of shared resources;\\n\\xe2\\x80\\x94 single physical root cause;\\n\\xe2\\x80\\x94 environmental faults;\\n\\xe2\\x80\\x94 development faults;\\n\\xe2\\x80\\x94 manufacturing faults;\\n\\xe2\\x80\\x94 installation faults; and\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n45\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x94 service faults.\\nNOTE 1 \\nOther classifications of DFI are possible.\\nFor each class of dependent failures, possible measures are provided.\\nNOTE 2 \\nThe listed measures are examples provided as a non-exhaustive list of possible solutions. Their \\neffectiveness depends on several factors including the type of circuits and the technology which means that their \\neffectiveness for possible DFIs will vary. For that reason, it is recommended to provide evidence to demonstrate \\nthe claimed effectiveness. Some measures by themselves can be not enough to achieve an appropriate risk \\nreduction. In this case an appropriate combination of different measures can be chosen.\\nThe measures have been split into:\\n\\xe2\\x80\\x95 \\nmeasures which prevent the dependent failures occurring during operation; and\\n\\xe2\\x80\\x95 \\nmeasures which do not prevent the occurrence of the dependent failures but prevent them from \\nviolating a safety goal.\\nNOTE 3 \\nDFIs that are caused by software are not included in this DFIs list. Correct software development is \\naddressed by ISO 26262-6. Results of the DFA can affect the ASIL allocation of software elements.\\nNOTE 4 \\nService in automotive typically happens by replacement of the whole ECUs or sensor modules. \\nSemiconductor components are typically not serviced. Therefore service faults are usually not DFI for \\nsemiconductor parts.\\n \\n46 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 21 \\xe2\\x80\\x94 Dependent failure initiators due to random hardware faults of shared resources\\nDFI examples\\nFailures in common clock elements (including PLL, clock trees, clock enable sig-\\nnals, etc.)\\nFailures in common test logic including DFT (Design for Test) signals, scan chains etc., \\ncommon debug logic including debug routing network (network that provides access \\nto analogue or digital signals or enables reading of digital registers) and trace signals \\n(mechanism to trace one or more signals synchronously, e.g. controlled by triggers or \\ntrace clocks and read the result afterwards)\\nFailures in power supply elements including power distribution network, common \\nvoltage regulators, common references (e.g. band-gaps, bias generators and related \\nnetwork)\\nNon simultaneous supply switch on, that can cause effects like latch up or high in-\\nrush current\\nFailures in common reset logic including reset signals\\nFailures in shared modules (e.g. RAM, Flash, ADC, Timers, DMA,\\nInterrupt Controller, Busses, etc.)\\nMeasures to prevent \\ndependent failures \\nfrom violating the \\nsafety goal\\nDedicated independent monitoring of shared resources (e.g. clock monitoring, voltage \\nmonitoring, ECC for memories, CRC over configuration register content, signalling of \\ntest or debug mode)\\nSelective hardening against soft errors or selected redundancy\\nSelf-tests at start-up or post-run or during operation of the shared resources\\nDiversification of impact (e.g. clock delay between master & checker core, diverse \\nmaster and checker core, different critical paths)\\nIndirect detection of failure of shared resource (e.g. cyclic self-test of a function that \\nwould fail in the case of a failure of the shared resource)\\nIndirect monitoring using special sensors (e.g. delay lines used as common-cause \\nfailure sensors)\\nMeasures to prevent \\nthe occurrence of \\ndependent failures \\nduring operation\\nFault avoidance measures (e.g. conservative specification), functional redundancies \\nwithin shared resources (e.g. multiple via/contacts),\\nFault diagnosis (e.g. ability of identifying and isolating or reconfiguring/replacing \\nfailing shared resources, corresponding design rules)\\nDedicated production tests (e.g. end-of-line tests for SRAM capable of finding com-\\nplex faults)\\nSeparate resources to reduce the amount or scope of shared resources\\nAdaptive measures to reduce susceptibility (e.g. voltage/operating frequency decrease)\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n47\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 22 \\xe2\\x80\\x94 Dependent failures initiators due to random physical root causes\\nDFI examples\\nShort circuits (e.g.: local defects, electro migration, via migration, contact migration, \\noxide break down)\\nLatch up\\nCross talk (substrate current, capacitive coupling)\\nLocal heating caused e.g. by defective voltage regulators or output drivers\\nMeasures to prevent \\ndependent failures \\nfrom violating the \\nsafety goal\\nDiversification of impact (e.g. clock delay between master & checker core, diverse \\nmaster and checker core, different critical paths)\\nIndirect detection (e.g. cyclic self-test of a function that would fail in the case of phys-\\nical root cause) or indirect monitoring using special sensors (e.g. delay lines used as \\ncommon-cause failure sensors)\\nMeasures to prevent \\nthe occurrence of \\ndependent failures \\nduring operation\\nDedicated production tests\\nFault avoidance measures (e.g. physical separation/isolation, corresponding de-\\nsign rules)\\nPhysical separation on a single chip\\nTable 23 \\xe2\\x80\\x94 Systematic dependent failure initiators due to environmental conditions\\nDFI examples\\nTemperature\\nVibration\\nPressure\\nHumidity/Condensation\\nCorrosion\\nEMI\\nOvervoltage applied from external\\nMechanical stress\\nWear\\nAging\\nWater and other fluids intrusion\\nMeasures to prevent \\ndependent failures \\nfrom violating the \\nsafety goal\\nDiversification of impact (e.g. clock delay between master & checker core, diverse \\nmaster and checker core, different critical paths)\\nDirect monitoring of environmental conditions (e.g. temperature sensor) or indirect \\nmonitoring of environmental conditions (e.g. delay lines used as dependent -failure \\nsensors)\\nMeasures to prevent \\nthe occurrence of \\ndependent failures \\nduring operation\\nFault avoidance measures (e.g. conservative specification/robust design)\\nPhysical separation (e.g. distance of the die from a local heat source external to the die)\\nAdaptive measures to reduce susceptibility (e.g. voltage/operating frequency \\ndecrease)\\nLimit the access frequency or limit allowed operation cycles for subparts (e.g. specify \\nthe number of write cycles for an EEPROM)\\nRobust design of semiconductor packaging\\n \\n48 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 24 \\xe2\\x80\\x94 Systematic dependent failure initiators due to development faults\\nDFI examples\\nRequirement faults\\nSpecification errors\\nImplementation faults, i.e. incorrect implementation of functionality\\nLack or insufficiency of design measures to avoid crosstalk\\nLack or insufficiency of Latch up prevention measures\\nWrong configuration\\nLayout faults, such as incorrect routing e.g. over redundant blocks, insufficient insu-\\nlation, insufficient separation or isolation, insufficient EMI shielding\\nTemperature due to heating of power consuming parts of the die Temperature gradi-\\nents causing mismatches within sensitive measurement circuitry\\nMeasures to prevent \\ndependent failures \\nfrom violating the \\nsafety goal\\nMonitors (e.g. protocol checkers)\\nMeasures to prevent \\nthe occurrence of \\ndependent failures \\nduring operation\\nDesign process compliant with the ISO 26262 series of standards\\nDiversity (Depending on the DFI, diversity can be intended either as implementa-\\ntion/functional/architectural diversity or as development diversity)\\nTable 25 \\xe2\\x80\\x94 Systematic dependent failure initiators due to manufacturing faults\\nDFI examples\\nRelated to processes procedures and training\\nFaults in control plans and in monitoring of special characteristics\\nRelated to software flashing and end-of-line programming (e.g. wrong versions or \\nwrong programming conditions, protocols or timings)\\nMask misalignment\\nIncorrect End-of-Line trimming or fusing (e.g. Laser trimming, OTP or EEPROM pro-\\ngramming of calibration coefficients or customization settings)\\nMeasures to prevent \\ndependent failures \\nfrom violating the \\nsafety goal\\nnone\\nMeasures to prevent \\nthe occurrence of \\ndependent failures \\nduring operation\\nDedicated production tests\\nCompliance to ISO 26262 series of standards (see 4.9)\\nDiversity (depending on the DFI, diversity can be intended either as implementation/\\nfunctional/architectural diversity or as development diversity)\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n49\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 26 \\xe2\\x80\\x94 Systematic dependent failure initiators due to installation faults\\nDFI examples\\nRelated to wiring harness routing\\nRelated to the inter-changeability of parts\\nFailures of adjacent items or parts or elements. (e.g. wrong configuration of a con-\\nnected interface delivering data to an input, or incorrect load on a driven output)\\nWrong PCB connection\\nWrong configuration (e.g. of spare memory usage)\\nMeasures to prevent de-\\npendent failures from \\nviolating the safety goal\\nNone\\nMeasures to prevent \\nthe occurrence of \\ndependent failures \\nduring operation\\nDedicated installation tests\\nCompliance to ISO 26262 series of standards (see 4.9)\\nDiversity (depending on the DFI), diversity can be intended either as implementa-\\ntion/functional/architectural diversity or as development diversity\\n4.7.5.2\\t\\nVerification\\tof\\tmitigation\\tmeasures\\nThis sub-clause introduces exemplary methods to evaluate the effectiveness to control or avoid \\ndependent failures. The methods can be based on:\\n\\xe2\\x80\\x94 analytical approach using known principles;\\nEXAMPLE 1 \\nReference [4] and similar provide analytical approaches that can be used as a basis to \\nevaluate the effectiveness of the provided safety measures addressing dependent failures.\\n\\xe2\\x80\\x94 pre-silicon simulation using documented test protocols to provide evidence of robustness against \\nthe identified DFI;\\nEXAMPLE 2 \\nTest protocols that allow simulation of clock or power supply disturbances, EMI simulations \\netc. The simulation can be based on different levels of abstraction (based on the fault model to be targeted) \\nand use adequate fault injection techniques to produce the intended disturbance.\\n\\xe2\\x80\\x94 post-silicon robustness tests (e.g. EMI test, burn-in studies, accelerated aging test, electrical stress \\ntests); and\\n\\xe2\\x80\\x94 expert judgment supported by documented rationale.\\nA combination of measures can be used, e.g. References [24], [21] and similar provide a mix of \\nanalytical, fault injection and expert judgment based approaches that can be used as a basis to evaluate \\nthe effectiveness of the provided safety measures addressing dependent failures.\\nNOTE 1 \\nThe results and the arguments are documented and justified.\\nNOTE 2 \\nFollowing what is noted in ISO 26262-9:2018, 7.4.2, NOTE, the use of beta factors as in IEC 61508-\\n2:2010 [14] for the quantification of coupling effects is not considered in general a sufficiently reliable method.\\nThe level of detail of the evaluation is commensurate with the type of DFI, the claimed safety measures \\nand application.\\nAs stated in the EXAMPLE in ISO 26262-9:2018, 7.4.7, diversity is a measure that can be used to prevent, \\nreduce or detect common cause failures. In case diversity is used as a method to control or avoid \\ndependent failures, a rationale is provided to demonstrate that the level of implemented diversity is \\ncommensurate to the targeted DFI.\\nEXAMPLE 3 \\nA rationale can be provided with a combination of analytical approach and fault injection (e.g. as \\ndescribed in Reference [24]). For details on fault injection, see 4.8.\\n \\n50 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nIn the case where isolation or separation is used as a method to control or avoid dependent failures, \\na rationale is provided to demonstrate that the level of implemented isolation or separation is \\ncommensurate to the targeted DFI.\\nEXAMPLE 4 \\nSimulation can be used to provide evidence that the distance between two separated blocks is \\nsufficient to avoid the targeted DFI.\\n4.7.6\\t\\nDFA\\tworkflow\\nThe purpose of the DFA workflow is to identify the main activities that are judged necessary to \\nunderstand the operation of the safety measures that are implemented to assure achievement of the \\nsafety requirements and verify that they comply with the requirements for independence or freedom \\nfrom interference.\\nFigure\\t23\\t\\xe2\\x80\\x94\\tDFA\\tworkflow\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n51\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 1 \\nFirmware and any micro-code running on programmable HW elements, irrespective of whether they \\nare classified as CPUs or not, can be considered to be SW elements.\\nNOTE 2 \\nSafety measures can be activities that show a failure is not relevant for the DFA.\\n4.7.6.1\\t\\nDFA\\tdecision\\tand\\tidentification\\tof\\thardware\\tand\\tsoftware\\telements\\t(B1)\\nA DFA is conducted, according to ISO 26262-9:2018, Clause 7, whenever a semiconductor element is \\nrequired to have independence or freedom from interference e.g.:\\n\\xe2\\x80\\x95 \\ndiagnostic functions assigned to hardware or software elements;\\n\\xe2\\x80\\x95 \\nsimilar or dissimilar redundancy of hardware or software elements;\\n\\xe2\\x80\\x95 \\nshared resources on the hardware component or part (e.g. clock, reset, supply memory, ADC, I/O, \\ntest logic);\\n\\xe2\\x80\\x95 \\nexecution of multiple software tasks on shared hardware;\\n\\xe2\\x80\\x95 \\nshared software functions (e.g. I/O-routines, interrupt handling, configuration, math library or \\nother library functions); and\\n\\xe2\\x80\\x95 \\nindependence requirements derived from ASIL decomposition on system or element level that affect \\ndifferent elements on the IC, where the DFA needs to provide evidence of sufficient independence \\nin the design or that the potential common causes lead to a safe state (refer to ISO 26262-9:2018, \\nClause 5).\\nThe inputs to this step are:\\n\\xe2\\x80\\x95 \\nthe technical safety requirements, in particular the independence and freedom from interference \\nrequirements resulting from the safety concept on system level;\\n\\xe2\\x80\\x95 \\nthe description of the architecture, which can include block diagrams, flow charts, fault trees, state \\ndiagrams, hardware partitioning, software partitioning; and\\n\\xe2\\x80\\x95 \\nthe safety measures.\\nThe focus of this step is to analyse the architecture and identify each pair or group of elements that \\ncan be affected by any of the above listed cases and evaluate if the architectural description is detailed \\nenough to capture the overall design dependencies. The outcome of this step is a list of each pair or \\ngroup of elements that can be affected by dependent failures and associated independence or freedom \\nfrom interference requirements.\\n4.7.6.2\\t\\nIdentification\\tof\\tDFI\\t(B2)\\nThis step is based on the prior architectural analysis and it targets a check of the completeness of the \\nderived independence or freedom from interference requirements and breaks them down wherever \\ndifferent initiators can lead to a dependent failure.\\nA list of typical DFI as provided in 4.7.5.1 can be used to prove whether known dependent failures, \\nother than those that were derived from the architecture, can be applied. Further it is crosschecked if \\ndependent failures mechanisms were identified during the quantitative analysis.\\nThe outcome of this step is a consolidation of the list from the previous step.\\n4.7.6.3\\t\\nSufficiency\\tof\\tinsight\\tprovided\\tby\\tthe\\tavailable\\tinformation\\ton\\tthe\\teffect\\tof\\tidentified\\t\\nDFI (B3 & B4)\\nThis step verifies that the available documentation provides sufficient insight to each DFI that was \\nevaluated during previous steps. Where additional information is required to judge the validity of a DFI \\n \\n52 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nfor the target architecture, it is added and the identification of the DFI (step 2) is finished based on the \\nupdated descriptions.\\nNOTE \\nA hierarchical approach is recommended so that the analysis can be performed at an appropriate \\nlevel of detail. For instance a top level view reveals what the shared resources are. Then a breakdown view that \\nencapsulates a hardware subpart and its safety measures can be used to identify dependencies at the design level.\\n4.7.6.4 \\nConsolidation of list of relevant DFI (B5)\\nBased on the information provided, the list of identified DFA relevant elements, independence \\nrequirements and the related DFI for the fulfilment of the safety requirements is consolidated (e.g. by \\nreview).\\nFrom the consolidated list, dependent failures that are caused by random hardware faults can be \\nincorporated into the quantitative analysis of the required metrics in accordance with ISO 26262-5:2018 \\nClauses 8 and 9.\\n4.7.6.5\\t\\nIdentification\\tof\\tnecessary\\tsafety\\tmeasures\\tto\\tcontrol\\tor\\tmitigate\\tDFI\\t(B6)\\nIn order to fulfil independence requirements or freedom from interference requirements, necessary \\nsafety measures are added to mitigate the effect of the dependent failures that are relevant for the \\ntarget architecture.\\nSub-clause 4.7.5.1 provides a list of examples of DFI and measures known to be effective. Finally the \\nrequired safety measures are documented.\\nNOTE 1 \\nFor dependent failures that arise from random hardware faults the result of the quantitative \\nanalysis can be used to identify those that are relevant to achieve the targeted metrics in accordance with \\nISO 26262-5:2018 Clauses 8 and 9.\\nNOTE 2 \\nIf quantifiable random hardware failures are identified as being possible DFIs (e.g. a shared oscillator \\ndelivering a clock that is too fast for the timing constraints of a digital core; overvoltage delivered to an internal \\nsupply due to a fault of a supply voltage regulator) they are taken into account for the quantitative analysis \\n(see ISO 26262-5:2018, 9.4.3.2, NOTE 1). For the case that they are not quantifiable (e.g. the influence of timing \\neffects caused by a fault in a clock tree; thermal coupling effects between an element and its safety mechanism; \\nsubstrate currents due to a fault in one of the blocks) the evaluation and definition of mitigation measures is \\ncontinued qualitatively (see ISO 26262-9:2018, 7.4.2).\\n4.7.6.6\\t\\nSufficiency\\tof\\tinsight\\tprovided\\tby\\tthe\\tavailable\\tinformation\\ton\\tthe\\tdefined\\tmitigation\\t\\nmeasures (B7 & B8)\\nThis step verifies that the available documentation provides sufficient insight to analyse the \\neffectiveness of the safety measures that were introduced during the previous step. If the information \\navailable is deemed insufficient for proper evaluation, additional details can be added to the DFI \\nmitigation measure definition.\\n4.7.6.7 \\nConsolidate list of safety measures (B9)\\nThe list of the defined safety measures for the mitigation of dependent failures is consolidated based on \\nthe updated documentation (e.g. by review).\\nNOTE 1 \\nFor safety measures that were incorporated into the quantitative analysis (see B5) the effect of the \\nsafety measure can also be evaluated quantitatively.\\nNOTE 2 \\nAdditional safety measures which are introduced to mitigate DFIs, irrespective of whether they were \\nintroduced due to quantitative or qualitative evaluation, change the chip area and thus influence the failure rate \\ndistribution over each part of the chip. Thus the quantitative analysis usually is updated.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n53\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n4.7.6.8 \\nEvaluation of the effectiveness to control or to avoid the dependent failures (B10)\\nThe effectiveness of the introduced safety measures to mitigate or avoid dependent failures is verified. \\nThe verification methods that can be applied are identical to those that are applied in the case of safety \\nmeasures defined to avoid or mitigate the effect of random hardware or systematic failures according \\nto ISO 26262-5:2018, Clause 10. The following techniques can be useful:\\n\\xe2\\x80\\x95 \\nFTA, ETA, FMEA;\\n\\xe2\\x80\\x95 \\nfault injection simulation;\\n\\xe2\\x80\\x95 \\napplication of specific design rules based on technology qualification tests;\\n\\xe2\\x80\\x95 \\noverdesign with respect to e.g. device voltage classes or distances;\\n\\xe2\\x80\\x95 \\nstress testing with respect to temperature profile or overvoltage of supply and inputs;\\n\\xe2\\x80\\x95 \\nEMC and ESD testing; and\\n\\xe2\\x80\\x95 \\nexpert judgement.\\nNOTE 1 \\nThe results and the arguments are documented and justified.\\nThe elements used to implement the safety measures are included in the quantitative analysis according \\nto ISO 26262-5:2018, Clause 8 and 9.\\nNOTE 2 \\nIn the case where an introduced safety measure can be the subject of dependent failures as well, their \\navoidance or mitigation is evaluated by (re)applying the DFA procedure for the newly introduced dependent \\nfailures.\\nNOTE 3 \\nIf there is proven experience with similar measures to mitigate dependent failures, it can be used to \\njudge effectiveness of the measure under analysis, given that the transferability of the result can be argued.\\nNOTE 4 \\nDuring the analysis, possible relationships between the hardware and software can be considered \\n(see ISO 26262-6:2018, Clause 6)\\n4.7.6.9\\t\\nAssessment\\tof\\trisk\\treduction\\tsufficiency\\tand\\tif\\trequired\\timprove\\tdefined\\tmeasures\\t\\n(B11 & B12)\\nTo close the DFA an evaluation of the remaining risks of dependant failures is completed. If the \\nmitigation is not regarded to be sufficient, the safety measure is improved (B12) and the evaluation of \\nthe effectiveness is repeated.\\nFor the case that residual risks can be quantified, they could be accounted in the quantitative analysis \\n(if not already done in the quantitative analysis path via B5 & B9). For example in the case of a function \\nand its safety mechanism which are affected by a dependent failure, the failure mode coverage of the \\nsafety mechanism is reduced accounting for the unmitigated dependencies.\\nNOTE \\nIf the targeted metrics of quantitative analyses are achieved, risk is understood as sufficiently low \\nfrom the random hardware fault point of view, even if no safety measure is allocated to the hardware element \\nwhich is affected by the fault that was identified as relevant DFI. Systematic DFIs concerning the same element \\nare handled in the DFA on a qualitative base and can lead to the definition of safety measures independent of the \\nquantitative analysis result.\\n4.7.7 \\nExamples of dependent failures analysis\\nDetailed examples of dependent failures analysis according to this sub-clause are described in Annex B \\nof this document.\\n \\n54 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n4.7.8 \\nDependent failures between software element and hardware element\\nHardware and software dependent failures are in general considered separately. A joint consideration of \\nhardware and software dependent failures is done in cases in which the safety mechanism addressing \\nthe hardware is implemented in software.\\nEXAMPLE 1 \\nSoftware based CPU Self-Test is combined with an independent hardware watchdog so that in \\ncase the CPU fails either the CPU Self-Test will detect it or the watchdog would catch it.\\nEXAMPLE 2 \\nWithin the E-GAS concept [55] the layer 2 software monitors the layer 1 software. Both software \\nelements can run on the same hardware element. Layer 1 and layer 2 are already diverse to each other which \\ncontributes to the reduction of dependent faults violating the safety goal. To further reduce the probability \\nof safety goal violation due to dependent faults in hardware, additional safety measures are introduced, e.g. \\na program flow monitoring and a CPU Self-Test to address dependent failures in the CPU, inverted redundant \\nstorage of important layer 2 variables in the RAM module and an independent challenge and response watchdog \\nto ensure the relevant software modules have been executed.\\n4.8 Fault injection\\n4.8.1 \\nGeneral\\nFault injection at the semiconductor component level is a known methodology (see References [30], \\n[31], [32], [33] and [21]) which can be used to support several activities of the lifecycle when the safety \\nconcept involves semiconductor components.\\nIn particular, for semiconductor components, fault injection can be used for:\\n\\xe2\\x80\\x95 \\nsupporting the evaluation of the hardware architectural metrics; and\\n\\xe2\\x80\\x95 \\nevaluating the diagnostic coverage of a safety mechanism;\\nNOTE 1 \\nIf it is impractical to achieve accurate results in a reasonable time with reasonable resources, \\nthen it is possible to limit the scope of the injection campaign (e.g. injection campaigns on IP block level \\nonly), use only analytical methods or use a combination of analytical methods and fault injection.\\nEXAMPLE 1 \\nFault injection is used to verify the diagnostic coverage provided by software-based \\nhardware tests or hardware-based safety mechanisms such as hardware built-in self-test.\\n\\xe2\\x80\\x95 \\nevaluating the diagnostic time interval and the fault reaction time interval; and\\n\\xe2\\x80\\x95 \\nconfirming the fault effect.\\nEXAMPLE 2 \\nFault injection is used to evaluate the probability that a fault will result in an observable \\nerror at the output of an IP in the context of specific inputs, for example to compute the architectural \\nvulnerability factor for transient faults as described in Reference [25].\\n\\xe2\\x80\\x95 \\nsupporting the pre-silicon verification of a safety mechanism with respect to its requirements, \\nincluding its capability to detect faults and control their effect (fault reaction).\\nEXAMPLE 3 \\nFault injection is used to cause an error to trigger a hardware-based safety mechanism and \\nverify the correct reaction at related software-level.\\nEXAMPLE 4 \\nFault injection is used during pre-silicon verification of safety mechanisms to verify specific \\ncorner cases.\\nEXAMPLE 5 \\nFault injection is used during integration of the safety mechanisms to verify interconnectivity.\\n4.8.2 \\nCharacteristics or variables of fault injection\\nWith respect to fault injection, the following information can help the verification planning:\\n\\xe2\\x80\\x95 \\nthe description and rationale of the fault models, and related level of abstraction;\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n55\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\ntype of safety mechanism including required confidence level;\\n\\xe2\\x80\\x95 \\nobservation points and diagnostic points;\\n\\xe2\\x80\\x95 \\nfault site, fault list; and\\n\\xe2\\x80\\x95 \\nworkload used during fault injection.\\nIn particular, the verification planning describes and justifies:\\n\\xe2\\x80\\x95 \\nthe fault model and the related level of abstraction:\\n\\xe2\\x80\\x95 \\nAs clarified in the following clauses for DFA, digital, analogue and PLD, fault injection can be \\nperformed at the appropriate level depending on the fault model being considered, the specific \\nsemiconductor technology, feasibility, observability and use case; and\\nNOTE 1 \\nDepending on the purpose, fault injection can be implemented at different abstraction levels \\n(e.g. semiconductor component top-level, part or subpart level, RTL, etc.). A rationale for the abstraction \\nlevel is provided.\\nEXAMPLE 1 \\nSelection of the abstraction level can also depend on the nature of the fault that is \\nintended to be modelled by fault injection: a stuck-at fault can be injected in a gate level netlist, whereas \\nfor bit-flips an RTL abstraction is sufficient.\\nNOTE 2 \\nSelection can also depend on the required accuracy.\\nEXAMPLE 2 \\nThe evaluation of the diagnostic coverage for a CPU software-based hardware test by \\nthe injection of port faults or net faults in a gate level netlist, has a high confidence level.\\n\\xe2\\x80\\x95 \\nthe level at which to observe the effect of faults (observation points) and at which to observe \\nthe reaction of a safety mechanism (diagnostic points).\\nEXAMPLE 3 \\nFor the verification of the diagnostic coverage of a parity circuit, the observation and \\ndiagnostic points can be set at the part or subpart level.\\nEXAMPLE 4 \\nFor the verification of the diagnostic coverage of a loopback between different IOs, they \\ncan be set at the top level.\\nNOTE 3 \\nIf top level fault injection is not feasible, for example, due to the complexity of the \\nsemiconductor component under test, fault injection can be performed at the part or subpart level \\nby creating a model of the safety mechanism in the simulation environment itself. Observation and \\ndiagnostic points are set accordingly. Evidence is provided to show that the model used sufficiently \\nreflects the safety properties of the safety mechanism.\\nEXAMPLE 5 \\nIn the complete RTL representation of a microcontroller with a watchdog, the watchdog \\nis replaced by a functionally equivalent model.\\n\\xe2\\x80\\x95 \\nthe fault injection method. Depending on the purpose, feasibility and observability, fault injection \\ncan be implemented via different methods;\\nEXAMPLE 6 \\nDirect fault injection where the fault site is known; fault injection by formal methods; fault \\ninjection by emulation; fault injection by irradiation.\\n\\xe2\\x80\\x95 \\nthe location (fault site) and number of faults (fault list) to be injected, considered in relationship to \\nthe failure mode being verified.\\nNOTE 4 \\nA sampling factor can be used to reduce the fault list, if justified with respect to the specified \\npurpose, confidence level, type/nature of the safety mechanism, selection criteria etc.\\nNOTE 5 \\nSelection criteria include (e.g. References [57] and [58]): Sample size n (e.g. how many faults \\nand time points were simulated or analysed); the result of the analysis of the sample p (e.g. the ratio of \\nstuck-at faults detected by a safety mechanism); the \\xe2\\x80\\x9cdesired confidence\\xe2\\x80\\x9d \\xce\\xb1; the margin of error (Confidence \\nInterval) CI, sometimes denoted by a value d such that the margin of error is p \\xc2\\xb1 d; statistical independence. \\nA justification is provided for the choices.\\n \\n56 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b\" \\nISO 26262-11:2018(E)\\nEXAMPLE 7 \\nWhen verifying the diagnostic coverage of a dual-core lock-step, the relevant fault population \\ncould be limited to the compared CPU outputs and related fault locations.\\nEXAMPLE 8 \\nWhen verifying the diagnostic coverage of a software-based hardware test, CPU internal \\nfaults are relevant.\\nNOTE 6 \\nTechniques like fault collapsing can also be used to reduce the faults population to prime faults.\\n\\xe2\\x80\\x95 \\nthe fault injection controls, with respect to the related claim in the respective safety analysis; and\\nEXAMPLE 9 \\nFault injection controls can include the type of fault to be injected, the duration of a transient \\nfault, the number of faults injected in a simulation run, time and location of fault occurrence and the window \\nof observation of the expected action of a safety mechanism.\\n\\xe2\\x80\\x95 \\nthe test bench (workload) used during fault injection. Depending on the specific purposes, the test \\nbench can be derived from the functional test suite of the circuit or from a test bench similar to the \\nexpected use case.\\nEXAMPLE 10 \\nFor the verification of the completeness and correctness of a dual-core lock-step comparator, \\na basic workload is used, i.e. stimulating only a portion of the CPU such as the outputs.\\nEXAMPLE 11 \\nFor the verification of the diagnostic coverage of an asymmetric redundancy, a set of stimuli \\nderived from the functional test suite is used.\\nEXAMPLE 12 \\nFor the verification of Fsafe (see Reference [61]) for transient faults, a workload similar to the \\nexpected use case is considered.\\nEXAMPLE 13 \\nFor a software based hardware test for a CPU, the workload is primarily the test itself.\\n4.8.3 \\nFault injection results\\nResults of fault injection can be used to verify the safety concept and the underlying assumptions as \\nlisted in 4.8.1 (e.g. the effectiveness of the safety mechanism, the diagnostic coverage and number of \\nsafe faults).\\nNOTE 1 \\nEvidence of fault injection is maintained in the case of inspections during functional safety audits.\\nNOTE 2 \\nAn exact correspondence between the fault simulated and the fault identified in the safety analysis \\n(e.g. for open faults) could not always exist. In such a case refinement of the safety analysis can be based on the \\nresults of other representative faults (e.g. N-detect testing as reported in 5.1.10.2).\\n4.9 Production and Operation\\n4.9.1 \\nAbout Production\\nThe first objective of ISO 26262-7:2018 Clauses 5 and 6 is to develop and maintain a production process \\nfor safety-related elements or items that are intended to be installed in road vehicles.\\nSemiconductor products typically use standardised production processes such as wafer processing and \\ndie assembly operations. It is possible that a production process is developed for a specific product or \\npackage, but this is less common than using a standardised flow. It is not generally possible to identify \\ndistinct steps in the process flow as being safety-related or not, so everything is considered as being \\nsafety-related.\\nA semiconductor product is typically designed using a target process technology and an associated \\nlibrary of device models that represent the electrical characteristics of a device fabricated with \\nthat technology. Element design is implemented in a process technology by following a sequence of \\nstandardised manufacturing processes (e.g. diffusion, oxide deposition, ion implantation, die assembly) \\neach of which typically has risk mitigation in place through methods such as process FMEA and \\ncontrol plans. Libraries of device models used during product development represent the devices (e.g. \\ntransistors, resistors, capacitors) fabricated in that process technology. The element's safety-related \\nproduction requirements can be fulfilled by following a controlled semiconductor manufacturing \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n57\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n\"\n",
      "b' \\nISO 26262-11:2018(E)\\nprocess compliant with a quality standard. The product and process are both also verified by a \\nmanufacturing test. The manufacturing test evaluates element performance against the element\\'s \\nelectrical specification. Manufacturing process performance is evaluated against the process control \\nspecification as per the process control plan. This testing process helps assure that the manufactured \\nelement complies with its requirements including the hardware safety requirements.\\n4.9.2 \\nProduction Work Products\\nThe requirements of ISO 26262-7:2018, Clauses 5 and 6 could be complied with by meeting the \\nrequirements of a quality management system compliant to standards such as IATF 16949:2016 [51]. A \\nsemiconductor supplier or subcontractor with a quality management system compliant to such standard \\ncan find that existing work products can be partially or fully reused to satisfy the requirements of \\nISO 26262-7:2018, Clauses 5 and 6.\\nEXAMPLE 1 \\nThe safety-related content of the production control plan (see ISO 26262-7:2018, 5.5.2) can \\npartially or fully re-use the content of the quality management system\\'s production control plan.\\nEXAMPLE 2 \\nThe control measures report (see ISO 26262-7:2018, 6.5.1) can partially or fully re-use the content \\nof the quality management system\\'s control measures report.\\n4.9.3 \\nAbout service (maintenance and repair), and decommissioning\\nTypically, within the context of ISO 26262 series of standards, semiconductor components have no \\nmaintenance or decommissioning requirements, and are not serviceable. As a result, the safety plan \\nwill typically tailor out the work products associated with maintenance, repair and decommissioning \\nas they are out of scope for a semiconductor element.\\nAn alignment on expectations for both the semiconductor supplier and the customer concerning service \\nand decommissioning can be included in the DIA.\\n4.10 Interfaces within distributed developments\\nISO 26262\\xe2\\x80\\x938:2018, Clause 5 describes the procedures and allocates responsibilities within distributed \\ndevelopments for items and elements. The goal of this sub-clause is to clarify the term \"supplier\" with \\nrespect to distributed developments involving semiconductors.\\nIf the semiconductor developer is part of a distributed development as a supplier, it is subject to the \\nrequirements of ISO 26262-8:2018 Clause 5. The customer (i.e. Tier 1 or semiconductor integrator) \\nis responsible for managing the semiconductor developer as a supplier with respect to safety-related \\ndevelopment responsibility. Work products of ISO 26262-8:2018, Clause 5 which can be executed by the \\nsemiconductor developer in this context include but are not limited to:\\n\\xe2\\x80\\x95 \\ndevelopment interface agreement (ISO 26262-8:2018, 5.5.2); and\\n\\xe2\\x80\\x95 \\nsupplier\\'s safety plan (ISO 26262-8:2018, 5.5.3).\\nA semiconductor developer can also be a customer in a distributed development. Suppliers to \\nsemiconductor developers can be internal or external to the semiconductor developer\\'s organization. \\nIn all such cases the semiconductor developer is responsible for managing their suppliers with \\nrespect to safety-related development responsibility. The supplier\\'s work products for compliance \\nto ISO 26262-8:2018, Clause 5 become part of the semiconductor developer\\'s safety argument. Work \\nproducts of ISO 26262-8:2018, Clause 5 which can be executed by the semiconductor developer in this \\ncontext include but are not limited to:\\n\\xe2\\x80\\x95 \\ndevelopment interface agreement (ISO 26262-8:2018, 5.5.2);\\n\\xe2\\x80\\x95 \\nsupplier selection report (ISO 26262-8:2018, 5.5.1); and\\n\\xe2\\x80\\x95 \\nfunctional safety assessment report (ISO 26262-8:2018, 5.5.4).\\n \\n58 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nThe lowest level of a safety-related distributed development is the level at which the responsibility \\nfor safety ends. There can be suppliers at lower levels who do not have safety responsibility, such as \\nsuppliers of manufacturing materials. These lower level suppliers can be subject to requirements \\noutside the scope of ISO 26262, such as the requirements of a quality management system.\\n4.11\\tConfirmation\\tmeasures\\nThe confirmation reviews, functional safety audit and functional safety assessment for semiconductors \\nare carried out according to ISO 26262-2:2018, 6.4.10, 6.4.11 and 6.4.12.\\nThe applicability of those clauses to semiconductors is tailored according to the context in which the \\nsemiconductor device is assessed. If the semiconductor device is being developed as an SEooC, the \\ntailoring can be done following the guidelines in ISO 26262-10 [61]. In the case of intellectual properties, \\nthe tailoring can be done following the guidelines in 4.5 of this document.\\nIn general, each confirmation review concerning safety at the item level will be tailored out as they are \\ntypically out of scope for a semiconductor supplier.\\nNOTE \\nThe tailoring can be supported by checklists.\\nEXAMPLE \\nThe functional safety audit can be tailored by means of a Process Safety Audit (PSA). The PSA is \\nexecuted according to a checklist. The PSA checklist is based on the Safety Plan and lists which activities and \\nwork products are required according to the context in which the semiconductor device is assessed. If gaps \\nare identified, measures are put in place to cover those gaps. The PSA is performed with the required level of \\nindependence for functional safety audit as listed in ISO 26262-2:2018, Table 1.\\n4.12\\tClarification\\ton\\thardware\\tintegration\\tand\\tverification\\nThe following Table 27 and Table 28 show how ISO 26262-5:2018, Table 10 and Table 11 can be applied \\nto semiconductors.\\nNOTE 1 \\nThe tables are a starting point and can be modified for specific use cases with an appropriate \\nrationale.\\nTable 27 \\xe2\\x80\\x94 Methods for deriving test cases for hardware integration testing at \\nsemiconductor level\\nMethod\\nInterpretation at semiconductor level\\nAnalysis of requirements\\nRelevant safety requirements are allocated to the semicon-\\nductor device. This is usually done in the semiconductor \\nindustry during IC pre-silicon verification (at simulation \\nlevel) and post-silicon verification (at silicon level)\\nAnalysis of internal and external interfaces\\nEach pre or post silicon verification activity related to \\nthe IC integration and to the IC IOs can be claimed to be \\naddressing this entry\\nGeneration and analysis of equivalence classes\\nTest-benches are selected according to homogenous groups \\nof features\\nAnalysis of boundary values\\nStandard verification technique\\nKnowledge or experience based error guessing\\ne.g. potential design concerns identified in external analy-\\nsis, e.g. design FMEA\\nAnalysis of functional dependencies\\nStandard verification technique\\nAnalysis of common limit conditions, sequences \\nand sources of common cause failures\\ne.g. tests on clock, power, temperature, EMI\\nAnalysis of environmental conditions and opera-\\ntional use cases\\ne.g. temperature cycling, SER experiments, HTOL tests\\nStandards if existing\\ne.g. standard for CAN, I2C, UART, SPI etc.\\nAnalysis of significant variants\\ne.g. PVT (Process skews, Voltage, Temperature), character-\\nization tests\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n59\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 28 \\xe2\\x80\\x94 Hardware integration tests to verify the completeness and correctness of the \\nimplementation of the hardware safety requirements at semiconductor level\\nMethod\\nInterpretation at semiconductor level\\nFunctional testing\\nCan be covered by pre-silicon verification tech-\\nniques\\nElectrical testing\\nCan be covered by post-silicon verification tech-\\nniques, limited to hardware safety requirements \\nthat can be verified at that level\\nFault injection testing\\nSee 4.8\\nConcerning Table 27, the use of the word \\xe2\\x80\\x9ctest case\\xe2\\x80\\x9d is applied somewhat differently between systems \\nand semiconductor components. Semiconductor components are tested in two ways:\\n\\xe2\\x80\\x95 \\npost-silicon verification focuses on correct integration and freedom from systematic faults and is \\napplied to a small subset of devices; and\\n\\xe2\\x80\\x95 \\nproduction testing focuses on faults that can occur during production. State of the art production \\ntesting applies structural tests. Production testing is applied to all produced devices. This relates \\nto clause \\xe2\\x80\\x9cProduction\\xe2\\x80\\x9d and is not within scope of hardware integration verification.\\nNOTE 2 \\nIn this context, the term \\xe2\\x80\\x9ctest cases\\xe2\\x80\\x9d refers to validation test cases that test the functional and the \\nelectrical behaviour of the design. Test structures and test equipment implemented for production testing can \\nalso be helpful for post-silicon verification.\\nSeveral of the methods included in Table 27 are, in general, standard for a semiconductor test process \\nas they relate directly to verification of data sheet technical specifications over the specified operating \\nrange (e.g. voltage, temperature, frequency) unless indicated otherwise. Methods of equivalence classes \\nand error guessing are, in general, less relevant for the testing of semiconductor hardware and therefore \\nless commonly used.\\n5\\t Specific\\tsemiconductor\\ttechnologies\\tand\\tuse\\tcases\\n5.1 Digital components and memories\\n5.1.1 \\nAbout digital components\\nDigital components include the digital part of components like microcontrollers, System on Chip (SoC) \\ndevices and Application Specific Integration Circuits (ASICs).\\n5.1.2 \\nFault models of non-memory digital components\\nA list of often used digital fault models include (e.g. References [56], [60]):\\n\\xe2\\x80\\x95 \\npermanent, as further detailed below; and\\n\\xe2\\x80\\x95 \\nstuck-at fault: a fault in a circuit characterized by a node remaining at either a logic high (1) or \\nat a logic low (0) state regardless of changes in input stimuli;\\n\\xe2\\x80\\x95 \\nopen-circuit fault: a fault in a circuit that alters the number of nodes by breaking a node into \\ntwo or more nodes;\\n\\xe2\\x80\\x95 \\nbridging fault: two signals that are connected unintentionally. Depending on the logic circuitry \\nemployed, this can result in a wired-OR or wired-AND logic function. Normally restricted to \\nsignals that are physically adjacent in the design; and\\n \\n60 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nSingle Event Hard Error (SHE): an irreversible change in operation resulting from a single \\nradiation event and typically associated with permanent damage to one or more elements of a \\ndevice (e.g. gate oxide rupture).\\n\\xe2\\x80\\x95 \\ntransient, as further detailed below.\\n\\xe2\\x80\\x95 \\nSingle Event Transient (SET): A momentary voltage excursion (e.g. a voltage spike) at a node in \\nan integrated circuit caused by the passage of a single energetic particle;\\n\\xe2\\x80\\x95 \\nSingle Event Upset (SEU): A soft error caused by the signal induced by the passage of a single \\nenergetic particle;\\n\\xe2\\x80\\x95 \\nSingle Bit Upset (SBU): A single storage location upset from a single event;\\n\\xe2\\x80\\x95 \\nMultiple Cell Upset (MCU): A single event that induces several bits in an IC to fail at the same \\ntime. The error bits are usually, but not always, physically adjacent; and\\n\\xe2\\x80\\x95 \\nMultiple Bit Upset (MBU): Two or more single-event-induced bit errors occurring in the same \\nnibble, byte, or word. An MBU could be not corrected by a simple ECC (e.g. a single-bit error \\ncorrection).\\nNOTE 1 \\nSET, SEU, SBU, MCU and MBU are typically indicated as \\xe2\\x80\\x9csoft errors\\xe2\\x80\\x9d.\\nNOTE 2 \\nTransition faults and similar timing related phenomena are considered when relevant for \\nthe specific technology.\\nNOTE 3 \\nSome fault models can have the same effect as other fault models and therefore can \\nbe detected by the same safety mechanism. An appropriate justification is provided to show that \\ncorrespondence.\\nEXAMPLE A safety mechanism designed to target stuck-at faults can detect bridging faults or open \\nfaults that do manifest as stuck-at over time.\\nNOTE 4 \\nTable 29 includes additional fault models related to memories.\\n5.1.3 \\nDetailed fault models of memories\\nMemory fault models can vary depending on the memory architecture and memory technology. Typical \\nfault models of semiconductor memories are shown in Table 29. The listing is not exhaustive and can be \\nadjusted based on additional known faults or depending on the application.\\nNOTE 1 \\nTypically only a subset of the listed memory fault models can be activated during typical stress \\nconditions while others can be activated at end-of-line test facilities. Evidence is provided to show the \\neffectiveness of the memory tests with respect to the test conditions.\\nNOTE 2 \\nAs shown by several publications (e.g. Reference [47]), the real defect distribution can be different \\nfrom memory to memory. Therefore, the previous list of fault models and the relationship with the target DC can \\nbe changed based on a specific pareto fault model.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n61\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b\" \\nISO 26262-11:2018(E)\\nTable 29 \\xe2\\x80\\x94 fault models of memory elements\\nElement\\nFault models\\nFLASH (NAND, embedded)\\nstuck-at, additional fault modelsa, soft error model\\nROM, OTP, eFUSE\\nstuck-at, additional fault modelsa\\nEEPROM\\nstuck-at, additional fault modelsa\\nEmbedded RAM\\nstuck-at, additional fault modelsa, soft error model\\nDRAM\\nstuck-at, additional fault modelsa, soft error model\\na \\nFor example, Stuck-open Faults (SOFs), some kind of coupling faults. Based on memory structure, for example, \\naddressing faults (AF), addressing delay faults (ADF), Transition Faults (TFs), Neighbourhood Pattern Sensitive Faults \\n(NPSFs), Sense Transistor Defects (STDs), Word-line Erase Disturb (WED), Bit-line Erase Disturb (BED), Word-line Program \\nDisturb (WPD), Bit-line Program Disturb (BPD). These fault models are for RAM but it can be shown that the same fault \\nmodels are also valid for embedded FLASH or NAND FLASH, even if caused by different phenomena (see References [48], \\n[49] and [50]).\\n5.1.4 \\nFailure modes of digital components\\nThis sub-clause gives an example how to characterize the failure modes of digital components based on \\ntheir functional specification.\\nAs example of classification, for any function of the element, the element failure can be modelled as:\\n\\xe2\\x80\\x95 \\nfunction omission: function not delivered when needed (FM1);\\n\\xe2\\x80\\x95 \\nfunction commission: function executed when not needed (FM2);\\n\\xe2\\x80\\x95 \\nfunction timing: function delivered with incorrect timing (FM3); and\\n\\xe2\\x80\\x95 \\nfunction value: function provides incorrect output (FM4).\\nThe failure mode can be adapted to any logical function. In the context of a safety analysis \\n(ISO 26262-9:2018, Clause 8) the failure mode description is enhanced with a root cause effect analysis \\nto understand how the failure mode propagates to other parts or subparts.\\nIn general, the failure modes of an IP block can be described at different abstraction levels and based \\non different perspectives on the block's fault-free functionality and faulty behaviours. The selection of \\nthe failure mode set influences the feasibility, effort and confidence of a safety analysis. Criteria for a \\nreasonable and objective oriented definition of the failure mode set are:\\n\\xe2\\x80\\x95 \\nfailure modes allow the mapping of underlying technology faults to failure modes, as described in 4.3;\\n\\xe2\\x80\\x95 \\nfailure modes support the assessment of the diagnostic coverage of the applied safety \\nmechanisms; and\\n\\xe2\\x80\\x95 \\nfailure modes ideally are disjunctive, i.e. each of the originating faults ideally leads to only one \\nparticular failure mode.\\nNOTE \\nAt the proposed level of abstraction, failure modes can be caused by the same physical root cause.\\nEXAMPLE \\nFM3 (timing) and FM4 (value) can be caused by a stuck-at fault or a soft error affecting some \\ninner logic function. If FM3 and FM4 are controlled by different safety mechanisms with different diagnostic \\ncoverage capabilities the safety concept is more robust against failure mode distributions.\\nAnnex A provides an example on how to use digital failure modes for diagnostic coverage evaluation.\\n5.1.5\\t\\nExample\\tof\\tfailure\\tmode\\tdefinitions\\tfor\\tcommon\\tdigital\\tblocks\\nTable 30 contains exemplary, non-binding failure mode definitions for common IP blocks.\\n \\n62 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n\"\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 30 \\xe2\\x80\\x94 Example of failure modes for digital components\\nPart/subpart\\nFunction\\nAspects to be considered for Failure modea\\nCentral Processing \\nUnit (CPU)\\nExecute given instruction \\nflow according to given In-\\nstruction Set Architecture.\\nCPU_FM1: given instruction flow(s) not executed (total \\nomission)\\nCPU_FM2: un-intended instruction(s) flow executed \\n(commission)\\nCPU_FM3: incorrect instruction flow timing (too \\nearly/late)\\nCPU_FM4: incorrect instruction flow result\\nCPU_FM1 can be further refined if necessary into:\\n \\n \\n\\xe2\\x80\\x95 \\nCPU_FM1.1: given instruction flow(s) not executed \\n(total omission) due to program counter hang up\\n\\xe2\\x80\\x95 \\nCPU_FM1.2: given instruction flow(s) not executed \\n(total omission) due to instruction fetch hang up\\nCPU Interrupt Handler \\ncircuit (CPU_INTH)\\nExecute interrupt service \\nroutine (ISR) according to \\ninterrupt request\\nCPU_INTH_FM1: ISR not executed (omission/too few)\\nCPU_INTH_FM2: un-intended ISR execution (commis-\\nsion/too many)\\nCPU_INTH_FM3: delayed ISR execution (too early/late)\\nCPU_INTH_FM4: incorrect ISR execution (see CPU_\\nFM1/2/4)\\nCPU Memory Manage-\\nment Unit (CPU_MMU)\\nThe Memory Management \\nUnit (MMU) typically per-\\nforms two functions:\\n\\xe2\\x80\\x95 \\ntranslates virtual \\naddresses into physical ad-\\ndresses\\n\\xe2\\x80\\x95 \\nControls memory \\naccess permissions.\\nCPU_MMU_FM1: Address translation not executed\\nCPU_MMU_FM2: Address translation when not requested\\nCPU_MMU_FM3: delayed address translation\\nCPU_MMU_FM4: translation with incorrect physical \\naddress\\nCPU_MMU_FM5: un-intended blocked access\\nCPU_MMU_FM6: un-intended allowed access\\nCPU_MMU_FM7: delayed access\\nInterrupt Controller \\nUnit (ICU)\\nSend interrupt requests \\nto given CPU according to \\nhardware-based or soft-\\nware-based interrupt events \\nand according to intended \\nquality of service (e.g. prior-\\nity). The interrupt controller \\ncan service multiple CPUs.\\nICU_FM1: Interrupt request to CPU missing\\nICU_FM2: Interrupt request to CPU without triggering \\nevent\\nICU_FM3: Interrupt request too early/late\\nICU_FM4: Interrupt request sent with incorrect data\\nDMA\\nData Transfer: Move data \\nwhen requested from source \\naddress(es) to destination ad-\\ndress(es) and notify the data \\ntransfer completion.\\nThe set of data transferred is \\ncalled a message.\\nDMA_FM1: No requested data transfer. The message is \\nnot sent as intended to the destination address.\\nDMA_FM2: Data transfer without a request.\\nDMA_FM3: Data transfer too early/late.\\nDMA_FM4: Incorrect output\\na \\nFailure Modes can be caused by permanent and transient random hardware faults.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n63\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nFunction\\nAspects to be considered for Failure modea\\n(first\\tlevel\\tof\\tabstraction)\\nBuses and Intercon-\\nnects\\n(internal communica-\\ntion)\\nDeliver bus transaction initi-\\nated from a given bus master \\nto the target address accord-\\ning to the intended quality of \\nservice (TXFR).\\nA transaction is a given set \\nof data as defined by the bus \\nprotocol.\\nBUS_TXFR_FM1: Requested transaction not delivered\\nBUS_TXFR_FM2: Transaction delivered without a request\\nBUS_TXFR_FM3: Transaction delivered with incorrect \\ntiming\\nBUS_TXFR_FM3: Transaction delivered with incorrect \\ndata\\nExternal SDRAM with \\nSDRAM Controller\\nVolatile memory fetch (read) \\nor store (write) data to given \\nrow and column address \\naccording to input command \\nfrom SDRAM controller.\\nSDRAM_RW_FM1: given write/read access not executed \\n(omission)\\nSDRAM_RW_FM2: un-intended write/read access exe-\\ncuted (commission)\\nSDRAM_RW_FM3: incorrect write/read access result \\n(too early/late)\\nSDRAM_RW_FM4: incorrect write/read access result\\nor (second level of abstraction)\\nExternal SDRAM with \\nSDRAM Controller\\nSDRAM controller provides \\nrow address to be prepared \\nfor read or write operation on \\na selected bank.\\nSDRAM_RA_FM1: given row address not accessed \\n(omission)\\nSDRAM_RA_FM2: un-intended row address accessed \\n(commission)\\nSDRAM_RA_FM3: delayed row address result (too \\nearly/late)\\nSDRAM_RA_FM4: incorrect row address result\\nExternal SDRAM with \\nSDRAM Controller\\nSDRAM controller provides \\ncolumn address to access data \\nfor read or write operation.\\nSDRAM_CA_FM1: given column address not accessed \\n(omission)\\nSDRAM_CA_FM2: un-intended column address accessed \\n(commission)\\nSDRAM_CA_FM3: delayed column address result (too \\nearly/late)\\nSDRAM_CA_FM4: incorrect column address result\\nExternal SDRAM with \\nSDRAM Controller\\nSDRAM controller provides \\ncommands (e. g. activate, \\nwrite, read, pre-charge, \\nrefresh \\xe2\\x80\\xa6) to get data for read \\nor write operation.\\nSDRAM_IN_FM1: given instruction not executed \\n(omission)\\nSDRAM_IN_FM2: un-intended instruction executed \\n(commission)\\nSDRAM_IN_FM3: delayed instruction result (too \\nearly/late)\\nSDRAM_IN_FM4: incorrect instruction result\\nExternal SDRAM with \\nSDRAM Controller\\nSDRAM data path provides \\nwrite/read data to/from \\nmemory array.\\nSDRAM_DW_FM1: given data word not executed \\n(omission)\\nSDRAM_DW_FM2: un-intended data word executed \\n(commission)\\nSDRAM_DW_FM3: delayed data word result (too \\nearly/late)\\nSDRAM_DW_FM4: incorrect data word result\\na \\nFailure Modes can be caused by permanent and transient random hardware faults.\\n \\nTable 30 (continued)\\n64 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nFunction\\nAspects to be considered for Failure modea\\nExternal FLASH with \\nFLASH Controller\\nNon-volatile memory fetches \\n(read) or store (write) data \\nto given address according to \\ninput command from FLASH \\ncontroller.\\nFLASH_RW_FM1: given write/read access not executed \\n(omission)\\nFLASH_RW_FM2: un-intended write/read access execut-\\ned (commission)\\nFLASH_RW_FM3: delayed write/read access result (too \\nearly/late)\\nFLASH_RW_FM4: incorrect write/read access result\\n(first\\tlevel\\tof\\tabstraction)\\nSRAM with SRAM \\ncontroller\\nProvides storage for variables \\nand/or constants.\\nThe analysis is done after \\nconsidering the access control \\nlogic called SRAM controller \\nfrom the perspective of an \\nhardware element issuing a \\ncommand.\\nTypically a command is a \\nread, write or possibly a \\nread-modify-write.\\nSRAM_RW_FM1: given command not executed (omission)\\nSRAM_RW_FM2: un-intended command executed (com-\\nmission)\\nSRAM_RW_FM3: delayed command result (too early/late)\\nSRAM_RW_FM4: incorrect command result\\nSRAM with SRAM \\ncontroller\\nSRAM hard-macro (HM): \\nProvides data or stores data \\nto given address according to \\ninput command from SRAM \\ncontroller.\\nSRAM_HM_FM1: command from SRAM controller not \\nexecuted (omission)\\nSRAM_HM_FM2: unintended access to the SRAM caused \\ne.g. by a transient fault\\nSRAM_HM_FM3: SRAM command delayed (too early/\\nlate) e.g. delayed by the internal timing generation\\nSRAM_HM_FM4: Final SRAM data corrupt or written at \\nwrong location\\nEmbedded FLASH \\n(eFLASH) with \\neFLASH controller\\nNon-volatile memory (NVM) \\nstores program code and data \\nconstants.\\nProgram and erase function. \\nErase suspend and resume \\noperations to interrupt on-go-\\ning erase operation.\\neFLASH_E_FM1: Program or erase not performed.\\neFLASH_E_FM2: Program or erase performed when not \\nrequested.\\neFLASH_E_FM3: Incorrect Program or erase timing\\neFLASH_E_FM4: Program or erase performed with \\nwrong content.\\nNon-volatile memory (NVM) \\nstores program code and data \\nconstants.\\nRead Function\\neFLASH_R_FM1: Read access not performed.\\neFLASH_R_FM2: Read access when not requested.\\neFLASH_R_FM3: Incorrect read access timing.\\neFLASH_R_FM4: Read access delivers wrong content.\\na \\nFailure Modes can be caused by permanent and transient random hardware faults.\\n \\nTable 30 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n65\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nFunction\\nAspects to be considered for Failure modea\\nData coherency\\nCoherency is defined by \\ncoherence invariants inde-\\npendent of the underlying \\narchitecture. The invariants \\nchosen for this example are \\nbased on Reference [52].\\nBased on the complexity of the topic the failure modes \\nare just few examples on situations that can lead to a \\nnon-coherent state of given addresses.\\nCOHERENCY_FM1: Write to memory A not executed \\n(omission). Memory is seen as updated by the partic-\\nipants in the coherency. This failure mode leads to a \\nnon-coherent state for memory A.\\nCOHERENCY_FM2: Un-intended write to memory A \\n(commission). This situation can be related to the sit-\\nuation where many cores attempt to write to the same \\nlocation.\\nCOHERENCY_FM3: delayed update (write) of memory \\nA (too early/late). A possible situation is when a legal \\nwrite is delayed but the other agents participating in \\nthe coherency protocol think the address content is \\ncoherent.\\nCOHERENCY_FM4: Content of memory A is corrupt. This \\ncan be caused by an incorrect write command (see e.g. \\nSRAM) or by a defect in the storage element.\\nCommunication Pe-\\nripheral\\n(COM)\\nCan be applied to \\nCAN, Flexray, Ether-\\nnet, SPI\\nTransfer Data provided by \\nsoftware to external interface \\naccording to the interface \\nprotocol.\\nReceive and process data pro-\\nvided by an external interface \\naccording to interface proto-\\ncol. Notify software about the \\navailability of data.\\nThe set of data transferred is \\ncalled a message.\\nCOM_TX_FM1: No message transferred as requested\\nCOM_TX_FM2: Message transferred when not requested\\nCOM_TX_FM3: Message transferred too early/late\\nCOM_TX_FM4: Message transferred with incorrect value\\nCOM_RX_FM1: No incoming message processed\\nCOM_RX_FM2: Message transferred when not requested\\nCOM_RX_FM3: Message transferred too early/late\\nCOM_RX_FM4: Message transferred with incorrect value\\nSignal processing \\naccelerator\\nTakes high bandwidth signals \\nfrom a source (e.g. sensor \\ndata) and processes them (e.g. \\narithmetically) according to a \\ngiven code and/or configura-\\ntion (e.g. GPU, DSP). Typical-\\nly this is done to offload a \\ngeneral purpose CPU which \\ncould do that task only less \\nefficiently. Typically this pro-\\ncessing needs to comply with \\nreal time requirements.\\nSP_FM1: Processing stalled, no or constant output (ser-\\nvice omission)\\nSP_FM2: Unrequested output or interrupts (service \\ncommission)\\nSP_FM3: Output structurally broken, e.g. corrupt frames \\n(service timing)\\nSP_FM4: Output structurally OK, but erroneous data \\n(service value)\\na \\nFailure Modes can be caused by permanent and transient random hardware faults.\\n5.1.6 \\nQualitative and quantitative analysis of digital component\\nAs seen in ISO 26262-9:2018, Clause 8, qualitative and quantitative safety analyses are performed at \\nthe appropriate level of abstraction during the concept and product development phases. In the case of \\na digital component:\\n\\xe2\\x80\\x95 \\nqualitative analysis is useful to identify failure modes of digital components. One of the possible \\nways in which it can be performed uses information derived from digital component block diagrams \\nand information derived from this document;\\nNOTE 1 \\nAnnex A gives an example about how to define failure modes for digital components.\\n \\nTable 30 (continued)\\n66 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 2 \\nQualitative analysis includes dependent failure analysis of this part as seen in 4.7.\\n\\xe2\\x80\\x95 \\nquantitative analysis is performed using a combination of:\\n\\xe2\\x80\\x95 \\nlogical block level structuring;\\n\\xe2\\x80\\x95 \\ninformation derived from the digital component RTL description (to obtain functional \\ninformation) and gate-level net list (to obtain functional and structural information);\\n\\xe2\\x80\\x95 \\ninformation to evaluate potential unspecified interaction of sub functions (dependent failures, \\nsee 4.7);\\n\\xe2\\x80\\x95 \\nlayout information \\xe2\\x80\\x95 only available in the final stage;\\n\\xe2\\x80\\x95 \\ninformation for the verification of diagnostic coverage with respect to some specific fault \\nmodels such as bridging faults (see 5.1.2). This can be applicable to only some cases like the \\npoints of comparison between a part and its corresponding safety mechanism; and\\n\\xe2\\x80\\x95 \\nexpert judgement supported by rationale and careful consideration of the effectiveness of the \\nsystem-level measures.\\nNOTE 3 \\nISO 26262-5:2018, Annex D can be used as a starting point for diagnostic coverage (DC) with \\nthe claimed DC supported by a proper rationale.\\nNOTE 4 \\nThe information for quantitative analysis can be progressively available during the \\ndigital component development phase. Therefore, the analysis could be repeated based on the latest \\ninformation.\\nEXAMPLE 1 \\nDuring a first step of the quantitative analysis, a pre-Design For Test (DFT) and pre-\\nlayout gate-level net list could be available, while later the analysis is repeated using post-DFT and post-\\nlayout gate-level net list.\\nNOTE 5 \\nWhenever a quantitative analysis is performed, the accuracy of the analysis is factored into \\nits results. The validity argument states the level of confidence in the results, and suitable correction \\n(e.g. guard-bands) is applied to the results to ensure a high degree of certainty. See 5.1.10 for a discussion \\non the confidence of the computation and verification (in that context, of fault injections).\\n\\xe2\\x80\\x95 \\nsince the parts and subparts of a digital component can be implemented in a single physical \\ncomponent, both dependent failure analysis and analysis of independence or freedom from \\ninterference are important activities for digital components. See 4.7 for further details.\\nNOTE 6 \\nThe analysis of dependent failures is performed on a qualitative basis because no general and \\nsufficiently reliable method exists for quantifying such failures.\\nEXAMPLE 2 \\nThe evaluation of dependent failures starts early in design. Design measures are specified \\nto avoid and reveal potential sources of dependent failures or to detect their effect on the \\xe2\\x80\\x9cSystem on Chip\\xe2\\x80\\x9d \\nsafety performance. Layout confirmation is used in the final design stage.\\n5.1.7 \\nNotes on quantitative analysis of digital components\\n5.1.7.1 \\nHow to consider permanent faults of digital components\\nRequirements and recommendations for the failure rates computation in general are defined in \\nISO 26262-5 and tailored for semiconductor components in 4.6 of this document.\\nFollowing the example given in ISO 26262-5:2018, Annex E, the failure rates and the metrics for \\npermanent faults of digital components can be computed in the following way:\\n\\xe2\\x80\\x95 \\nthe digital component is divided into hierarchical levels (parts, subparts or elementary subparts) \\nas required;\\nNOTE 1 \\nAssumptions on the independence of identified parts are verified during the dependent failure \\nanalysis.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n67\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 2 \\nThe necessary level of detail (e.g. whether to stop at part level or if to go down to subpart or \\nelementary subpart level) can depend on the stage of the analysis and on the safety mechanisms used (inside \\nthe digital component or at the system or element level).\\nEXAMPLE 1 \\nIn the case of a CPU with a hardware lock-step safety mechanism, the analysis considers the \\nCPU function as a whole while more detail can be needed for the lock-step comparator.\\nEXAMPLE 2 \\nIn the case of a CPU with a structural software-based hardware test, the failure mode is \\ndefined in more detail because the software test will cover different failure modes with different failure \\nmode coverage.\\nEXAMPLE 3 \\nThe confidence of the accuracy of the computation of failure rate of parts or subparts can \\nbe proportional to the level of detail: a low level of detail could be appropriate for analysis at concept stage \\nwhile a higher level detail could be appropriate for analysis at the development stage.\\nNOTE 3 \\nDue to the complexity of modern digital components (hundreds or thousands of parts and \\nsubparts), to guarantee completeness of the analysis, it is helpful to support the division process with \\nautomatic tools. Care is taken to ensure digital component level analysis across module boundaries. \\nPartitions are done along levels of RTL hierarchy if RTL is available.\\n\\xe2\\x80\\x95 \\nthe failure rates of each part or subpart can be computed using one of the following two methods, \\nas already described in 4.6.2.4:\\n\\xe2\\x80\\x95 \\nif the total failure rate of the whole digital component die (i.e. excluding package and bonding) \\nis given (in FIT), then the failure rate of the part or subpart could be assumed to be equal \\nto the occupying area of the part or subpart (i.e. area related to gates, flip-flops and related \\ninterconnections) divided by the total area of the digital component die multiplied by the total \\nfailure rate, or\\nNOTE 4 \\nFor mixed signal chips with power stages, this approach is applied within each domain, as the \\ntotal failure rate for the digital domain can be different from the analogue and power domain. See 5.2 for \\nfurther details.\\nEXAMPLE 4 \\nIf a CPU area occupies 3 % of the whole digital component die area, then its failure rate could \\nbe assumed to be equal to 3 % of the total digital component die failure rate.\\n\\xe2\\x80\\x95 \\nif the base failure rates, i.e. the failure rate of basic subparts like gates of the digital component, are \\ngiven, then the failure rate of the part or subpart could be assumed to be equal to the sum of the \\nnumber of those basic subparts multiplied by its failure rate.\\nNOTE 5 \\nSee 4.6 for examples for how to derive the base failure rate values.\\n\\xe2\\x80\\x95 \\nthe evaluation is completed by classifying the faults into safe faults, residual faults, detected dual-\\npoint faults and latent dual-point faults; and\\nEXAMPLE 5 \\nCertain portions of a debug unit implemented inside a CPU are safety-related (because the \\nCPU itself is safety-related), but they themselves cannot lead to a direct violation of the safety goal or their \\noccurrence cannot significantly increase the probability of violation of the safety goal.\\n\\xe2\\x80\\x95 \\nthe failure mode coverage with respect to residual and latent faults of that part or subpart is \\ndetermined.\\nEXAMPLE 6 \\nThe failure mode coverage associated with a certain failure rate can be computed by \\ndividing the subpart into smaller subparts, and for each of them compute the expected capability of the \\nsafety mechanisms to cover each subpart. For example, the failure mode coverage of a failure in the CPU \\nregister bank can be computed by dividing the register bank into smaller subparts, each one related to the \\nspecific register (e.g. R0, R1,\\xe2\\x80\\xa6), and computing the failure mode coverage of the safety mechanism for each \\nof them, e.g. combining the failure mode coverage for each of the corresponding low-level failure modes.\\nNOTE 6 \\nThe effectiveness of safety mechanisms could be affected by dependent failures. Adequate \\nmeasures are considered as listed in 4.7.\\n \\n68 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 7 \\nDue to the complexity of modern digital components (millions of gates), fault injection methods \\ncan assist the computation and be used for verification of the amount of safe faults and especially of the \\nfailure mode coverage. See 4.8 and 5.1.10 for details. Fault injection is not the only method, and other \\napproaches are possible as described in 5.1.10.\\n5.1.7.2 \\nHow to consider transient faults of digital components\\n5.1.7.2.1 \\nFailure rate of transient fault\\nAs described in ISO 26262-5:2018, 8.4.7, NOTE 2, the transient faults are considered when shown to \\nbe relevant due, for instance, to the technology used. They can be addressed either by specifying and \\nverifying a dedicated target \\xe2\\x80\\x9csingle-point fault metric\\xe2\\x80\\x9d value to them or by a qualitative rationale.\\nNOTE \\nA justification is given for the selected procedure.\\nWhen the quantitative approach is used, failure rates for transient faults of each part or subpart are \\ncomputed using the base failure rate for transient faults.\\nDue to the amount and density of memory elements in RAM memories, the resulting failure rates for \\ntransient faults can be significantly higher than those related to processing logic or other parts of a \\ndigital component. Therefore, as recommended in ISO 26262-5:2018, 8.4.7, NOTE 1 it can be helpful to \\ncompute a separate metric for RAM memories and for the other parts of the digital component.\\n5.1.7.2.2\\t\\nClassification\\tof\\ttransient\\tfault\\nFor transient faults, the amount of safe faults can be particularly relevant. To justify the estimated \\namount of safe transient faults, a rationale about the results and the assumptions used to derive them \\nis made available.\\nNOTE 1 \\nThe rationale can be derived from fault injection as described in 4.8 or arguments based on the circuit \\narchitecture or application.\\nEXAMPLE 1 \\nA fault in a register storing a safety-related constant (i.e. a value written only once but read \\nat each clock cycle and, if wrong, violating the safety goal) is never safe. If instead, for example, the register \\nis written every 10 ms but used for a safety-related calculation only once, 1 ms after it is written, a random \\ntransient fault in the register would result in 90 % safe faults because in the remaining 90 % of the clock cycles, a \\nfault in that register will not cause a violation of the safety goal.\\nNOTE 2 \\nAs described in ISO 26262-5:2018, 8.4.7, NOTE 2 transient faults can be addressed via a single-point \\nfault metric. Transient faults are not considered as far as latent faults are concerned. No failure mode coverage \\nfor latent faults is computed for transients because the root cause rapidly disappears (per definition of transient). \\nFurthermore, it is assumed that in the greatest majority of the cases, the effect will rapidly be removed, e.g. by \\na following power-down cycle removing the erroneous state of the flip-flop or memory cell that was changed by \\nthe transient fault, before a second fault can cause the occurrence of a multiple-point failure. In special cases, this \\nassumption could be invalid and additional measures can be necessary and addressed on a case by case basis.\\nNOTE 3 \\nTransient faults are contained within the affected subpart and do not spread inadvertently to other \\nsubparts if they are not logically connected.\\nNOTE 4 \\nSome of the coverage values of safety mechanisms defined in ISO 26262-5:2018, Annex D, Tables \\nD.3 to D.10, are valid for permanent faults only. This important distinction can be found in the related safety \\nmechanism description, in which it is written how the coverage value can be considered for transient faults.\\nEXAMPLE 2 \\nThe typical value of the coverage of RAM March test (see Table 33) is rated HIGH. However in \\nthe related description (5.1.13.7), it is written that these types of tests are not effective for soft error detection. \\nTherefore, for example, the coverage of RAM March test with respect to transient faults is zero.\\n5.1.8 \\nExample of quantitative analysis\\nAn example of quantitative analysis is given in Annex C.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n69\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.1.9 \\nExample of techniques or measures to detect or avoid systematic failures during design \\nof a digital component\\nThe general requirements and recommendations related to hardware architecture and detailed design \\nare respectively defined in ISO 26262-5:2018, 7.4.1 and ISO 26262-5:2018, 7.4.2. Moreover, requirements \\nrelated to hardware verification are given in ISO 26262-5:2018, 7.4.4.\\nA digital component is developed based on a standardised development process. The two following \\napproaches are examples of how to provide evidence that sufficient measures for avoidance of \\nsystematic failures are taken during the development of a digital component:\\n\\xe2\\x80\\x95 \\nusing a checklist such as the one reported in Table 31; and\\n\\xe2\\x80\\x95 \\nusing field data from similar products, which were developed using the same process as the \\ntarget device.\\nMoreover, the following general guidelines can be considered:\\n\\xe2\\x80\\x95 \\nthe documentation of each design activity, test arrangements and tools used for the functional \\nsimulation and the results of the simulation;\\n\\xe2\\x80\\x95 \\nthe verification of each activity and its results, for example by simulation, equivalence checks, \\ntiming analysis or checking the technology constraints;\\n\\xe2\\x80\\x95 \\nthe usage of measures for the reproducibility and automation of the design implementation process \\n(script based, automated work and design implementation flow); and\\nNOTE \\nThis implies ability to freeze tool versions to enable reproducibility in the future in compliance \\nwith legal requirements.\\n\\xe2\\x80\\x95 \\nthe usage \\xe2\\x80\\x95 for 3rd party soft-cores and hard-cores \\xe2\\x80\\x95 of validated macro blocks and to comply \\nwith each constraint and procedure defined by the macro core provider if practicable.\\nTable 31 \\xe2\\x80\\x94 Example of techniques or measures to achieve compliance with ISO 26262-5 \\nrequirements during the development of a digital component\\nISO 26262-5:2018 \\nrequirement\\nDesign \\nphase\\nTechnique/Measure\\nAim\\n7.4.1.6 Modular design \\nproperties\\nDesign entry Structured description \\nand modularization\\nThe description of the circuit\\'s functionality \\nis structured in such a fashion that it is easily \\nreadable, i.e. circuit function can be intui-\\ntively understood on the basis of description \\nwithout simulation efforts.\\n7.4.1.6 Modular design \\nproperties\\n \\nDesign description in HDL Functional description at high level, e.g. at \\nRTL, in hardware description language, for \\nexample, VHDL or Verilog.\\n7.4.4 Verification of \\nhardware design\\n \\nHDL simulation\\nPre-silicon verification of circuit described in \\nVHDL or Verilog by means of simulation.\\n7.4.4 Verification of \\nhardware design\\n \\nFormal verification\\nPre-silicon verification of circuit described \\nin VHDL or Verilog by means of static formal \\nverification.\\n7.4.4 Verification of \\nhardware design\\n \\nRequirement Driven \\nVerification\\nAll functional and safety-related require-\\nments are verified. To be shown via traceabili-\\nty between specification and verification plan.\\n7.4.4 Verification of \\nhardware design\\n \\nPre-silicon verification \\non module level\\nPre-silicon verification \"bottom-up\" for \\nexample by assertion based pre-silicon verifi-\\ncation, i.e. verification of circuit described in \\nVHDL or Verilog by means of property check-\\ning at runtime, where property is specified in \\nsome modelling or assertion language.\\n \\n70 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nISO 26262-5:2018 \\nrequirement\\nDesign \\nphase\\nTechnique/Measure\\nAim\\n7.4.4 Verification of \\nhardware design\\n \\nPre-silicon verification \\non top level\\nVerification of the entire circuit.\\n7.4.2.4 Robust design \\nprinciples\\n \\nRestricted use of asyn-\\nchronous constructs\\nAvoidance of typical timing anomalies during \\nsynthesis, avoidance of ambiguity during sim-\\nulation and synthesis caused by insufficient \\nmodelling, design for testability.\\nThis does not exclude that for certain types \\nof circuitry, such as reset logic or for very \\nlow-power microcontrollers, asynchronous \\nlogic could be useful: in this case, the aim is to \\nsuggest additional care to handle and verify \\nthose circuits.\\n7.4.2.4 Robust design \\nprinciples\\n \\nSynchronisation of pri-\\nmary inputs and control \\nof meta-stability\\nAvoidance of ambiguous circuit behaviour as \\na result of set-up and hold timing violation.\\n7.4.4 Verification of \\nhardware design\\n \\nFunctional and structur-\\nal coverage-driven ver-\\nification (with coverage \\nof verification goals in \\npercentage)\\nQuantitative assessment of the applied \\nverification scenarios during the functional \\ntest. The target level of coverage is defined \\nand shown.\\n7.4.2.4 Robust design \\nprinciples\\n \\nObservation of coding \\nguidelines\\nStrict observation of the coding style results in \\na syntactic and semantic correct circuit code.\\n7.4.4 Verification of \\nhardware design\\n \\nApplication of code \\nchecker\\nAutomatic verification of coding rules (\"Cod-\\ning style\") by code checker tool.\\n7.4.4 Verification of \\nhardware design\\n \\nDocumentation of simu-\\nlation results\\nDocumentation of each data needed for a \\nsuccessful simulation in order to verify the \\nspecified circuit function.\\n7.4.4 Verification of \\nhardware design\\nSynthesis\\nTo check timing \\nconstraints, or static \\nanalysis of the propaga-\\ntion delay (STA \\xe2\\x80\\x94 Static \\nTiming Analysis)\\nVerification of the achieved timing constraint \\nduring synthesis.\\n7.4.4 Verification of \\nhardware design\\n \\nComparison of the gate \\nnetlist with the reference \\nmodel (formal equiva-\\nlence check)\\nFunctional equivalence check of the synthe-\\nsised gate netlist.\\n7.4.1.6 Modular design \\nproperties\\n \\nDocumentation of \\nsynthesis constraints, \\nresults and tools\\nDocumentation of each defined constraint \\nthat is necessary for an optimal synthesis to \\ngenerate the final gate netlist.\\n7.4.1.6 Modular design \\nproperties\\n \\nScript based procedures\\nReproducibility of results and automation of \\nthe synthesis cycles.\\n7.4.2.4 Robust design \\nprinciples\\n \\nAdequate time margin for \\nprocess technologies in \\nuse for less than 3 years\\nAssurance of the robustness of the imple-\\nmented circuit functionality even under \\nstrong process and parameter fluctuation.\\n7.4.1.6 Modular design \\nproperties (testability)\\nTest inser-\\ntion and \\ntest pattern \\ngeneration\\nDesign for testability \\n(depending on the test \\ncoverage in percent)\\nAvoidance of not testable or poorly testable \\nstructures in order to achieve high test cover-\\nage for production test or on-line test.\\n7.4.1.6 Modular design \\nproperties (testability)\\n \\nProof of the test coverage \\nby ATPG (Automatic Test\\nPattern Generation) \\nbased on achieved test \\ncoverage in percent\\nDetermination of the test coverage that can \\nbe expected by synthesised test pattern \\n(Scan-path, BIST) during the production test.\\nThe target level of coverage and fault model \\nare defined and shown.\\n \\nTable 31 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n71\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nISO 26262-5:2018 \\nrequirement\\nDesign \\nphase\\nTechnique/Measure\\nAim\\n7.4.4 Verification of \\nhardware design\\n \\nSimulation of the gate \\nnetlist after test inser-\\ntion, to check timing \\nconstraints, or static \\nanalysis of the propaga-\\ntion delay (STA)\\nVerification of the achieved timing constraint \\nduring test insertion.\\n7.4.4 Verification of \\nhardware design\\n \\nComparison of the gate \\nnetlist after test inser-\\ntion with the reference \\nmodel (formal equiva-\\nlence check)\\nFunctional equivalence check of the gate \\nnetlist after test insertion.\\n7.4.4 Verification of \\nhardware design\\nPlacement, \\nrouting, lay-\\nout genera-\\ntion\\nSimulation of the gate \\nnetlist after layout, to \\ncheck timing constraints, \\nor static analysis of the \\npropagation delay (STA)\\nVerification of the achieved timing constraint \\nduring back-end.\\n7.4.4 Verification of \\nhardware design\\n \\nAnalysis of power net-\\nwork\\nShow robustness of power network and \\neffectiveness of related safety mechanisms. \\nExample: IR drop test.\\n7.4.4 Verification of \\nhardware design\\n \\nPerform cross clock do-\\nmain check on gate level \\nnetlist, before and after \\ntest insertion\\nAvoid cross clock domain violations during \\nfunctional or test modes.\\n7.4.4 Verification of \\nhardware design\\n \\nComparison of the gate \\nnetlist after layout with \\nthe reference model (for-\\nmal equivalence check)\\nFunctional equivalence check of the gate \\nnetlist after back-end.\\n7.4.4 Verification of \\nhardware design\\n \\nDesign rule check (DRC)\\nVerification of process design rules.\\n7.4.4 Verification of \\nhardware design\\n \\nLayout versus schematic \\ncheck (LVS)\\nVerification of the layout.\\n \\nTable 31 (continued)\\n72 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nISO 26262-5:2018 \\nrequirement\\nDesign \\nphase\\nTechnique/Measure\\nAim\\n7.4.5 Production, \\noperation, service and \\ndecommissioning\\n9.4.1.2, 9.4.1.3 Dedi-\\ncated measures\\nSafety-relat-\\ned special \\ncharac-\\nteristics \\nduring chip \\nproduction\\nDetermination of the \\nachievable test coverage \\nof the production test\\nEvaluation of the test coverage during pro-\\nduction tests with respect to the safety-relat-\\ned aspects of the digital component.\\n7.4.5 Production, \\noperation, service and \\ndecommissioning\\n9.4.1.2, 9.4.1.3 Dedi-\\ncated measures\\n \\nDetermination of meas-\\nures to detect and weed \\nout early failures\\nAssurance of the robustness of the manu-\\nfactured chip for the selected technology \\nprocess. For example, for gate oxide integri-\\nty (GOI): high temp/high voltage operation \\n(Burn-In), high current operation, voltage \\nstress, etc. Other example of tests are EM, \\nStress migration and NBTI tests.\\n7.4.5 Production, \\noperation, service and \\ndecommissioning\\n10 Hardware integra-\\ntion and verification\\nEvaluation \\nof hardware \\nelement\\nDefinition and execution \\nof qualification tests like \\nBrown-out test, High \\nTemperature Operating \\nLifetime (HTOL) test and \\nfunctional test cases\\nFor a digital component with integrated \\nbrown-out detection, the digital component \\nfunctionality is tested to verify that the \\noutputs of the digital component are set to \\na defined state (for example by stopping \\nthe operation of the microcontroller in the \\nreset state) or that the brown-out condition \\nis signalled in another way (for example by \\nraising a safe-state signal) when any of the \\nsupply voltages monitored by the brown-out \\ndetection reach a low boundary as defined for \\ncorrect operation.\\nFor a digital component without integrated \\nbrown-out detection, the digital component \\nfunctionality is tested to verify if the digital \\ncomponent sets its outputs to a defined state \\n(for example by stopping the operation of the \\ndigital component in the reset state) when \\nthe supply voltages drop from nominal value \\nto zero. Otherwise an assumption of use is de-\\nfined, and an external measure is considered.\\n5.1.9.1 \\nPrinciples, techniques or measures to detect or avoid systematic failures during RTL \\ndesign\\nSome of the principles, techniques or measures used for software development (see ISO 26262-6) can \\nbe considered in order to mitigate systematic failures during RTL design.\\nDue to the differences between using RTL for hardware design and software development, none of the \\ncontents of ISO 26262-6 can be applied directly without adequate tailoring and adoption of the specific \\nneeds of RTL hardware design.\\nEXAMPLE 1 \\nSimilar effects of static code analysis (see ISO 26262-6:2018, Table 7, entry 1h) can be achieved by \\napplication of automatic verification of coding rules (\"Coding style\") by code checker tool.\\nEXAMPLE 2 \\nSimilar effects of methods listed in ISO 26262-6:2018, Table 7, ISO 26262-6:2018, Table 8 \\nand ISO 26262-6:2018, Table 9 can be achieved by application of functional and structural coverage-driven \\nverification (with coverage of verification goals in percentage) and formal methods based on properties.\\nNOTE 1 \\nFor quantitative assessment of the applied verification scenarios during the functional test, the target \\nlevel of coverage can be based on: statement coverage, block coverage, conditional/expression coverage, branch/\\ndecision coverage, toggle coverage and Finite State Machine (FSM) coverage.\\nNOTE 2 \\nIn the case of a high-level synthesis flow, like developing in OpenCL, C-to-HDL flows, or a model based \\napproach, interactions with the requirements of ISO 26262-6 can be more applicable.\\n \\nTable 31 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n73\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.1.10\\t Verification\\tusing\\tfault\\tinjection\\tsimulation\\n5.1.10.1 General\\nAs mentioned in 4.8, fault injection is a useful method for semiconductor components. This is especially \\ntrue for digital circuits for which fault insertion testing of single-event upsets at the hardware level is \\nimpractical or even impossible for certain fault models. Therefore, fault injection using design models \\n(e.g. fault injection done at the gate-level netlist) is helpful to complete the verification step.\\nNOTE 1 \\nFault injection can be used both for permanent (e.g. stuck-at faults) and transient (e.g. single-event \\nupset) faults.\\nNOTE 2 \\nFault injection is just one of the possible methods for verification, and other approaches are possible.\\nFault injection utilizing design models can be successfully used to assist in verification of safe faults \\nand computation of their amount and failure mode coverage.\\nEXAMPLE 1 \\nInjecting faults and utilizing well-specified observation points to determine if the fault caused \\na measurable effect. Moreover, it can be used to assist the computation and to verify the values of failure mode \\ncoverage, i.e. injecting faults that were able to cause a measurable effect and determining if those faults were \\ndetected or controlled by the safety mechanisms within the maximum fault handling time interval.\\nThe confidence of the computation and verification with fault injection is evaluated with respect to:\\n\\xe2\\x80\\x95 \\nthe quality and completeness of the test-bench used to stimulate the circuit under test;\\nNOTE 2 \\nThe quality and completeness of a test-bench is measured in terms of its capability to activate the \\ncircuit under test. It can be measured in terms of functional coverage of the test-bench.\\n\\xe2\\x80\\x95 \\nthe completeness of the fault injection campaign measured as a ratio of fault scenarios covered \\nwith respect to all possible scenarios;\\nNOTE 3 \\nA scenario includes the fault site, fault occurrence, fault duration, etc.\\n\\xe2\\x80\\x95 \\nthe level of detail of the circuit representation; and\\nEXAMPLE 2 \\nGate-level netlist is appropriate for fault injection of permanent faults such as stuck-at faults. \\nHardware accelerator-based methods could be helpful in order to maximize test execution speed. RTL is \\nalso an acceptable approach for stuck-at faults, provided that the correlation with gate level is shown.\\nEXAMPLE 3 \\nModelling at a RTL is appropriate for fault injection of SEU transient faults. Simulation models \\nare also an acceptable approach for SEU transient faults, provided that suitable correlation is demonstrated \\nwith RTL or gate-level models.\\n\\xe2\\x80\\x95 \\nthe details available for the safety mechanisms to be simulated.\\n5.1.10.2\\t About\\tverification\\tof\\tfault\\tmodels\\tdifferent\\tthan\\tstuck-at\\nSub-clause 5.1.2 shows that fault models other than stuck-at can be considered.\\nEXAMPLE 1 \\nA suitable way to simplify the verification of non-stuck-at faults can be to provide evidence that \\nthe fault distribution of stuck-open/bridging faults is a very limited portion of the whole fault models population, \\ni.e. much lower than the stuck-at 0/1 fault population.\\nEXAMPLE 2 \\nIn some cases, hardware safety mechanisms can be more effective to detect each kind of fault \\nand easier to be verified using e.g. the N-detect approach. On the other hand, in the case of a software-based \\nsafety mechanism addressing random hardware failures, it can be difficult with the N-detect technique to gain \\na high level of confidence in the pattern richness due to the possible change of the context between subsequent \\nexecutions of the test at run time. In this case, alternative solutions can be applied (e.g. Reference [39]).\\n \\n74 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nIf properly exercised, methods derived from stuck-at simulations (like N-detect testing, see for example \\nReferences [35] to [37]) can be applied for verification of non-stuck-at fault models as well.\\nEXAMPLE 3 \\nSince exhaustiveness is not required, the non-stuck-at fault models analysis can be applied to a \\nsubset of the digital component subparts selected depending on their possible impact (for example comparators) \\nor on a statistical basis.\\nEXAMPLE 4 \\nFor N-detect testing, \\xe2\\x80\\x9cproperly exercised\\xe2\\x80\\x9d means that N different detections of the same fault are \\nguaranteed by the pattern set (i.e. pattern richness). N can range from 5 to 10.\\nNOTE \\nFault injection can also be used to inject bridging faults (see 5.1.2) in specific locations based on layout \\nanalysis or to verify the impact of dependent failures such as injection of clock and reset faults.\\n5.1.11 Example of safety documentation for a digital component\\nThe necessary information from the work products is provided to the system integrator, including \\ndocumentation of assumed requirements, assumptions related to the design external to the SEooC and \\napplicable work products.\\nOn that basis, the safety documentation for an SEooC digital component can include the following \\ndocuments or a subset of them as specified in the DIA:\\n\\xe2\\x80\\x95 \\nthe safety case related to the digital component, see ISO 26262-2:2018, 6.5.4;\\n\\xe2\\x80\\x95 \\nthe safety plan for the digital component, see ISO 26262-2:2018, 6.5.3;\\n\\xe2\\x80\\x95 \\nother plans as seen in ISO 26262-8, when applicable, such as configuration management plan, change \\nmanagement plan, impact analysis and change request plan, verification plan, documentation \\nmanagement plan and software tool qualification plan;\\n\\xe2\\x80\\x95 \\nthe evidence related to the execution of the applicable steps of a safety plan as seen in ISO 26262-2;\\n\\xe2\\x80\\x95 \\nthe hardware specifications as seen in ISO 26262-5, such as hardware safety requirements \\nspecification, hardware-software Interface (HSI) specification and hardware design specification;\\n\\xe2\\x80\\x95 \\nthe reports related to the execution of the applicable steps of the verification plan and other plans \\nas seen in ISO 26262-5 and ISO 26262-8, such as hardware safety requirements verification report, \\nhardware design verification report, and hardware integration and verification report; and\\n\\xe2\\x80\\x95 \\nthe reports related to safety analyses as seen in ISO 26262-5, ISO 26262-8 and ISO 26262-9, such \\nas hardware safety analysis report, review report of the effectiveness of the architecture of the \\ndigital component to cope with random hardware failures, review report of evaluation of safety \\ngoal violations due to random hardware failures and results of analyses of dependent failures.\\nNOTE 1 \\nThe DIA specifies which documents are made available and what level of detail is provided to the \\ndigital component\\xe2\\x80\\x99s customer.\\nThe following information can be considered:\\n\\xe2\\x80\\x95 \\nthe description of lifecycle tailored for the digital component; list of applicable work products \\n(description of which work products of the lifecycle are applicable for the digital component);\\n\\xe2\\x80\\x95 \\nthe description of the digital component safety architecture with an abstract description of digital \\ncomponent functionalities and description of safety mechanisms;\\n\\xe2\\x80\\x95 \\nthe description of Assumptions of Use (AoU) of the digital component with respect to its intended \\nuse, including: assumption on the digital component safe state; assumptions on maximum fault \\nhandling time interval and MPFDI; assumptions on the digital component context, including its \\nexternal interfaces;\\n\\xe2\\x80\\x95 \\nthe description of the digital component configuration and related hardware and/or software \\nprocedures to control a failure after its detection;\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n75\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nthe DIA defines which of the following reports are needed at system/item level:\\n\\xe2\\x80\\x95 \\nhardware safety analysis report;\\n\\xe2\\x80\\x95 \\nreport of the effectiveness of the architecture of digital component to cope with random \\nhardware faults;\\n\\xe2\\x80\\x95 \\nreport of evaluation of safety goal violation due to random hardware failures; and\\n\\xe2\\x80\\x95 \\nresults of analyses of dependent failures.\\n\\xe2\\x80\\x95 \\nthe description of the functional safety assessment process; list of confirmation measures and \\ndescription of the independency level; summary of process for avoidance of systematic failures in \\nthe digital component.\\nNOTE 2 \\nThis documentation can be recorded in one document named a \\xe2\\x80\\x9cSafety Manual\\xe2\\x80\\x9d or \\xe2\\x80\\x9cSafety Application \\nNote\\xe2\\x80\\x9d of the digital component.\\n5.1.12 Examples of safety mechanisms for digital components and memories\\nNOTE \\nThis sub-clause extends on ISO 26262-5:2018 Annex D for digital semiconductor components.\\nFor memories, the following Table 32 and Table 33 can be applied.\\nTable 32 \\xe2\\x80\\x94 Non-volatile memory\\nSafety mechanism/ \\nmeasure\\nSee overview \\nof techniques\\nTypical diagnostic coverage \\nconsidered achievable\\nNotes\\nParity bit\\n5.1.13.6\\nLow\\n\\xe2\\x80\\x94\\nMemory monitoring \\nusing error-detec-\\ntion-correction codes \\n(ECC)\\n5.1.13.1\\nHigh\\nThe effectiveness depends on the \\nnumber of redundant bits. Can be \\nused to correct errors\\nModified checksum\\n5.1.13.2\\nLow\\nDepends on the number and loca-\\ntion of bit errors within test area\\nMemory Signature\\n5.1.13.3\\nHigh\\n\\xe2\\x80\\x94\\nBlock replication\\n5.1.13.4\\nHigh\\n\\xe2\\x80\\x94\\nTable 33 \\xe2\\x80\\x94 Volatile memory\\nSafety mechanism/ \\nmeasure\\nSee overview \\nof techniques\\nTypical diagnostic coverage \\nconsidered achievable\\nNotes\\nRAM pattern test\\n5.1.13.5\\nMedium\\nHigh coverage for stuck-at failures. \\nNo coverage for linked failures. \\nCan be appropriate to run under \\ninterrupt protection\\nRAM March test\\n5.1.13.7\\nHigh\\nDepends on the write read order \\nfor linked cell coverage. Test gener-\\nally not appropriate for run time\\nParity bit\\n5.1.13.6\\nLow\\n\\xe2\\x80\\x94\\n \\n76 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nSafety mechanism/ \\nmeasure\\nSee overview \\nof techniques\\nTypical diagnostic coverage \\nconsidered achievable\\nNotes\\nMemory monitoring \\nusing error-detec-\\ntion-correction codes \\n(ECC)\\n5.1.13.1\\nHigh\\nThe effectiveness depends on the \\nnumber of redundant bits. Can be \\nused to correct errors\\nBlock replication\\n5.1.13.4\\nHigh\\nCommon failure modes can reduce \\ndiagnostic coverage\\nRunning checksum/CRC\\n5.1.13.8\\nHigh\\nThe effectiveness of the signature \\ndepends on the polynomial in \\nrelation to the block length of the \\ninformation to be protected. Care \\nis taken so that values used to de-\\ntermine checksum are not changed \\nduring checksum calculation\\nProbability is 1/maximum value \\nof checksum if random pattern is \\nreturned\\nFor general digital logic, Table 34 can be applied.\\nTable 34 \\xe2\\x80\\x94 Combinatorial and sequential logic\\nSafety mechanism/ \\nmeasure\\nSee overview of \\ntechniques\\nTypical diagnostic coverage \\nconsidered achievable\\nNotes\\nSelf-test by software\\nISO 26262-\\n5:2018, D.2.3.1\\nMedium\\n\\xe2\\x80\\x94\\nSelf-test supported by \\nhardware (one-chan-\\nnel)\\nISO 26262-\\n5:2018, D.2.3.2\\nMedium\\nHigher coverage is possible, de-\\npending on effectiveness of test. \\nGate level is an appropriate level \\nfor this test\\nFor on-chip interconnect, Table 35 can be applied.\\nTable 35 \\xe2\\x80\\x94 On-chip communication\\nSafety mechanism/ \\nmeasure\\nSee overview of \\ntechniques\\nTypical diagnostic coverage \\nconsidered achievable\\nNotes\\nOne-bit hardware \\nredundancy\\nISO 26262-\\n5:2018, D.2.5.1\\nLow\\n\\xe2\\x80\\x94\\nMulti-bit hardware \\nredundancy (includ-\\ning ECC)\\nISO 26262-\\n5:2018, D.2.5.2\\nMedium\\nMulti-bit redundancy can achieve \\nhigh coverage by proper interleav-\\ning of data, address and control \\nlines, and if combined with some \\ncomplete redundancy, e.g. for the \\narbiter.\\nComplete hardware \\nredundancy\\nISO 26262-\\n5:2018, D.2.5.3\\nHigh\\nCommon failure modes can reduce \\ndiagnostic coverage\\nInspection using test \\npatterns\\nISO 26262-\\n5:2018, D.2.5.4\\nHigh\\nDepends on type of pattern\\n5.1.13 Overview of techniques for digital components and memories\\n5.1.13.1 Memory monitoring using error-detection-correction codes (ECC)\\nNOTE 1 \\nThis technique/measure is referenced in Table 32 and Table 33 of this document.\\n \\nTable 33 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n77\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nAim: To detect each single-bit failure, each two-bit failure, some three-bit failures, and some all-bit \\nfailures in a word (typically 32, 64 or 128 bits).\\nDescription: Every word of memory is extended by several redundant bits to produce a modified \\nHamming code with a Hamming distance of at least 4. Every time a word is read, checking of the \\nredundant bits can determine whether or not a corruption has taken place. If a difference is found, a \\nfailure message is produced.\\nThe procedure can also be used to detect addressing failures, by calculating the redundant bits for the \\nconcatenation of the data word and its address. Otherwise for addressing failures, the probability of \\ndetection is dependent on the number of ECC bits for random data returned (for example, address line \\nopen or address line shorted to another address line such that an average of the two cells is returned). \\nThe coverage will most likely be lower if the addressing error leads to a completely different cell \\nselected, it could even be 0% if no protection against address decoder faults is provided.\\nFor RAM cell write-enable failure, ECC can provide high coverage if the cell cannot be initialized. The \\ncoverage is 0 % if the write-enable failure affects the entire cell after it has been initialized.\\n5.1.13.2\\t Modified\\tchecksum\\nNOTE \\nThis technique/measure is referenced in Table 32 of this document.\\nAim: To detect each single bit failure.\\nDescription: A checksum is created by a suitable algorithm which uses each of the words in a block of \\nmemory. The checksum can be stored as an additional word in ROM, or an additional word can be added \\nto the memory block to ensure that the checksum algorithm produces a predetermined value. In a later \\nmemory test, a checksum is created again using the same algorithm, and the result is compared with \\nthe stored or defined value. If a difference is found, a failure message is produced (see Reference [34]). \\nThe probability of a missed detection is 1/(2size of checksum) if a random result is returned. If certain \\ndata disturbances are more probable, some checksums can provide a better detection ratio than the \\none for random results.\\n5.1.13.3 Memory signature\\nNOTE 1 \\nThis technique/measure is referenced in Table 32 of this document.\\nAim: To detect each one-bit failure and most multi-bit failures.\\nDescription: The contents of a memory block are compressed (using either hardware or software) \\ninto one or more bytes using, for example, a cyclic redundancy check (CRC) algorithm. A typical \\nCRC algorithm treats the whole contents of the block as byte-serial or bit-serial data flow, on which \\na continuous polynomial division is carried out using a polynomial generator. The remainder of the \\ndivision represents the compressed memory contents \\xe2\\x80\\x94 it is the \\xe2\\x80\\x9csignature\\xe2\\x80\\x9d of the memory \\xe2\\x80\\x94 and is \\nstored. The signature is computed once again in later tests and compared with one already stored. A \\nfailure message is produced if there is a difference.\\nCRCs are particularly effective in detecting burst errors. The effectiveness of the signature depends on \\nthe polynomial in relation to the block length of the information to be protected. The probability of a \\nmissed detection is 1/(2size of checksum) if a random result is returned (see Reference  [34]).\\nNOTE 2 \\nUse of an 8 bit CRC is not generally considered the state of the art for memory sizes above 4 k.\\n5.1.13.4 Block replication (for example double memory with hardware or software comparison)\\nNOTE \\nThis technique/measure is referenced in Table 32 and Table 33 of this document.\\nAim: To detect each bit failure.\\nDescription: The address space is duplicated in two memories. The first memory is operated in the \\nnormal manner. The second memory contains the same information and is accessed in parallel to the \\n \\n78 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nfirst. The outputs are compared and a failure message is produced if a difference is detected. Dependent \\non memory subsystem design, storage of inverse data in one of the two memories can enhance \\ndiagnostic coverage. Coverage can be reduced if failure modes (such as common address lines, write-\\nenables) exist that are common to both blocks or if physical placement of memory cells makes logically \\ndistant cells physical neighbours.\\n5.1.13.5 RAM Pattern test\\nNOTE 1 \\nThis technique/measure is referenced in Table 33 of this document.\\nAim: To detect predominantly static bit failures.\\nDescription: A bit pattern followed by the complement of that bit pattern is written into the cells \\nof memory.\\nRAM locations are generally tested individually. The cell content is stored and then all 0s are written \\nto the cell. The cell contents are then verified by a read back of the 0 values. The procedure is repeated \\nby writing all 1s to the cell and reading the contents back. If a transition failure from 1 to 0 is a failure \\nmode of concern, an additional write and read of 0s can be performed. Finally, the original contents of \\nthe cell are restored (see Reference [34], Section 4.2.1). The test is effective at detecting stuck-at and \\ntransition failures but cannot detect most soft errors, addressing faults and linked cell faults.\\nNOTE 2 \\nThe test is often implemented in the background with interrupt suppression during the test of each \\nindividual location.\\nNOTE 3 \\nBecause the implementation includes a read of a just written value, optimizing compilers have a \\ntendency to optimize out the test. If an optimizing compiler is used, good design practice is to verify the test code \\nby an assembler-level code inspection.\\nNOTE 4 \\nSome RAMs can fail such that the last memory access operation is echoed back as a read. If this is a \\nplausible failure mode, the diagnostic can test two locations together, first writing a 0 to one location and then a \\n1 to the next and then verifying a 0 is read from the first location.\\n5.1.13.6 Parity bit\\nNOTE \\nThis technique/measure is referenced in Table 32 and Table 33 of this document.\\nAim: To detect a single corrupted bit or an odd number of corrupted bit failures in a word (typically \\n8 bits, 16 bits, 32 bits, 64 bits or 128 bits).\\nDescription: Every word of the memory is extended by one bit (the parity bit) which completes each \\nword to an even or odd number of logical 1s. The parity of the data word is checked each time it is read. \\nIf the wrong number of 1s is found, a failure message is produced. The choice of even or odd parity \\nought to be made such that, whichever of the zero word (nothing but 0s) or the one word (nothing but \\n1s) is the more unfavourable in the event of a failure, then that word is not a valid code.\\nParity can also be used to detect addressing failure, when the parity is calculated for the concatenation \\nof the data word and its address. Otherwise, for addressing failures, there is a 50 % probability of \\ndetection for random data returned (for example, address line open or address line shortened to another \\naddress line such that an average of the two cells is returned). The coverage is 0 % if the addressing \\nerror leads to a completely different cell selected.\\nFor RAM cell write-enable failure, parity can detect 50 % of failures if the cell is unable to be initialized. \\nThe coverage is 0 % if the write-enable failure affects the entire cell after it has been initialized.\\n5.1.13.7 RAM March test\\nNOTE 1 \\nThis technique/measure is referenced in Table 33 of this document.\\nAim: To detect predominantly persistent bit failures, bit transition failures, addressing failures and \\nlinked cell failures.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n79\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nDescription: A pattern of 0s and 1s is written into the cells of memory in a specific pattern and verified \\nin a specific order.\\nA March test consists of a finite sequence of March elements; while a March element is a finite sequence \\nof operations applied to every cell in the memory array before proceeding to the next cell. For example, \\nan operation can consist of writing a 0 into a cell, writing a 1 into a cell, reading an expected 0 from \\na cell, and reading an expected 1 from a cell. A failure is detected if the expected \\xe2\\x80\\x9c1\\xe2\\x80\\x9d is not read. The \\ncoverage level for linked cells depends on the write/read order.\\nReference [34], Chapter 4, lists a number of different March tests designed to detect various RAM \\nfailure modes: stuck-at faults, transition faults (inability to transition from a one to a zero or a zero to \\na one but not both), address faults and linked cell faults. These types of tests are not effective for soft \\nerror detection.\\nNOTE 2 \\nThese tests can usually only be run at initialization or shutdown.\\n5.1.13.8 Running checksum/CRC\\nNOTE \\nThis technique/measure is referenced in Table 33 of this document.\\nAim: To detect single bit, and some multiple bit, failures in RAM.\\nDescription: A checksum/CRC is created by a suitable algorithm which uses each of the words in a \\nblock of memory. The checksum is stored as an additional word in RAM. As the memory block is \\nupdated, the RAM checksum/CRC is also updated by removing the old data value and adding in the new \\ndata value to be stored to the memory location. Periodically, a checksum/CRC is calculated for the data \\nblock and compared to the stored checksum/CRC. If a difference is found, a failure message is produced. \\nThe probability of a missed detection is 1/(2size of checksum/CRC) if a random result is returned. DC can \\nbe reduced as memory size increases.\\n5.2 Analogue/mixed signal components\\n5.2.1 \\nAbout analogue and mixed signal components\\nAs described in 4.2, a semiconductor component is structured in parts and subparts. If the signals that \\nare handled in an element (component, part or subpart) are not limited to digital states, this element \\nis seen as an analogue element. This is the case for each measurement interface to the physical world, \\nincluding sensors, actuator outputs, and power supplies.\\nFor analogue components, each element is analogue and no digital element is included. Mixed signal \\ncomponents consist of at least one analogue element and one digital element. Since analogue and \\ndigital elements require different methodologies and tooling for design, layout, verification and testing, \\nit is recommended to clearly divide the analogue and digital blocks. This can result in a variety of \\nconfigurations ranging from components that are primarily analogue but have digital support blocks \\n(e.g. digitally configurable voltage regulators or auto zeroing amplifiers) to components such as \\nmicrocontrollers that have only a few mixed signal peripherals (e.g. analogue to digital converters and \\nphase locked loops). A hierarchy of a typical mixed signal component including exemplary parts and \\nsubparts is shown in Figure 24.\\n \\n80 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 24 \\xe2\\x80\\x94 Generic hierarchy of analogue and mixed signal components\\nIn order to simplify the safety analysis, a mixed signal component can be divided into its analogue and \\ndigital elements. The boundary of an analogue element can be defined by its function and its associated \\nfault models and failure modes. Additionally, each element that has freedom from interference or \\nindependence requirements (e.g. redundant paths or functions and corresponding diagnostic functions) \\nis separated by part or subpart boundaries.\\nAdditional criteria can also be considered when dividing a mixed signal element (component or part) \\ninto sub elements (part or subpart):\\n\\xe2\\x80\\x95 \\nsignal flow;\\nEXAMPLE 1 \\nMixed signal control loops can consist of feedback ADC, digital regulator and output driver.\\n\\xe2\\x80\\x95 \\nconnectivity;\\nEXAMPLE 2 \\nReference and bias circuits can serve multiple analogue blocks and oscillators can serve \\nmultiple digital or mixed signal blocks.\\n\\xe2\\x80\\x95 \\ndifferent technologies;\\nEXAMPLE 3 \\nHV switch is a DMOS transistor while the gate driver can use conventional MOS devices.\\nNOTE \\nOne benefit for a separation of these parts is that they can have failure rates with different orders \\nof magnitude or different fault models.\\n\\xe2\\x80\\x95 \\ndifferent supply domains; and\\nEXAMPLE 4 \\nFeedback DAC can have different supplies than the other mixed signal block output driver.\\n\\xe2\\x80\\x95 \\nother criteria for partitioning.\\nEXAMPLE 5 \\nFrequency partitioning, such as high frequency versus low frequency subparts.\\nThe level of detail of the analysis is determined by the relevant safety requirements, safety mechanisms \\nand the need to provide evidence of independence of safety mechanisms. Higher granularity does not \\nnecessarily result in a significant benefit for the safety analysis.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n81\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.2.2 \\nAnalogue and mixed signal components and failure modes\\n5.2.2.1 \\nAbout failure modes\\nThe failure modes of a hardware element depend on its function. The failure mode distribution depends \\non the hardware element implementation.\\nNOTE 1 \\nThe \\xe2\\x80\\x9cimplementation\\xe2\\x80\\x9d is intended both the actual circuit design and the targeted process used.\\nThe classification of a failure mode depends on the functional and safety requirements allocated to the \\nsystem integrating the element. Based on the integration, a specific failure mode can or cannot lead to \\na violation of a safety requirement. Table 36 identifies possible failure modes that can be of concern for \\nan analogue and mixed signal part or subpart. The table can be used to extend the list of failure modes \\nreported in ISO 26262-5:2018, Annex D.\\nThe failure modes identified in Table 36 as well as the mentioned parts and subparts, are a general \\nreference and can be adjusted on a case by case basis. Failure modes for analogue circuits can be \\nderived by applying key words as mentioned in 4.3.2.\\nThe actual failure mode list used in a specific project can be adjusted (adding or removing failure \\nmodes) based on the specific implementation details or on the level of granularity deemed necessary \\nfor the analysis.\\nIt is noted that the relevance of the failure modes, including but not limited to those listed in Table 36 is \\ndependent on the context of the function to be analysed.\\nEXAMPLE 1 \\nThe obvious failure modes of a voltage regulator are over-voltage and under-voltage. These \\nfailure modes can be detected by an over voltage and under voltage (OV/UV) monitor as described in 5.2.4.2.\\nBesides the obvious failure modes reported in the above example, it is important to identify each \\nrelevant failure mode in order to perform a complete and thorough analysis.\\nEXAMPLE 2 \\nIf a voltage regulator is used as a sensor supply or as an ADC reference supply, then the failure \\nmodes affecting the stability and the accuracy of the output voltage, even within the OV/UV thresholds, can be \\ncritical. Output voltage with insufficient accuracy and output voltage oscillation within the OV/UV thresholds \\ncan be mitigated by using appropriate measures. An independent ADC (internal or external) can be used to \\nperiodically measure the regulator output voltage with the required accuracy to detect those failure modes.\\nEXAMPLE 3 \\nIf a voltage regulator is used as a supply for a radio frequency (RF) module which has tight supply \\nvoltage ripple requirements, the prevention of fluctuation on the regulated output voltage caused by input \\nvoltage variations is an important feature, i.e. the power supply rejection ratio (PSRR). Failure modes like output \\nvoltage oscillation within the OV/UV (i.e. ripple) limits and spikes affecting the regulated voltage can be relevant. \\nA low pass filter as described in 5.2.4.8 can be used to mitigate these failures.\\nEXAMPLE 4 \\nIf a voltage regulator used as an MCU core supply is sensitive to output voltage drops during start-\\nup (power-up) due to in-rush current exceeding regulator load current and/or current limit, a too fast start-up \\ntime can be critical. A proper regulator soft-start function can be used to mitigate such failure.\\nIf failure modes are classified as not safety-related, a rationale is to be provided in the safety analysis to \\nsupport the classification.\\nGiven the variety of implementations, Table 36 does not give any indication about the quantitative \\nimpact of the listed failure modes, i.e. the failure mode distribution. It is the responsibility of the \\nsemiconductor supplier to provide such quantitative data. An example is given in 5.2.3.3.\\nNOTE 2 \\nEven though it is known that a single physical root cause can lead to more than one failure mode, it is \\nreasonable to assume that the sum of the distribution of each failure mode is 100 % which is a prerequisite for \\nthe quantitative analysis.\\n \\n82 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 36 \\xe2\\x80\\x94 Possible failure modes of analogue and mixed signal parts and subparts\\nPart/subpart\\nShort description\\nFailure modes\\nRegulators and Power stages\\nVoltage regulators (line-\\nar, SMPS, etc.)\\nHardware part/subpart \\nthat maintains the volt-\\nage of a power source \\nwithin a prescribed \\nrange that can be toler-\\nated by elements using \\nthat voltage.\\nOutput voltage higher than a high threshold of the pre-\\nscribed range (i.e. over voltage \\xe2\\x80\\x94 OV)\\nOutput voltage lower than a low threshold of the prescribed \\nrange (i.e. under voltage \\xe2\\x80\\x94 UV)\\nOutput voltage affected by spikesb\\nIncorrect start-up time (i.e. outside the expected range)\\nOutput voltage accuracy too low, including driftc\\nOutput voltage oscillationa within the prescribed range\\nOutput voltage affected by a fast oscillationa outside the \\nprescribed range but with average value within the pre-\\nscribed range\\nQuiescent current (i.e. current drawn by the regulator in \\norder to control its internal circuitry for proper operation) \\nexceeding the maximum value\\nCharge pump, regulator \\nboost\\nHardware part/sub-\\npart that converts, and \\noptionally regulates, \\nvoltages using switch-\\ning technology and ca-\\npacitive-energy storage \\nelements, and main-\\ntains a constant output \\nvoltage with a varying \\nvoltage input.\\nOutput voltage higher than a high threshold of the pre-\\nscribed range (i.e. over voltage \\xe2\\x80\\x94 OV)\\nOutput voltage lower than a low threshold of the prescribed \\nrange (i.e. under voltage \\xe2\\x80\\x94 UV)\\nOutput voltage affected by spikesb\\nIncorrect start-up time (i.e. outside the expected range)\\nQuiescent current (i.e. current drawn by the regulator in \\norder to control its internal circuitry for proper operation) \\nexceeding the maximum value\\nHigh-side/Low-side \\n(HS/LS) driver\\nHardware part/sub-\\npart that applies voltage \\nto a load in a single di-\\nrection: high side driver \\nto connect the load to \\nhigh rail, low side driver \\nto connect the load to \\nlow rail.\\nHS/LS driver is stuck in ON or OFF state\\nHS/LS driver is floating (i.e. open circuit, tri-stated)\\nHS/LS driver resistance too high when turned on\\nHS/LS driver resistance too low when turned off\\nHS/LS driver turn-on time too fast or too slow\\nHS/LS driver turn-off time too fast or too slow\\na \\n   An oscillation is an instability of the part/subpart caused by internal failure, e.g. regulation loop failures, lower or \\nnegative hysteresis for a comparator, etc.. Oscillation includes any repetitive voltage and current variation (i.e. periodic pulse).\\nb \\n   A spike is a non-repetitive variation on the output voltage or current, i.e. pulse due to load jumps, etc.\\nc \\n   Drift is a slow and continuous variation of a parameter (i.e. current, voltage, threshold, etc.) outside the expected \\nrange reported into the circuit specification. Slow variation means slower than maximum fault handling time interval. For \\nexample drift covers floating or stuck at open failure modes.\\nd \\n   Several of the failure modes reported for the ADC or DAC can be grouped into two main sets: static error and absolute \\naccuracy (total) error. Static errors are errors that affect the accuracy of a converter when it is converting static (DC) \\nsignals and can be completely described by four terms: offset error, gain error, integral nonlinearity, and differential \\nnonlinearity.\\nNOTE 1   Each term can be expressed in LSB units or sometimes as a percentage of the full scale range (FSR). For example, \\nan error of \\xc2\\xbd LSB for an 8-bit converter corresponds to 0,2 % FSR.\\nNOTE 2   The absolute accuracy (total) error is the maximum value of the difference between an analogue value and the ideal \\nmid-step value. It includes offset, gain, and integral linearity errors, and also the quantization error in the case of an ADC.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n83\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nShort description\\nFailure modes\\nHalf-bridge driver or\\nfull-bridge (H-bridge) \\ndriver\\nHardware part/sub-\\npart that can apply \\nvoltage across a load in \\neither direction.\\nA half-bridge driver is \\nbuilt with two drivers \\n(one HS and one LS driv-\\ner). An H-bridge (or full-\\nbridge) driver is built \\nwith four drivers (two \\nHS and two LS drivers)\\nHS/LS driver is stuck in ON or OFF state\\nHS/LS driver is floating (i.e. open circuit, tri-stated)\\nHS/LS driver ON resistance too high when turned on\\nHS/LS driver OFF resistance too low when turned off\\nHS/LS driver turn-on time too fast or too slow\\nHS/LS driver turn-off time too fast or too slow\\n\\xe2\\x80\\x98Dead time\\xe2\\x80\\x99 is too short (i.e. when turning off high-side \\ndriver and turning on low-side driver, or when turning off \\nlow-side driver and turning on high-side driver)\\n\\xe2\\x80\\x98Dead time\\xe2\\x80\\x99 is too long\\nHigh-side/Low-side \\npre-driver\\nHardware part/subpart \\ndriving a gate of an ex-\\nternal FET that is used \\nas a HS or LS driver.\\nHS/LS pre-driver is stuck in ON or OFF states\\nHS/LS pre-driver output voltage/current too high or too low\\nHS/LS pre-driver is floating (i.e. open circuit, tri-stated)\\nHS/LS pre-driver slew rate too slow or too fast\\nAnalogue to digital and digital to analogue convertersd\\nN bits digital to ana-\\nlogue converters (DAC)d\\nHardware part/subpart \\nconverting digital data \\ncoded on \\xe2\\x80\\x9cN bits\\xe2\\x80\\x9d into an \\nanalogue signal (voltage \\nor current).\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit)\\nOffset error (not including stuck or floating conditions on \\nthe outputs, low resolution)\\nLinearity error with monotonic conversion curve not \\nincluding stuck or floating conditions on the outputs, low \\nresolution\\nFull-scale gain-error not including stuck or floating condi-\\ntions on the outputs, low resolution\\nNo monotonic conversion curve\\nIncorrect settling time (i.e. outside the expected range)\\nOscillationa of the output signal including driftc\\na \\n   An oscillation is an instability of the part/subpart caused by internal failure, e.g. regulation loop failures, lower or \\nnegative hysteresis for a comparator, etc.. Oscillation includes any repetitive voltage and current variation (i.e. periodic pulse).\\nb \\n   A spike is a non-repetitive variation on the output voltage or current, i.e. pulse due to load jumps, etc.\\nc \\n   Drift is a slow and continuous variation of a parameter (i.e. current, voltage, threshold, etc.) outside the expected \\nrange reported into the circuit specification. Slow variation means slower than maximum fault handling time interval. For \\nexample drift covers floating or stuck at open failure modes.\\nd \\n   Several of the failure modes reported for the ADC or DAC can be grouped into two main sets: static error and absolute \\naccuracy (total) error. Static errors are errors that affect the accuracy of a converter when it is converting static (DC) \\nsignals and can be completely described by four terms: offset error, gain error, integral nonlinearity, and differential \\nnonlinearity.\\nNOTE 1   Each term can be expressed in LSB units or sometimes as a percentage of the full scale range (FSR). For example, \\nan error of \\xc2\\xbd LSB for an 8-bit converter corresponds to 0,2 % FSR.\\nNOTE 2   The absolute accuracy (total) error is the maximum value of the difference between an analogue value and the ideal \\nmid-step value. It includes offset, gain, and integral linearity errors, and also the quantization error in the case of an ADC.\\n \\nTable 36 (continued)\\n84 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nShort description\\nFailure modes\\nN bits analogue to digital \\nconverters (N-bit ADC)d\\nHardware part/subpart \\nconverting a continu-\\nous-time and continu-\\nous-amplitude analogue \\nsignal (i.e. a voltage \\nvalue) to a discrete-time \\nand discrete-amplitude \\ndigital signal coded on \\n\\xe2\\x80\\x9cN bits.\\xe2\\x80\\x9d\\nOne or more outputs are stuck (i.e. high or low)\\nOne or more outputs are floating (i.e. open circuit)\\nAccuracy error (i.e. Error exceeds the LSBs)\\nOffset error not including stuck or floating conditions on \\nthe outputs, low resolution\\nNo monotonic conversion characteristic (i.e. given two \\ninput analogue voltage V1>V2, the correspondent digital \\nvalues are D1<D2)\\nFull-scale error not including stuck or floating conditions \\non the outputs, low resolution\\nLinearity error with monotonic conversion curve not \\nincluding stuck or floating conditions on the outputs, low \\nresolution\\nIncorrect settling time (i.e. outside the expected range)\\nOscillators and clock generators\\nOscillator\\nHardware part/subpart \\ngenerating a periodic, \\noscillating signal. It can \\nbe used as a clock in a \\ndigital circuit.\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit)\\nIncorrect output signal swing (i.e. outside the expected \\nrange)\\nIncorrect frequency of the output signal (i.e. outside the \\nexpected range, including harmonics when applicable, for \\ninstance EMC emissions)\\nIncorrect duty cycle of the output signal (i.e. outside the \\nexpected range)\\nDriftc of the output frequency\\nJitter too high in the output signal\\na \\n   An oscillation is an instability of the part/subpart caused by internal failure, e.g. regulation loop failures, lower or \\nnegative hysteresis for a comparator, etc.. Oscillation includes any repetitive voltage and current variation (i.e. periodic pulse).\\nb \\n   A spike is a non-repetitive variation on the output voltage or current, i.e. pulse due to load jumps, etc.\\nc \\n   Drift is a slow and continuous variation of a parameter (i.e. current, voltage, threshold, etc.) outside the expected \\nrange reported into the circuit specification. Slow variation means slower than maximum fault handling time interval. For \\nexample drift covers floating or stuck at open failure modes.\\nd \\n   Several of the failure modes reported for the ADC or DAC can be grouped into two main sets: static error and absolute \\naccuracy (total) error. Static errors are errors that affect the accuracy of a converter when it is converting static (DC) \\nsignals and can be completely described by four terms: offset error, gain error, integral nonlinearity, and differential \\nnonlinearity.\\nNOTE 1   Each term can be expressed in LSB units or sometimes as a percentage of the full scale range (FSR). For example, \\nan error of \\xc2\\xbd LSB for an 8-bit converter corresponds to 0,2 % FSR.\\nNOTE 2   The absolute accuracy (total) error is the maximum value of the difference between an analogue value and the ideal \\nmid-step value. It includes offset, gain, and integral linearity errors, and also the quantization error in the case of an ADC.\\n \\nTable 36 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n85\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nShort description\\nFailure modes\\nPhase locked loop (PLL)\\nHardware part/subpart \\ncontrolling an oscillator \\nin order to generate a \\nsquare wave signal that \\nmaintains a constant \\nphase angle (i.e. lock) \\non the frequency of \\nan input, or reference \\nsignal. It can be used as \\nclock in a digital circuit.\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit)\\nIncorrect frequency of the output signal (i.e. outside the \\nexpected range, including harmonics when applicable, e.g. \\nEMC emissions)\\nIncorrect duty cycle of the output signal (i.e. outside the \\nexpected range)\\nDriftc of the output frequency\\nJitter too high in the output signal\\nLoss of lock condition (i.e. phase error, output clock not in \\nsync with input clock not leading to incorrect frequency \\nand incorrect duty cycle)\\nMissing pulse in the output signal\\nExtra pulse in the output signal\\nGeneric\\nOperational amplifier \\nand buffer\\nHardware part/subpart \\nintegrating a DC-cou-\\npled high-gain voltage \\namplifier with a differ-\\nential input and, usually, \\na single-ended output.\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit)\\nIncorrect gain on the output voltage (i.e. outside the ex-\\npected range)\\nIncorrect offset on the output voltage (i.e. outside the ex-\\npected range)\\nIncorrect output dynamic range (i.e. outside the expect-\\ned range)\\nIncorrect input dynamic range (i.e. outside the expected \\nrange)\\nOutput voltage accuracy too low, including driftc\\nOutput voltage affected by spikesb\\nOutput voltage oscillationa\\nSettling time of the output voltage too low\\na \\n   An oscillation is an instability of the part/subpart caused by internal failure, e.g. regulation loop failures, lower or \\nnegative hysteresis for a comparator, etc.. Oscillation includes any repetitive voltage and current variation (i.e. periodic pulse).\\nb \\n   A spike is a non-repetitive variation on the output voltage or current, i.e. pulse due to load jumps, etc.\\nc \\n   Drift is a slow and continuous variation of a parameter (i.e. current, voltage, threshold, etc.) outside the expected \\nrange reported into the circuit specification. Slow variation means slower than maximum fault handling time interval. For \\nexample drift covers floating or stuck at open failure modes.\\nd \\n   Several of the failure modes reported for the ADC or DAC can be grouped into two main sets: static error and absolute \\naccuracy (total) error. Static errors are errors that affect the accuracy of a converter when it is converting static (DC) \\nsignals and can be completely described by four terms: offset error, gain error, integral nonlinearity, and differential \\nnonlinearity.\\nNOTE 1   Each term can be expressed in LSB units or sometimes as a percentage of the full scale range (FSR). For example, \\nan error of \\xc2\\xbd LSB for an 8-bit converter corresponds to 0,2 % FSR.\\nNOTE 2   The absolute accuracy (total) error is the maximum value of the difference between an analogue value and the ideal \\nmid-step value. It includes offset, gain, and integral linearity errors, and also the quantization error in the case of an ADC.\\n \\nTable 36 (continued)\\n86 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nShort description\\nFailure modes\\nAnalogue switch\\nHardware part/subpart \\ncapable of switching \\nor routing analogue \\nsignals based on the \\nlevel of a digital control \\nsignal. Commonly \\nimplemented using a \\n\"transmission gate\\xe2\\x80\\x9d.\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit or tri-stated)\\nOffset too high affecting the output signal\\nResistive or capacitive coupling between control signal and \\noutput signal including crosstalk\\nAttenuation of the output signal\\nDriftc affecting the output signal\\nSpikesb affecting the output signal , e.g. during switching\\nVoltage/Current com-\\nparator\\nHardware part/subpart \\ncomparing an input \\nanalogue signal with a \\npredefined threshold \\n(i.e. voltage or current \\nconstant value) and \\nproducing a binary \\nsignal at the output; \\nthe output depends on \\nwhich is higher between \\nthe input signal and \\nthe threshold and it \\nremains constant as the \\ndifference has the same \\npolarity.\\nVoltage/Current comparator not triggering when expected\\nVoltage/Current comparator falsely triggering\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open)\\nOscillationa of the output\\na \\n   An oscillation is an instability of the part/subpart caused by internal failure, e.g. regulation loop failures, lower or \\nnegative hysteresis for a comparator, etc.. Oscillation includes any repetitive voltage and current variation (i.e. periodic pulse).\\nb \\n   A spike is a non-repetitive variation on the output voltage or current, i.e. pulse due to load jumps, etc.\\nc \\n   Drift is a slow and continuous variation of a parameter (i.e. current, voltage, threshold, etc.) outside the expected \\nrange reported into the circuit specification. Slow variation means slower than maximum fault handling time interval. For \\nexample drift covers floating or stuck at open failure modes.\\nd \\n   Several of the failure modes reported for the ADC or DAC can be grouped into two main sets: static error and absolute \\naccuracy (total) error. Static errors are errors that affect the accuracy of a converter when it is converting static (DC) \\nsignals and can be completely described by four terms: offset error, gain error, integral nonlinearity, and differential \\nnonlinearity.\\nNOTE 1   Each term can be expressed in LSB units or sometimes as a percentage of the full scale range (FSR). For example, \\nan error of \\xc2\\xbd LSB for an 8-bit converter corresponds to 0,2 % FSR.\\nNOTE 2   The absolute accuracy (total) error is the maximum value of the difference between an analogue value and the ideal \\nmid-step value. It includes offset, gain, and integral linearity errors, and also the quantization error in the case of an ADC.\\n \\nTable 36 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n87\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nShort description\\nFailure modes\\nSample & hold\\nHardware part/subpart \\nsampling the voltage of \\na continuously varying \\nanalogue input signal \\nand holding its value \\nat a constant level for \\na specified minimum \\nperiod of time.\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit)\\nIncorrect sampling leading to gain/offset error on output \\nvoltage dependent on input signal\\nIncorrect gain on the output voltage (i.e. outside the ex-\\npected range)\\nIncorrect offset on the output voltage (i.e. outside the ex-\\npected range)\\nIncorrect output dynamic range (i.e. outside the expect-\\ned range)\\nIncorrect input dynamic range (i.e. outside the expected \\nrange)\\nOutput voltage accuracy too low during hold phase, includ-\\ning driftc\\nOutput voltage during hold phase affected by spikesb\\nOutput voltage oscillationa during hold phase\\nOutput does not settle sufficiently accurate during hold time\\nAnalogue multiplexer\\nHardware part/subpart \\nconsisting of multiple \\nanalogue input signals, \\nmultiple control inputs \\nand one output signal.\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit)\\nIncorrect channel selection\\nOffset affecting the output signal too high\\nResistive or capacitive coupling among input channels and \\noutput signal including crosstalk\\nResistive or capacitive coupling among selectors and out-\\nput signal including crosstalk\\nIncorrect output dynamic range (i.e. outside the expect-\\ned range)\\nAttenuation of the output signal\\nDriftc affecting the output signal\\nSpikesb affecting the output signal (i.e. during switching)\\na \\n   An oscillation is an instability of the part/subpart caused by internal failure, e.g. regulation loop failures, lower or \\nnegative hysteresis for a comparator, etc.. Oscillation includes any repetitive voltage and current variation (i.e. periodic pulse).\\nb \\n   A spike is a non-repetitive variation on the output voltage or current, i.e. pulse due to load jumps, etc.\\nc \\n   Drift is a slow and continuous variation of a parameter (i.e. current, voltage, threshold, etc.) outside the expected \\nrange reported into the circuit specification. Slow variation means slower than maximum fault handling time interval. For \\nexample drift covers floating or stuck at open failure modes.\\nd \\n   Several of the failure modes reported for the ADC or DAC can be grouped into two main sets: static error and absolute \\naccuracy (total) error. Static errors are errors that affect the accuracy of a converter when it is converting static (DC) \\nsignals and can be completely described by four terms: offset error, gain error, integral nonlinearity, and differential \\nnonlinearity.\\nNOTE 1   Each term can be expressed in LSB units or sometimes as a percentage of the full scale range (FSR). For example, \\nan error of \\xc2\\xbd LSB for an 8-bit converter corresponds to 0,2 % FSR.\\nNOTE 2   The absolute accuracy (total) error is the maximum value of the difference between an analogue value and the ideal \\nmid-step value. It includes offset, gain, and integral linearity errors, and also the quantization error in the case of an ADC.\\n \\nTable 36 (continued)\\n88 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nShort description\\nFailure modes\\nVoltage references\\nHardware part/subpart \\nproducing a constant DC \\n(direct-current) output \\nvoltage regardless of \\nvariations in external \\nconditions such as \\ntemperature, baromet-\\nric pressure, humidity, \\ncurrent demand, or the \\npassage of time.\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit)\\nIncorrect output voltage value (i.e. outside the expected \\nrange)\\nOutput voltage accuracy too low, including drift c\\nOutput voltage affected by spikesb\\nOutput voltage oscillationa within the expected range\\nIncorrect start-up time (i.e. outside the expected range)\\nPassive network\\nHardware part/subpart \\nconsisting of a network \\nof passive devices \\n(resistor and capacitor) \\nproviding a specific low \\npass transfer function\\nOutput is stuck (i.e. high or low)\\nOutput is floating (i.e. open circuit)\\nIncorrect output dynamic range (i.e. outside the expect-\\ned range)\\nIncorrect attenuation of the output signal (i.e. outside the \\nexpected range)\\nIncorrect settling time (i.e. outside the expected range)\\nDriftc affecting the output signal\\nOscillationa affecting the output signal (i.e. due to cross-\\ntalk, coupling or parasitic effects)\\nSpikesb affecting the output (i.e. due to crosstalk, coupling \\nor parasitic effects)\\na \\n   An oscillation is an instability of the part/subpart caused by internal failure, e.g. regulation loop failures, lower or \\nnegative hysteresis for a comparator, etc.. Oscillation includes any repetitive voltage and current variation (i.e. periodic pulse).\\nb \\n   A spike is a non-repetitive variation on the output voltage or current, i.e. pulse due to load jumps, etc.\\nc \\n   Drift is a slow and continuous variation of a parameter (i.e. current, voltage, threshold, etc.) outside the expected \\nrange reported into the circuit specification. Slow variation means slower than maximum fault handling time interval. For \\nexample drift covers floating or stuck at open failure modes.\\nd \\n   Several of the failure modes reported for the ADC or DAC can be grouped into two main sets: static error and absolute \\naccuracy (total) error. Static errors are errors that affect the accuracy of a converter when it is converting static (DC) \\nsignals and can be completely described by four terms: offset error, gain error, integral nonlinearity, and differential \\nnonlinearity.\\nNOTE 1   Each term can be expressed in LSB units or sometimes as a percentage of the full scale range (FSR). For example, \\nan error of \\xc2\\xbd LSB for an 8-bit converter corresponds to 0,2 % FSR.\\nNOTE 2   The absolute accuracy (total) error is the maximum value of the difference between an analogue value and the ideal \\nmid-step value. It includes offset, gain, and integral linearity errors, and also the quantization error in the case of an ADC.\\n \\nTable 36 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n89\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b' \\nISO 26262-11:2018(E)\\nPart/subpart\\nShort description\\nFailure modes\\nCurrent source (in-\\ncluding bias current \\ngenerator)\\nHardware part/subpart \\ndelivering or absorbing \\na current (i.e. refer-\\nence current) which \\nis independent of the \\nvoltage across it. It typ-\\nically includes multiple \\nbranches which are \\nrouted to other circuits \\nrequiring a reference or \\nbias current.\\nOne or more outputs are stuck (i.e. high or low)\\nOne or more outputs are floating (i.e. open circuit)\\nIncorrect reference current (i.e. outside the expected range)\\nReference current accuracy too low , including driftc\\nReference current affected by spikesb\\nReference current oscillationa within the expected range\\nOne or more branch currents outside the expected range \\nwhile reference current is correct\\nOne or more branch currents accuracy too low , including \\ndriftc\\nOne or more branch currents affected by spikesb\\nOne or more branch currents oscillationa within the ex-\\npected range\\na \\n   An oscillation is an instability of the part/subpart caused by internal failure, e.g. regulation loop failures, lower or \\nnegative hysteresis for a comparator, etc.. Oscillation includes any repetitive voltage and current variation (i.e. periodic pulse).\\nb \\n   A spike is a non-repetitive variation on the output voltage or current, i.e. pulse due to load jumps, etc.\\nc \\n   Drift is a slow and continuous variation of a parameter (i.e. current, voltage, threshold, etc.) outside the expected \\nrange reported into the circuit specification. Slow variation means slower than maximum fault handling time interval. For \\nexample drift covers floating or stuck at open failure modes.\\nd \\n   Several of the failure modes reported for the ADC or DAC can be grouped into two main sets: static error and absolute \\naccuracy (total) error. Static errors are errors that affect the accuracy of a converter when it is converting static (DC) \\nsignals and can be completely described by four terms: offset error, gain error, integral nonlinearity, and differential \\nnonlinearity.\\nNOTE 1   Each term can be expressed in LSB units or sometimes as a percentage of the full scale range (FSR). For example, \\nan error of \\xc2\\xbd LSB for an 8-bit converter corresponds to 0,2 % FSR.\\nNOTE 2   The absolute accuracy (total) error is the maximum value of the difference between an analogue value and the ideal \\nmid-step value. It includes offset, gain, and integral linearity errors, and also the quantization error in the case of an ADC.\\n5.2.2.2 \\nAbout transient faults\\nAs defined in ISO 26262-1:2018, 3.173, a transient fault is a fault that occurs once and subsequently \\ndisappears. Soft errors such as Single Event Upset (SEU) and Single Event Transient (SET), are defined \\nas transient faults (see 5.1.2). ISO 26262-5:2018, 8.4.7 states that transient faults are considered \\nwhen shown to be relevant due, for instance, to the technology used and can be addressed either by a \\nquantitative approach, specifying and verifying a dedicated target \\xe2\\x80\\x9csingle-point fault metric\\xe2\\x80\\x9d value to \\nthem or by a qualitative rationale based on the verification of the effectiveness of the internal safety \\nmechanisms implemented to cover these transient faults.\\nIn terrestrial analogue circuits, transient faults are caused by alpha-particle or neutron hits or by \\nelectromagnetic interference such as power transients and crosstalk. They can cause SEU or even SET \\nalso called Analogue Single Event Transients (ASETs), such as transient pulses in operational amplifiers, \\ncomparators or reference voltage circuits.\\nDue to the intrinsic nature of analogue technology (in which transient or noise effects are considered \\nby design), the susceptibility to transient faults is lower than in digital circuits by orders of magnitude. \\nTherefore, the analysis of those effects can be limited in a first approximation to their digital part \\n(e.g. the digital decimation filter of a sigma-delta ADC).\\nHowever in some cases, like in the early part of the conversion cycle of an ADC (see Reference [28]) \\nor in a PLL (see Reference [20]) or differential switched-capacitor circuits (see Reference [10]), the \\nvulnerability to soft error can be high. In those cases, more detailed analyses are done and appropriate \\ncountermeasures are identified (see Reference [1]).\\n \\nTable 36 (continued)\\n90 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFor mixed signal components, the impact of soft errors in the digital part is considered as described in \\n5.1.7.2.\\nNOTE \\nSoft Error Rate evaluation by irradiation tests in analogue circuits is not a simple task. In this case \\nmeasurement is done mainly by more detailed analyses of the analogue part.\\n5.2.3 \\nNotes about safety analysis\\n5.2.3.1 \\nGeneral\\nThe examples and guidelines given in 5.1 can be valid for an analogue or mixed signal component. The \\nfollowing clauses describe some of the topics that can require additional clarification for an analogue or \\nmixed signal component.\\n5.2.3.2 \\nLevel of granularity of analysis\\nOne of the key aspects for the safety analysis of analogue elements is the proper identification of the \\ngranularity of the analysis. On one hand, a lower level of granularity is beneficial as it allows for a \\nbetter understanding of the failure modes and failure mode distributions. On the other, a higher level \\nof granularity allows for a clear allocation of safety mechanisms. Analogue elements are often used \\nto interface with physical objects making it useful to also consider mechanical characteristics and \\ndifferentiate the failure modes accordingly.\\nAs seen in ISO 26262-9:2018, Clause 8, qualitative and quantitative safety analyses are performed at \\nthe appropriate level of abstraction during the concept and product development phases. The level of \\nabstraction can be consequently adjusted depending on the target of the analysis. Qualitative analysis \\nis more suited to identify failure modes while quantitative analysis quantifies their failure rates and \\ndistributions.\\nEXAMPLE \\nA linear voltage regulator is monitored using a windowed voltage monitor. The voltage monitor \\nis at the output of the regulator and is able to detect over-voltage conditions. If the output value moves outside \\nof a defined tolerance it is to be considered faulty e.g. 1,2 V \\xc2\\xb1 0,12 V. If the analysis focuses on the output of \\nthe regulator it can be relatively easy to discriminate between types of failures (e.g. safe because it fails within \\nthe allowed range, safety related because of over or under voltage) and quantify the protection offered by the \\nvoltage monitor. However, it is difficult to quantify the likelihood of each type of failure as required for metric \\ncomputation. If the analysis goes inside the regulator and focuses, for instance, on faults of the bandgap it is easier \\nto analyse propagation and likelihood of each failure of the regulator but not simple to quantify the protection \\nthat the external voltage monitor offers on the bandgap itself.\\nFor the safety analysis, the type of safety mechanisms can drive the selection of the level of granularity. If \\nthe safety mechanisms addressing analogue features are located at system or element level, descending \\nin the component hierarchy can lead to an overly complex analysis. The quantification of the failure \\nmode distribution can require an investigation of higher granularity. For instance, applying an equal \\ndistribution to the failure modes of the linear voltage regulator can give less accurate results than \\napplying an equal distribution to the blocks composing the linear voltage regulator as, for instance, the \\nbandgap, the buffer, the driver, etc. With respect to terminology, in line with the classification described \\nin 4.2, the linear voltage regulator is to be considered a part and the bandgap, the buffer, the driver, etc. \\nsubparts.\\n5.2.3.3 \\nDeriving failure mode distributions for analogue components\\nThe failure distributions for analogue components are dependent on the circuit implementation and \\ntargeted process. Each supplier provides details on the failure mode distributions to be used in the \\nanalysis.\\nEXAMPLE 1 \\nA uniform failure mode distribution can be used for the initial analysis, e.g. if five failure modes \\nare defined, each failure mode is allocated 20 % distribution. The uniform failure mode distribution is considered \\nin the example in 5.2.3.5.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n91\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nEXAMPLE 2 \\nA more detailed distribution for each failure mode can be considered based on area; if the area of \\nthe circuit or circuits identified as the root cause for the defined failure mode is 5 %, then the allocated failure \\nmode distribution is 5 %.\\nApplicable failure modes and the level of detail of the failure mode distributions are justified according \\nto the circuit implementation and its physical area and documented accordingly.\\n5.2.3.4 \\nAbout safe faults\\nISO 26262-10 [61] states that safe faults can be faults of one of two categories:\\n\\xe2\\x80\\x95 \\nall n point faults with n > 2, unless the safety concept shows them to be a relevant contributor to a \\nsafety requirement, or\\n\\xe2\\x80\\x95 \\nfaults that will not contribute to the violation of a safety requirement.\\nAnalogue components are characterized by continuous signal regions and as such, tolerances are taken \\ninto consideration when used in systems. The tolerances on analogue functions as specified as part of \\nthe safety requirements allocated to that analogue component can be less constrained than the actual \\ntolerance of the analogue component itself. For this reason, the fraction of the failure mode that leads \\nto parametric failure or drift, but which remains within these tolerance ranges is safe. An analogue \\ncomponent has therefore an inherent capability to tolerate a fault. These faults are safe faults.\\nEXAMPLE 1 \\nA resistor is used to limit the current flowing through a specific branch. A failure in the accuracy of \\nthe resistor increasing its value (e.g. of 50 %) but not preventing the current limiting function would be a safe fault.\\nA specific fault in an element can have a different classification depending on the specific safety \\nrequirement considered. For more details see ISO 26262-5.\\nDepending on the system configuration and the safety requirements some failure modes are not \\nrelevant, i.e. they cannot violate the requirements. In this case, these failure modes can be classified as \\nsafe: They contribute to the hardware safety metrics increasing the failure rate of safe faults.\\nEXAMPLE 2 \\nAn output driver can have an output slope control to limit the rise and fall times of the output \\nvalue for EMI purposes. If the slew rate is irrelevant for the violation of the safety goal, failures in this slope \\ncontrol would be safe faults.\\nEXAMPLE 3 \\nIf a voltage regulator is used to supply digital circuits only, failure modes affecting the stability \\nand the accuracy of the output voltage within the OV/UV thresholds can be classified as safe.\\n5.2.3.5 \\nExample of quantitative analysis for an analogue component\\nA detailed example of quantitative analysis for analogue components is described in Annex D.\\n5.2.3.6 \\nDependent failures analysis\\nAs noted in ISO 26262-9:2018, 7.4.2, NOTE, the analysis of dependent failures is performed on a \\nqualitative basis because no general and sufficiently reliable method exists for quantifying such \\nfailures.\\nThe steps reported in 4.7 are applicable also for analogue and mixed signal components. In the \\ndependent failures analysis, there are aspects that can be clearly considered when addressing analogue \\ncomponents, parts or subparts.\\nAnalogue circuits are by nature sensitive to noise and interference among different blocks or functions. \\nFor this reason, structures to guarantee sufficient independence by means of isolation and separation \\n(e.g. by implementing barriers and/or guard-rings or placing circuits at certain distances or separating \\nthe power supply distribution and even the ground layer) are implemented for functional reasons. \\nIn fact, substrate, power supply and global signals like bias, clock or reset are often considered as a \\nsource of interference and special care is taken to reduce such effect. This good design practice, usually \\nfollowed for functional reasons, provides benefits in terms of dependent failures avoidance.\\n \\n92 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nAnalogue circuits can be very sensitive to process variation resulting in mismatches in the device \\nbehaviour. To ensure the \\xe2\\x80\\x9csame\\xe2\\x80\\x9d transfer function of two blocks, as in the case of redundant parts, the \\nsymmetry of the design and physical layout is a key factor. In such cases, special attention is taken to \\nensure exactly the same layout of the two blocks including orientation, symmetrical placing, routing \\netc.; therefore diversity is not always a viable solution to improve the common cause failure avoidance \\nfor analogue circuits.\\nAs a consequence of these aspects, the dependent failures initiators are often addressed by techniques \\nensuring isolation or separation instead of with techniques aiming to differentiate their effects.\\nIn other cases, diversity can still be a valid technique to achieve the detection or avoidance of dependent \\nfailures. For instance, in a dual channel approach, using two diverse ADC architectures (e.g. successive \\napproximation ADC and sigma delta ADC) can reduce significantly the probability of common cause \\nfailures.\\n5.2.3.7\\t\\nVerification\\tof\\tthe\\tarchitectural\\tmetrics\\tcomputation\\nThis sub-clause is addressing a specific part of the safety analysis verification: the verification of the \\narchitectural hardware safety metrics and in particular the fraction of safe faults and the failure mode \\ncoverage.\\nPossible approaches include:\\n\\xe2\\x80\\x95 \\nexpert judgment founded on an engineering approach given that any data, either qualitative or \\nquantitative, is supported by rationale and relevant arguments, and is documented accordingly;\\nNOTE 1 \\nIn some cases, such arguments can be derived from the functional characterization of the hardware \\nelements responsible for the claimed parameters. The aim of the functional characterization is the systematic \\nfailure avoidance and not the hardware random failure but, in some cases, it can be used as evidence to prove the \\nlevel of coverage with respect to a specific failure mode: This is the case in which the aim of a safety mechanism \\nis to detect 100 % of one of more failure modes and this capability is guaranteed by design.\\nEXAMPLE 1     A voltage monitor as described in 5.2.4.2 is a typical safety mechanism used to detect \\novervoltage and under-voltage failure modes affecting the voltage regulator. If, during the hardware \\ndesign verification, the functional characterization of the voltage monitor shows that:\\n\\xe2\\x80\\x95     any event leading to a regulated voltage outside the expected range defined in the specifica-\\ntion for enough time to make the supplied hardware circuit malfunction is detected by the voltage \\nmonitor; and\\n\\xe2\\x80\\x95     any event leading to a variation of the regulated voltage inside the range defined in the speci-\\nfication for any time does not affect the correct behaviour of the hardware circuit supplied by the \\nregulator;\\nthen, such characterizations can be used as arguments to claim a detection equal to 100 % of the \\nmentioned failure modes.\\n\\xe2\\x80\\x95 \\nas mentioned in 4.8, fault injection simulation during the development phase is a valid method to verify \\ncompleteness and correctness of safety mechanism implementation with respect to hardware safety \\nrequirements. Fault injection using design models can be successfully used to assist the verification. This \\nmethod can be applied to analogue and mixed signal components; and\\nNOTE 2 \\nThe fault injection campaign can be limited to a subset of faults or failures that are judged to be \\ncritical in a specific case. The most critical failure modes are identified after considering their distribution, their \\nclaimed amount of safe faults, their claimed level of detection and the safety mechanisms or safety requirements \\nresponsible for those levels.\\n\\xe2\\x80\\x95 \\na combination of the above methods, i.e. fault injection which supports expert judgment by \\nproviding arguments and evidence for the cases judged more critical and /or addressable by fault \\ninjection method alone.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n93\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.2.4 \\nExamples of safety mechanisms\\nThe following tables give a non-exhaustive list of examples of commonly used analogue safety \\nmechanisms that complements the information contained in ISO 26262-5:2018, Annex D.\\nSome analogue safety mechanisms have a digital output signal which is used to control the reaction to \\na failure and bring the component to a safe state. In many cases, this information is stored so that it can \\nbe communicated through a digital interface. Other analogue safety mechanisms control or suppress a \\nfault from resulting in the violation of a safety requirement and do not interface with the digital domain.\\nTo comply with ISO 26262-5:2018, 8.4.8, the safety mechanisms described in the following tables can \\nrequire additional measures to detect faults affecting them that, as dual-point faults, can lead to the \\nviolation of the safety goal.\\nThe examples given in Table 37 to Table 40 are not exhaustive and other techniques can be used.\\nNOTE 1 \\nIt is not possible to give a general guidance on the DC because it strongly depends on the specific \\ntechnology, type of circuit, use case etc.\\nNOTE 2 \\nEvidence is provided to support the claimed diagnostic coverage.\\nTable 37 \\xe2\\x80\\x94 Power supply\\nSafety mechanism/ \\nmeasure\\nSee overview of \\ntechniques\\nNotes\\nOver and under voltage \\nmonitoring\\n5.2.4.2\\nTypically an analogue circuit with an output latched in a digital core.\\nVoltage clamp (limiter)\\n5.2.4.3\\nTypically used to suppress voltage transients or spikes.\\nOver-current monitoring\\n5.2.4.4\\nTypically an analogue circuit with an output latched in digital core.\\nCurrent limiting\\n5.2.4.5\\nTypically an analogue circuit with feedback to an analogue control \\nloop (e.g. to disable regulator main pass element).\\nPower on reset\\n5.2.4.6\\nFunctional block which keeps the circuit in a known initialized \\nstate until power supply rails and/or the clock signal are stable.\\nTable 38 \\xe2\\x80\\x94 Analogue I/O\\nSafety mechanism/ \\nmeasure\\nSee overview of \\ntechniques\\nNotes\\nResistive pull up/down\\n5.2.4.1\\nTypically used on input signals to avoid floating conditions due to \\npin failure or external pin interconnect failure.\\nFilter\\n5.2.4.8\\nAnalogue or digital circuit, typically used to suppress high frequency \\nsignal variation, like an output from analogue over & under voltage \\nmonitoring circuit.\\n \\n94 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 39 \\xe2\\x80\\x94 Miscellaneous analogue components\\nSafety mechanism/ \\nmeasure\\nSee overview of \\ntechniques\\nNotes\\nAnalogue watchdog\\n5.2.4.7\\nTypically a monostable circuit used to monitor proper operation \\nof an oscillator.\\nThermal monitor\\n5.2.4.9\\nTypically an analogue circuit with an output latched in digital \\ncore, or feedback to an analogue circuit control loop (e.g. to disable \\naffected circuit).\\nADC monitoring\\n5.2.4.11\\nAn analogue circuit typically controlled and evaluated by a digital \\ncircuit.\\nAnalogue BIST\\n5.2.4.10\\nTypically an analogue circuit controlled by a digital circuit that \\nverifies correct functionality of analogue safety mechanisms like \\nunder/over voltage monitoring, current limit protection and ther-\\nmal protection circuits.\\nTable 40 \\xe2\\x80\\x94 Analogue to Digital converter\\nSafety mechanism/ \\nmeasure\\nSee overview of \\ntechniques\\nNotes\\nADC attenuation detec-\\ntion\\n5.2.4.12\\nTypically an analogue circuit controlled by a digital circuit that \\nvalidates the ADC conversion path by measuring a known and \\nstable signal value.\\nStuck on ADC channel \\ndetection\\n5.2.4.13\\nTypically an analogue circuit controlled by a digital circuit that \\nvalidates the ADC conversion path by measuring a known and \\nstable signal value.\\n5.2.4.1 \\nResistive pull up/down\\nAim: To define a default voltage for a circuit node.\\nDescription: A resistor is connected from a circuit node to either a supply voltage or ground to define a \\ndefault voltage in the event that the driving signal becomes disconnected/high impedance. Commonly \\nused on I/O pins.\\nEXAMPLE \\nAn un-driven or disconnected device/module input pin would be at an unknown voltage level. \\nA pull-up resistor to the I/O supply voltage (or module supply voltage) or pull-down resistor to ground is used \\nto keep the input at a known voltage level. The circuit itself could be a passive resistor or an active circuit like a \\ncurrent mirror.\\n5.2.4.2 \\nOver & under voltage monitoring\\nAim: To detect, as early as possible, when a regulated voltage is outside the specified range.\\nDescription: The regulated voltage is compared via a differential input pair to a low and/or a high \\nanalogue reference voltage representing the limits of the specified operating range. The monitor output \\nwill change state when the regulated voltage is outside of the defined voltage window indicating a fault.\\nEXAMPLE \\nA window comparator is used to monitor the output of a Low Drop Out (LDO) regulator with \\nreference voltages set to the minimum and maximum specified voltage levels in regulation.\\n5.2.4.3 \\nVoltage clamp (limiter)\\nAim: To prevent the voltage of a circuit node from exceeding the maximum voltage that can be safely \\nsupported.\\nDescription: A voltage clamp limits the positive and/or negative voltage of a circuit node to an \\nacceptable level determined by system and/or device process capability. Voltage clamps can be biased \\nor unbiased. Unbiased clamps typically use Zener diodes to define the reference voltage while biased \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n95\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nclamps use a voltage source in combination with specialized diodes (Zener, Schottky) to define the \\nacceptable voltage level. Voltage clamps are typically used to protect against transient events.\\nEXAMPLE \\nAn ESD protection circuit is a specialized voltage clamp typically implemented on I/O pins. It is \\ndesigned to shunt the energy of a high voltage electrostatic discharge on the I/O pins away from the internal \\ncircuitry to ensure that internal circuitry is not exposed to excessive voltage levels during the ESD event.\\n5.2.4.4 \\nOver-current monitoring\\nAim: To detect, as early as possible, when the output current exceeds a certain value.\\nDescription: The implementation of over-current monitoring can vary. A typical approach for a voltage \\nregulator circuit with an MOS output device is to add a sense FET in parallel with a regulator main FET. \\nThe sense FET current, which is proportional to the main FET current, flows across a sense resistor. \\nThe voltage drop across the sense resistor is amplified and monitored by a voltage monitor.\\nNOTE \\nThe output of an over-current monitor is a digital output which is subsequently used as feedback to \\nan analogue circuit control loop, and/or latched in a digital core which interfaces to the control and/or status \\nmonitoring circuits.\\n5.2.4.5 \\nCurrent limiter\\nAim: To limit output current to a maximum level in order to maintain a safe operating area of the output \\ndevice and prevent electrical overstress.\\nDescription: A closed loop system using negative feedback from a current monitor to reduce the drive \\nto the output device thereby limiting the output current.\\n5.2.4.6 \\nPower on reset\\nAim: To hold the outputs of a system in a known state (typically off) until internal nodes have stabilized \\nupon power up or power reset conditions.\\nDescription: Typically, a bandgap-derived voltage reference is compared to an attenuated supply \\nvoltage in order to detect the minimum specified supply voltage which will ensure correct operation. \\nHysteresis is typically required to prevent oscillation as the attenuated supply voltage exceeds the \\nreference voltage.\\nEXAMPLE \\nAn under-voltage monitor is a mechanism used to detect and drive power-on reset.\\n5.2.4.7 \\nAnalogue watchdog\\nAim: To monitor proper operation of an oscillator.\\nDescription: Typically implemented with a monostable circuit (one shot) which is reset on each cycle \\nof the oscillator. If an oscillator transition does not occur within a specified time period defined by the \\nmonostable circuit, a fault signal is produced.\\n5.2.4.8 \\nFilter\\nAim: To avoid transients potentially causing failures:\\nDescription: A filter can be used in multiple ways as a safety mechanism.\\nEXAMPLE 1 \\nA bypass capacitor can be used to suppress voltage transients. An RC time constant is used to \\nevaluate whether the duration of a fault which has the potential to violate the safety goal is within the maximum \\nfault handling time interval.\\nEXAMPLE 2 \\nA digital de-glitch circuit can be used to filter level shifted analogue voltage comparator outputs.\\n \\n96 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.2.4.9 \\nThermal monitor\\nAim: To detect when circuit temperature exceeds a specified limit.\\nDescription: Typically, a PTAT (proportional to absolute temperature) voltage is compared to a \\ntemperature independent reference voltage usually derived from a bandgap. The comparator will \\ngenerate a fault signal when the PTAT voltage exceeds the reference voltage.\\n5.2.4.10 Analogue Built-in Self-Test (Analogue BIST)\\nAim: Typically, to verify correct operation of diagnostic circuits and increase the detection of latent faults.\\nDescription: The implementation of analogue BIST varies according to the diagnostic function to be \\nverified. Analogue BIST typically involves exercising diagnostic circuits into and out of fault scenarios \\nby injecting currents or voltages into the diagnostic circuit to ensure the diagnostic circuit can switch \\nto both faulted and non-faulted states.\\n5.2.4.11 ADC monitoring\\nAim: To measure an analogue signal by means of digital conversion with an output processed/evaluated \\nin the digital core as an independent/ redundant analogue signal monitor.\\nDescription: A critical analogue signal for which accuracy is relevant is converted in a digital code by \\nmeans of an independent ADC (e.g. located outside the component or, at least biased by an independent \\nsource). The digital code is then processed by the CPU or an equivalent digital machine in order \\nto determine if the original analogue signal has the required performance in terms of accuracy and \\nstatic and dynamic behaviour. The frequency of the sampling and the resolution of the ADC and digital \\nprocessing define which failure modes can be detected and to what accuracy.\\n5.2.4.12 ADC attenuation detection\\nAim: To detect incorrect conversion of an analogue signal into its digital interpretation.\\nDescription: Upon each background conversion loop, the element performs the conversion of the internal \\nVmid voltage both with and without the selectable attenuation switched in. The conversion results are \\nstored respectively in separate SPI fields. A mathematical operation of dividing the attenuated result by \\nthe non-attenuated result verifies that the attenuation factor is within specified limits.\\n5.2.4.13 Stuck on ADC channel detection\\nAim: To detect stuck on faults affecting the input signal to be converted by the ADC\\nDescription: The element provides a multiplexer channel with series resistor RPOST, which is selected \\nonly when converting the test voltage channels (Vhigh, Vlow, Vmid), and RPOST is otherwise bypassed. \\nThe value of RPOST is chosen such that a stuck-on channel within the post-buffer mux pulls one or more \\nof the test voltage channels out of the expected voltage range.\\nEXAMPLE \\nEach software loop, the MCU reads the ADC conversion results for the Vhigh, Vlow and Vmid \\ncomponent ADC channels over SPI, and compares them against fixed detection thresholds.\\n5.2.5 \\nAvoidance of systematic faults during the development phase\\nAnalogue and mixed signal components are developed based on a standardised development process.\\nThe general requirements and recommendations related to hardware architecture and detailed design \\nare defined in ISO 26262-5:2018, Clause 7.\\nThe guidance in 5.1.9 can be applied to the analogue and mixed signal components if:\\n\\xe2\\x80\\x95 \\nTable 31 is replaced by Table 41; and\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n97\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b\" \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nthe usage of 3rd party validated macro blocks and to comply with each constraint and procedure \\ndefined by the macro core provider, if practicable, is restricted to hard cores only.\\nNOTE \\nWear and aging are considered during development with proper verification and validation \\nprocedures.\\nTable 41 \\xe2\\x80\\x94 Examples of measures to avoid systematic failures in analogue and mixed signal \\ncomponents\\nISO 26262-5:2018 \\nClause\\nDesign phase\\nTechnique/ \\nMeasure\\nAim\\n6.5.1 hardware \\nsafety require-\\nments specifica-\\ntion\\nSpecification\\nUsing an appropriate \\nrequirement manage-\\nment tool\\nTo streamline the identification and tracking \\nof the safety requirements for the hardware \\nelement.\\n6.5.2 hardware/\\nsoftware interface \\nspecification\\n \\nUsing a model to describe \\nhardware/software inter-\\nface for critical elements\\nTo reduce the risk of misinterpretation and \\nto ensure consistency between hardware \\nand software design.\\n7.5.1 hardware de-\\nsign specification\\n \\nUsing an appropriate tool \\nto allocate requirements \\nto hardware design\\nTo streamline the identification and tracking \\nof the design specification for the hardware \\nelement.\\n7.4.1.6 Properties \\nof modular hard-\\nware design\\nDesign\\nUse of modular, hierarchi-\\ncal, and simple design\\nThe description of the circuit's functional-\\nity is structured in such a fashion that it is \\neasily to understand. i.e. circuit function can \\nbe intuitively understood by its description \\nwithout simulation efforts\\n7.4.1.6 Properties \\nof modular hard-\\nware design\\n \\nhardware design using \\nschematics\\nSchematic entry is the method typically used \\nfor analogue circuitry.\\n7.4.4 Verification of \\nhardware design\\n \\nBehavioural model \\nsimulation for critical \\nelements\\nBehavioural models are simplified models \\nof the design. Behavioural modelling for \\nanalogue circuits allows for the evaluation of \\nfunctionality in an early design stage (e.g. to \\nprove the design concept) and a reduction in \\nsimulation time.\\n7.4.4 Verification of \\nhardware design\\n \\nTransistor level simula-\\ntion\\nSimulation on transistor level is the method \\nused to verify and validate dedicated critical \\nfunctionalities of analogue circuits where \\nsimulation time is feasible.\\n7.4.4 Verification of \\nhardware design\\n \\nSafe operating area (SOA) \\nchecks done by design \\nreview and/or tools\\nAn analogue circuit is composed of devices \\nwith different current/voltage capabilities. \\nSOA checking ensures that each device will \\nwork safely within its specific operational \\narea according to its technology.\\n7.4.4 Verification of \\nhardware design\\n \\nCorner simulations (i.e. \\ntechnology process and \\nenvironmental condi-\\ntions spread)\\nIn order to ensure block-level functionality, \\nsimulations are performed which take the \\nspread of process parameters and environ-\\nmental conditions into account.\\n7.4.4 Verification of \\nhardware design\\n \\nMonte Carlo simulations \\nof most sensitive blocks\\nIn order to ensure block-level functionality of \\ncritical circuits, the effect of on-chip process \\nspread is simulated using a statistical ap-\\nproach (i.e. Monte Carlo simulations)\\n7.4.4 Verification of \\nhardware design\\n \\nMixed mode simulations \\nfor critical elements\\nTo ensure the correctness of critical elements, \\ne.g. analogue to digital interfaces, analogue/\\ndigital closed loop control, digital circuits are \\nsimulated in the analogue domain.\\n \\n98 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n\"\n",
      "b' \\nISO 26262-11:2018(E)\\nISO 26262-5:2018 \\nClause\\nDesign phase\\nTechnique/ \\nMeasure\\nAim\\n7.4.4 Verification of \\nhardware design\\n \\nRequirement Driven Ver-\\nification\\nAll functional and safety-related require-\\nments are verified. To be shown via traceabili-\\nty between specification and verification plan\\n7.4.4 Verification of \\nhardware design\\n \\nDesign for testability\\nSpecific hardware structures (e.g. test \\nmodes, multiplexers) are included into the \\ndesign and layout in order to test otherwise \\ninaccessible circuit nodes and improve the \\ntest coverage\\n7.4.2.4 Robust \\ndesign principles\\n \\nApplication of schematic \\ndesign guidelines\\nManual checks\\n7.4.4 Verification of \\nhardware design\\n \\nApplication of schematic \\ncheckers\\nTo perform automatic checks for example on \\ninterconnections or on the selection of the \\nproper devices as a function of polarities. For \\nexample SOA (Safe Operating Area) checker\\n7.4.4 Verification of \\nhardware design\\n \\nDocumentation of simula-\\ntion results\\nDocumentation of each data needed for a \\nsuccessful simulation in order to verify the \\nspecified circuit function\\n7.4.4 Verification of \\nhardware design\\n \\nSchematic design inspec-\\ntion or walk-through\\nDesign review usually includes inspection or \\nwalk-through.\\n7.4.4 Verification of \\nhardware design\\n \\nApplication and valida-\\ntion of hard-core (reused \\nschematic design and/or \\nlayout)\\nUsage of an already proven schematic or \\nlayout.\\n7.4.4 Verification of \\nhardware design\\n \\nVerification for behav-\\nioural models (if used) \\nagainst the transistor \\nlevel description\\nCross check between behavioural model \\nand the transistor level schematic design by \\nsimulation\\n7.4.4 Verification of \\nhardware design\\n \\nSimulation of netlist \\nwith parasitics extracted \\nfrom layout for critical \\nelements\\nBack-annotated netlist simulated by ana-\\nlogue simulator\\n7.4.4 Verification of \\nhardware design\\nDesign\\nVerification of netlist \\nwith parasitics extracted \\nfrom layout against the \\nschematic netlist for criti-\\ncal elements\\nBack-annotated netlist is checked against the \\nschematic description in terms of simulation \\nresults in order to consider parasitic layout \\neffects.\\n7.4.4 Verification of \\nhardware design\\n \\nLayout inspection or \\nwalk-through (avoid \\ncross talk between \\nnoisy and sensitive nets; \\navoid signal path with \\nminimum width; use of \\nmultiple contacts/vias to \\nconnect layers)\\nThe layout of analogue circuits is mainly \\ndone manually (automation is very limited \\nwith respect to the analogue blocks) and so \\nlayout inspection is crucial.\\nThe design review usually includes layout \\ninspection or walk-through.\\n7.4.4 Verification of \\nhardware design\\n \\nDesign rule check (DRC)\\nThe layout of analogue circuits is mainly \\ndone manually (automation is very limited \\nwith respect to the analogue blocks) and so \\ndesign rule checking is more crucial than in \\nthe digital domain.\\n7.4.4 Verification of \\nhardware design\\n \\nLayout versus schematic \\ncheck (LVS)\\nThe layout of analogue circuits is typically \\ndone manually (automation is very limited \\ncompared to the analogue blocks) and so \\nchecking layout versus schematic is more \\ncrucial than in the digital domain.\\n \\nTable 41 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n99\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nISO 26262-5:2018 \\nClause\\nDesign phase\\nTechnique/ \\nMeasure\\nAim\\n7.4.4 Verification of \\nhardware design\\nHardware de-\\nsign\\tverification\\nDevelopment by hard-\\nware prototyping\\nVerification of implemented functions by \\nprototype (e.g. test chips, boards), can check \\nparticular points of the hardware design \\nwhere design review is not sufficient.\\n6.5.3 hardware \\nsafety require-\\nment verification \\nreport\\nVerification\\nhardware safety require-\\nment verification report\\nProvide evidence of consistency with \\nhardware specification, completeness and \\ncorrectness\\n10.5.1 hardware \\nintegration and \\nverification activ-\\nities\\nHardware \\nintegration ver-\\nification\\nVerification of the \\ncompleteness and cor-\\nrectness of the design \\nimplementation on the \\ncomponent level\\nPerform component tests and reports\\n7.4.5 Production, \\noperation, service \\nand decommis-\\nsioning\\n9.4.1.2, 9.4.1.3 Ded-\\nicated measures\\nSafety-related \\nspecial charac-\\nteristics during \\nchip production\\nDetermination of the \\nachievable test coverage \\nof production test\\nEvaluation of the test coverage during pro-\\nduction test with respect to the safety-relat-\\ned aspects of the component.\\n7.4.5 Production, \\noperation, service \\nand decommis-\\nsioning\\n9.4.1.2, 9.4.1.3 Ded-\\nicated measures\\nDetermination of meas-\\nures to detect and cull \\nearly failures\\nAssurance of the robustness of the manu-\\nfactured component. In most, but not every \\nprocess, gate oxide integrity (GOI) is the \\nkey early life failure mechanism. There are \\nmultiple methods of screening early life GOI \\nfailures including high temp/high voltage op-\\neration (Burn-In), high current operation and \\nvoltage stress however these methods could \\nhave no benefit if GOI is not the primary con-\\ntributor to early life failures in a process.\\n7.4.5 Production, \\noperation, service \\nand decommis-\\nsioning\\n10 Hardware \\nintegration and \\nverification\\nEvaluation of \\nhardware ele-\\nment\\nDefinition and execution \\nof qualification tests like \\nBrown-out test , High \\nTemperature Operating \\nLifetime (HTOL) test and \\nfunctional test-cases,\\nSpecification of require-\\nments related to produc-\\ntion, operation, service \\nand decommission\\nHardware integration \\nand verification report\\nFor an analogue component with integrated \\nbrown-out detection, the component func-\\ntionality is tested to verify that the outputs of \\nthe analogue circuit are set to a defined state \\n(for example by stopping the operation of the \\nanalogue circuits in the reset state) or that \\nthe brown-out condition is signalled in an-\\nother way (for example by raising a safe-state \\nsignal) when any of the supply voltages moni-\\ntored by the brown-out detection reach a low \\nboundary as defined for correct operation.\\nFor an analogue component without integrat-\\ned brown-out detection, the analogue func-\\ntionality is tested to verify if the analogue \\ncircuit sets its outputs to a defined state (for \\nexample by stopping the operation of the \\nanalogue circuit in the reset state) when the \\nsupply voltages drop from nominal value to \\nzero. Otherwise an assumption of use is de-\\nfined and an external measure is considered.\\n5.2.6 \\nExample of safety documentation for an analogue/mixed-signal component\\nAnalogue and mixed-signal components are predominantly developed within a distributed development \\ndue to the specific nature of their functionality.\\n \\nTable 41 (continued)\\n100 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nGuidelines reported in 5.1.11 for digital components can be used as a reference for the safety work \\nproducts to be exchanged, however, an adaptation to the different development approach can be \\nnecessary.\\n\\xe2\\x80\\x95 \\nthe DIA between the component manufacturer and the end user specifies which documents are to \\nbe made available from each party as well as the level of work-share between the parties; and\\n\\xe2\\x80\\x95 \\nthe safety requirement specification defines the expected functionality of the component. \\nIt is critical that such specifications are carefully compiled by the end user, according to \\nISO 26262-8:2018, Clause 6, to ensure that correct functionality is understood by each supplier \\nin the distributed development. A description about the usage of the elements of the component \\nas well as identification of predefined on-chip/off-chip safety mechanisms is important to allow \\na proper safety analysis at a system or element level (e.g. to allow fault classification into safe, \\npotential to violate a safety goal, etc., for each safety goal considered).\\nNOTE 1 \\nIf the component is developed out of context, the requirements derived from the technical safety \\nconcept are replaced by assumptions of use.\\nDocumentation describing the capabilities of analogue and mixed signal components are listed below:\\n\\xe2\\x80\\x95 \\nthe results of the checks against the applicable requirements of ISO 26262 series of standards, \\nincluding confirmation measures reports, if applicable;\\n\\xe2\\x80\\x95 \\nsafety analysis results as per agreement;\\nNOTE 2 \\nThese can be raw failures of the component, their distribution and diagnostic coverage offered \\nfrom the specified safety mechanisms or a full FMEA for different safety requirements-\\n\\xe2\\x80\\x95 \\ninformation regarding the calculation of the failure rate (e.g. number of transistors); and\\n\\xe2\\x80\\x95 \\na description of any assumptions of use of the component with respect to its intended usage.\\nNOTE 3 \\nThis can be consolidated in a \\xe2\\x80\\x9cSafety Manual\\xe2\\x80\\x9d or \\xe2\\x80\\x9cSafety Application Note\\xe2\\x80\\x9d of the analogue or \\nmixed signal component.\\n5.3 Programmable logic devices\\n5.3.1 \\nAbout programmable logic devices\\n5.3.1.1 \\nGeneral\\nAs shown in Figure 25, PLDs can be seen as a combination of configurable I/O, non-fixed functions \\n(composed of logic blocks and user memory with a related configuration technology to configure them), \\nsignal routing capabilities connecting those logic blocks and fixed logic functions.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n101\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 25 \\xe2\\x80\\x94 A generic block diagram of a PLD\\nThe non-fixed logic functions can include, but are not limited to, simple logic gates, multiplexers, \\ninverters, flip-flops and memory to more complex functions such as digital signal processing \\nfunctionality. Signal routing capabilities can range from simple point-to-point solutions, to complex \\nbus interconnects with flexible routing possibilities and clocking options. PLDs can differ in their \\nimplementation of user memory. Some devices provide limited memory capabilities, whilst others \\nprovide local or global memory structures that can be used for a wide variety of applications. The \\nmore complex devices can also implement fixed functions such as CPUs, memory controllers, security \\nmodules, and others, thus freeing up design resources for user configurability. Clock, power and reset \\ncircuitries are fixed functions. It is up to the PLD design if single or multiple instances are implemented.\\nA common feature of PLDs is that users can configure them with the functionality adapted to the \\nspecific application needs. The design or configuration of the devices can be done with a variety of \\ntools, ranging from the very simple to entire development suites supporting complex features such as \\ntiming analysis and optimization of the design. Once the user design is completed it can be programmed \\ninto the device. Different technologies support either one time programmability or the reprogramming \\nof the device multiple times. These methods can be further distinguished by providing volatile or \\nnon-volatile capabilities. This is represented in the block diagram by the block labelled \\xe2\\x80\\x9cconfiguration \\ntechnology\\xe2\\x80\\x9d.\\nNOTE \\nThe safety-related capabilities of non-volatile technologies such as Flash (reprogrammable) or \\nAntifuse (programmable) can differ from those of volatile technologies such as SRAM.\\n5.3.1.2 \\nAbout PLD types\\nTable 42 provides a non-exhaustive list of commonly used PLD types.\\n \\n102 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 42 \\xe2\\x80\\x94 Commonly used PLD types\\nType\\nDescription\\nProgrammable Array Logic (PAL)\\nOne-time programmable devices implementing sum-of-products \\nlogic for each of its outputs.\\nGate Array Logic (GAL)\\nSimilar functionality as PALs with the feature of being program-\\nmable many times.\\nComplex Programmable Logic Device \\n(CPLD)\\nNon-volatile devices with similar functionality as PALs with a much \\nhigher integration rate and additional complex feedback paths.\\nField Programmable Gate Array (FPGA)\\nMostly volatile implementation of very sophisticated logic, routing \\nand memory functions.\\n5.3.1.3 \\nFunctional safety lifecycle tailoring for PLD\\n5.3.1.3.1 \\nGeneral\\nFigure 26 describes, using the same approach of ISO 26262-10,[61] how it is possible to tailor the \\nfunctional safety lifecycle to PLDs.\\nFigure 26 \\xe2\\x80\\x94 SEooC PLD hardware development\\nNOTE 1 \\nThe references shown in Figure 26 are related to the ISO 26262 series of standards.\\nNOTE 2 \\nIn the context of this document, PLD manufacturer refers to an organisation that develops the PLD \\nand has the responsibility for the manufacturing of the PLD. PLD user refers to an organisation that develops a \\nprogram for PLD or applies it in the application.\\nNOTE 3 \\nProviders of IP blocks for PLD are considered in 4.5 of this document.\\nNOTE 4 \\nAlthough each clause of the ISO 26262 series of standards is not shown in Figure 26, this does not \\nimply that they are not applicable.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n103\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nThe following clauses give examples with respect to some specific part of the ISO 26262 series of \\nstandards for either PLD manufacturers or PLD users.\\n5.3.1.3.2 \\nISO 26262-2 (management of functional safety)\\nIn general, ISO 26262-2 adapted to the appropriate level is applicable for the PLD manufacturer and the \\nPLD user.\\nEXAMPLE 1 \\nISO 26262-2:2018, 6.4.2.1 requires that a project manager is appointed at the initiation of the item \\ndevelopment. For a PLD manufacturer it means that a project manager is appointed at the initiation of the PLD \\ndevelopment.\\nEXAMPLE 2 \\nAccording to ISO 26262-2:2018, 6.4.6.5 the safety plan includes item level planning such as the \\nplanning of the hazard analysis and risk assessment as given in ISO 26262-3 [64], Clause 6. Since the hazard analysis \\nand risk assessment is done on item level only this requirement is not applicable for a safety plan on PLD level.\\nEXAMPLE 3 \\nISO 26262-2:2018, 6.4.11 requires a functional safety audit to be carried out for the item. Since \\nit is not possible for the PLD manufacturer to carry out a safety audit on item level, it is handled on PLD level \\ninstead.\\nEXAMPLE 4 \\nISO 26262-2:2018, 7.4.2.1 requires the organization to appoint persons with the responsibility and \\nthe corresponding authority, as given in ISO 26262-2:2018, 5.4.2.7, to maintain the functional safety of the item \\nafter its release for production. For a PLD manufacturer this means that a person is appointed for maintaining \\nthe functional safety of the PLD after its release for production, instead of being responsible for maintaining the \\nfunctional safety of the whole item.\\n5.3.1.3.3 \\nISO 26262-3 (concept phase)\\nWith respect to ISO 26262-3, the PLD manufacturer usually does not have any responsibility during the \\nconcept phase, unless the PLD manufacturer also assumes the role of item integrator. If the PLD user is \\nresponsible on item level, this part is applicable.\\n5.3.1.3.4 \\nISO 26262-4 (product development at the system level)\\nA PLD can be developed as an SEooC. For an SEooC development, ISO 26262-4:2018, Clause 6 and \\nISO 26262-4:2018, Clause 7 are partially or fully in scope. Guidelines for SEooC development can be \\nfound in ISO 26262-10 [61].\\nEXAMPLE \\nDedicated hardware safety measures can be implemented on the PLD by the PLD manufacturer \\nto support the technical safety concept. Other measures can depend on the implemented user circuitry and can \\nrequire specific measures (e.g. redundancy in logic, external watchdog) and are the responsibility of the user. \\nThe assumptions made by the PLD manufacturer on the system level measures are documented and verified by \\nthe PLD user.\\nIf the PLD user is also the item integrator, ISO 26262-4 is fully in scope.\\n5.3.1.3.5 \\nISO 26262-5 (product development at the hardware level)\\nAll the ISO 26262-5 clauses, including ISO 26262-5:2018, Clause 8 and ISO 26262-5:2018, Clause 9, are \\napplicable to PLD manufacturers and PLD users according to their level of contribution to the overall \\nsafety concept.\\nEXAMPLE \\nIf the PLD does not include any hardware safety mechanisms, the main role of PLD manufacturer \\nis to provide base failure rate, failure modes, and failure modes distribution using, for example, the methods \\ndescribed in 4.6 of this document. A reference or exemplary computation of hardware architectural metrics can \\nbe provided but the PLD user computes the metrics for the specific design to be implemented in the PLD.\\nWith respect to ISO 26262-5:2018, Clause 8 and ISO 26262-5:2018, Clause 9, the responsibility of PLD \\nmanufacturers is generally related to providing the information, methods and/or tools needed to enable \\nPLD users to compute and verify the metrics, including:\\n\\xe2\\x80\\x95 \\nthe distribution of failure modes; and\\n \\n104 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nthe diagnostic coverage values for the safety mechanisms that are embedded in the PLD (see 5.3).\\nWith respect to ISO 26262-5:2018, Clause 10, for semiconductor components it is assumed that it is not \\nrelated only to integration tests but it is applicable as well to PLD manufacturers and PLD users testing \\nactivities according to their level of contribution to the overall safety concept. Further information on \\ndiagnostic coverage is provided in 5.3.4.\\n5.3.1.3.6 \\nISO 26262-6 (product development at the software level)\\nBased on ISO 26262-4:2018, 6.4.6.5, requirements of ISO 26262-5 and ISO 26262-6 can be combined for \\nprogrammable logic like PLDs.\\nIn the case of a high-level synthesis flow, like developing in OpenCL, C-to-HDL flows, or a model based \\napproach, interactions with the requirements of ISO 26262-6 are relevant for the development of the \\nhigh level language code. ISO 26262-5 is relevant for the subsequent steps used for traditional PLD \\ndevelopment.\\nIf the development flow for PLD users and PLD manufacturers is based on HDL languages, this is similar to \\nthe one used to develop microcontrollers, so ISO 26262-5 applies. ISO 26262-6 is not relevant in this case.\\nNOTE \\nSpecific techniques and measures for user PLD circuit development are discussed in 5.3.5.3. For \\nmany methods there are similarities with respect to what is specified in ISO 26262-6, e.g. observation of coding \\nguidelines.\\n5.3.1.3.7 \\nISO 26262-7 (production and operation)\\nIn general ISO 26262-7 adapted to the appropriate level is applicable for the PLD manufacturer. This \\nalso applies to the PLD user when involved in the production of a hardware element of the item or of the \\nitem itself.\\nEXAMPLE 1 \\nIn ISO 26262-7:2018, 5.4.1.1 the requirement is to plan the production process by evaluating the \\nitem. In the context of the PLD manufacturer the planning is done by evaluating the PLD instead of the item.\\nEXAMPLE 2 \\nISO 26262-7:2018, 5.4.1.4 requires the identification of reasonably foreseeable process failures \\nand their effect on functional safety and to implement appropriate measure to address these issues. It is \\napplicable to a PLD production without modification.\\nEXAMPLE 3 \\nISO 26262-7:2018, 5.4.3.5 requirements for decommissioning instructions are typically not \\napplicable to PLDs\\nEXAMPLE 4 \\nTo comply with ISO 26262-7:2018, 7.4.1.1 the PLD manufacturer implements a field monitoring \\nprocess for the PLD.\\n5.3.2 \\nFailure modes of PLD\\nIn line with the lifecycle shown in 5.3.1.3, Table 43 summarises the failure modes that can be of concern \\nfor PLD users. Failure modes for PLD can be derived by applying key words as mentioned in 4.3.2.\\nNOTE \\nThe listings do not claim exhaustiveness and can be adjusted based on additional known failure modes.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n105\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 43 \\xe2\\x80\\x94 Example of failure mode for PLD\\nElement\\n(see Figure 25)\\nDescription\\nAnalysed failure modes\\nFixed Function IPa\\n \\nSee Table 30.\\nPLD Digital I/O\\n \\nSee ISO 26262-5:2018, Table D.1, element \\xe2\\x80\\x9cDigital I/O\\xe2\\x80\\x9d and Table 30.\\nLogic Blockd\\n \\nPermanent corruption of the function implemented by the logic block.\\nTransient corruption of the function implemented by the logic block.b\\nConfiguration \\nTechnology\\nSee 5.3.1.1\\nUnintentional permanent change of the configuration of the logic block.\\nUnintentional transient change of the configuration of one logic block.c\\nPLD Analogue I/O\\n \\nSee ISO 26262-5:2018, Table D.1, element \\xe2\\x80\\x9cAnalogue I/O\\xe2\\x80\\x9d and Table 36.\\nUser Memory\\n \\nSee 5.1.3.\\nSignal Routing \\ncapabilitye\\n \\nPermanent corruption of the function implemented by a group of logic \\nblocks, including time delay of the function.\\nTransient corruption of the function implemented by a group of logic \\nblocks.\\na \\nAs described in 5.3.1, the fixed function IPs are a combination of elements similar to those that can be found in \\nmicrocontrollers. They are typically implemented in a separated area with respect to the non-fixed functions and therefore \\nthey can be considered in each aspect similar to the elements discussed in ISO 26262-5:2018, Table D.1 and 5.1.2 and 5.1.3 \\nfor digital components.\\nb \\nThe relevance of this failure mode depends on the type of PLD technology and type of Logic Block, see 5.3.1.2.\\nc \\nThe relevance of this failure mode depends on the type of PLD technology, see 5.3.1.2.\\nd \\nThe I/O configuration logic can be inside the fixed function IP or in the I/O itself.\\ne \\nWires and routing of configuration technology are considered in \"Signal Routing Capability\"\\n5.3.3 \\nNotes on safety analyses for PLDs\\n5.3.3.1 \\nQuantitative analysis for a PLD\\nA similar approach as discussed in 5.1 can also be used for PLDs. A quantitative analysis of the PLD \\nincluding the user design can be performed on different abstraction levels depending on the information \\navailable to the PLD user.\\nInformation about the PLD usage and user design is refined during the development phase of the design \\nand the analysis is repeated based on the latest information. The quantitative analysis of the PLD design \\ncan be augmented by a dependent failure analysis as described in 5.3.3.2.\\nThe following two sub-clauses describe examples of PLD die failure rate calculations and examples of \\nthe distribution of the failure rate to the identified failure modes.\\nThe hardware architectural metrics can be determined in a similar way to the example given in Annex C \\nof this document. The level of detail required for the analysis depends on the targeted ASIL and the \\napplication.\\n5.3.3.1.1 \\nExample of PLD die failure rate calculation using the model in 4.6.2.1.1\\nThe failure rates can be estimated as described in 4.6.\\nFor estimating failure rate of PLD die, the following are considered:\\n\\xe2\\x80\\x95 \\nfailure rate related to Configuration technology. Depending on industry sources, treatment of the \\ntransistors related to the configuration technology is different, i.e. the configuration technology \\nis considered as a separate entry of the computation, or the configuration technology in the logic \\nblocks, user memory entries and other relevant elements.\\n \\n106 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nfailure rate of unused resources. There are two possibilities both of which are applicable. One \\napproach is that the unused resources are considered as not safety-related. Depending on the PLD \\nstructure, a dependent failure analysis can analyse the influence of the unused logic on the user \\ndesign. An alternative approach is to consider the unused logic as safety-related and to estimate the \\nrespective fraction of faults that will lead to a safe failure (Fsafe according ISO 26262-10 [61]). This \\nestimation can be done by means of a quantitative analysis supported by information provided by \\nthe PLD manufacturer.\\nNOTE 1 \\nIf failure rates provided by the PLD manufacturer are used, any de-rating factor applied to the \\nprovided data is made available.\\nNOTE 2 \\nThis sub-clause extends the example in 4.6.2.1.1.1. Since assumptions are similar, not every note is \\nrepeated. A PLD with the characteristics outlined in Table 44 is used for the example.\\nTable 44 \\xe2\\x80\\x94 PLD resource overview\\nElement\\nResources\\nAssumed IEC 62380 category\\nLogic blocks\\n1 000\\nCPLD (EPLD, MAX, FLEX, FPGA, etc.)\\nUser memory\\n16 kb\\nLow-consumption SRAM\\nFixed function IP\\n20 k gates\\nDigital circuits, microcontroller, DSP\\nConfiguration technology\\n10 kb\\nLow-consumption SRAM\\nNOTE   For the Logic blocks, the CPLD entry of Figure 10 has been used as example. For modern volatile FPGA devices, the \\nLCA (RAM based) entry can be preferable.\\nThe complete PLD failure rate can be computed as shown in Table 45. The failure rates in Table 45 can \\nbe used to calculate the failure rates for this specific user design. The assumptions made for the user \\ndesign are given in Table 46.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n107\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 45 \\xe2\\x80\\x94 Example of the computation of the failure rates for the PLD\\nElement\\n\\xce\\xbb1\\nN\\n\\xce\\xb1\\n\\xce\\xbb2\\nBase FIT\\nDe-rating for \\ntemp\\nEffective FIT\\nLogic blocks\\n2,0 \\xc3\\x97 10\\xe2\\x88\\x925\\n100 000\\n(100 transistors per \\nmacrocell)\\n10\\n34\\n34,0604\\n0,17\\n5,7903\\nUser memory\\n1,7 \\xc3\\x97 10\\xe2\\x88\\x927\\n98 304\\n(6 transistors/bit \\nfor a low-consump-\\ntion SRAM)\\n10\\n8,8\\n8,8005\\n0,17\\n1,4961\\nFixed function IP\\n3,4 \\xc3\\x97 10\\xe2\\x88\\x926\\n80 000\\n(4 transistors/ \\ngate)\\n10\\n1,7\\n1,7082\\n0,17\\n0,2904\\nConfiguration \\ntechnology \\n(based on SRAM)\\n1,7 \\xc3\\x97 10\\xe2\\x88\\x927\\n61 440\\n(6 transistors/ \\nbit for a low-con-\\nsumption SRAM)\\n10\\n8,8\\n8,8003\\n0,17\\n1,4961\\nSum\\n53,3694\\n9,0729\\nNOTE 1   It is assumed that the number of transistors per macrocell (100, as derived from Figure 10) does not include \\nthe transistors related to the configuration technology. For this reason the configuration technology is considered as a \\nseparate entry of the computation. An alternative approach could be to adapt the number of transistors and include the \\nconfiguration technology in the logic blocks, user memory entries and other relevant elements.\\nNOTE 2   This table can be used also to derive a unitary FIT by dividing the resulting effective FIT with the number of \\nelements.\\nEXAMPLE   The FIT/logic block can be computed as 5,7903/1 000 = 0,0057.\\nNOTE 3   As shown in 4.6, alternatives are possible for the temperature de-rating factor. Those alternatives are applicable \\nas well for PLDs.\\nTable 46 \\xe2\\x80\\x94 Example of user design resource usage and failure rate calculation\\nElement\\nResource usage\\nEffective FIT\\nLogic blocks\\n23 %\\n1,3318\\nUser memory\\n10 %\\n0,1496\\nFixed function IP\\n100 %\\n0,2904\\nConfiguration technology (based on SRAM)\\n15 %\\n0,2244\\nSum\\n1,9962\\nThe data can be further refined if more detail about the user design is available. For example a logic \\nblock has different configuration options and the user design can only use a certain configuration. This \\nallows to further de-rate the calculated failure rate.\\nNOTE 3 \\nA dependent failure analysis can be used to analyse the influence of the different configuration \\noptions on the user design.\\nNOTE 4 \\nThe derivation of the de-rating factor can be facilitated by appropriate design tools.\\n5.3.3.1.2 \\nExample of a transient failure rate calculation for PLDs\\nThe computation of the transient failure rate for PLDs can follow 4.6.\\nNOTE \\nIf the transient failure rate provided by the PLD manufacturer includes a de-rating factor (for example \\nbased on average PLD utilization factor or based on operational profile), this factor is explained to the PLD user.\\nTable 46 can be used to calculate the failure rates for this specific user design in the same way that \\nfailure rates for transient faults were calculated in the previous clause.\\n \\n108 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.3.3.1.3 \\nExample of distribution of PLD failure rate to failure modes\\nOnce the PLD failure rate has been estimated, it is distributed to the identified failure modes, i.e. the \\nfailure modes distribution is computed.\\nFor PLD manufacturers, the failure modes distribution can be computed as described in 5.1.\\nThe following are examples of possible approaches for identification of failure modes and respective \\ndetermination of the failure modes distribution for PLD users:\\na) Identification of the failure modes at the functional block level of the user PLD design; assumption \\nof an equal distribution of the PLD failure rate to the identified failure modes;\\nb) Identification of the failure modes at the functional block level of the user PLD design; estimation \\nof the distribution of the PLD failure rate to the identified failure modes based on expert judgment \\ntaking resource estimation (e.g. fixed function IP, number of logic blocks, user memory, etc.) into \\naccount, supported by documented evidences; and\\nc) \\nIdentification of the failure modes by means of a partitioning of the implemented user PLD design \\nin elementary subparts; estimation of the distribution of the PLD failure rate to the identified \\nfailure modes based on the implemented user PLD design facilitated by information provided by \\nthe PLD manufacturer taking detailed resource utilization into account. This could be supported \\nby appropriate design tools.\\nNOTE 1 \\nIn the context of PLD manufacturer, the elementary subpart can be taken as a set of flip-flops and \\nthe related fan-in gates. In the same way, in the context of PLD users, the elementary subpart can be taken as \\nthe group of logic cells, constructed of flip-flops in a logic block and the combinatorial logic represented by logic \\nblocks. The level of detail, i.e. the number of elementary subparts considered depends on the type of safety \\nmechanism used and the application.\\nNOTE 2 \\nThe level of accuracy of the resulting quantitative data varies depending on the approach used.\\nEXAMPLE 1 \\nIf information on the implemented user PLD design is available, then approach c) can provide the \\nhighest level of accuracy. If this information is not available and no argument can be given why one of the failure \\nmodes is more likely than the other, the approach a) can be used.\\nNOTE 3 \\nThe required level of accuracy of the failure mode distribution depends also on the type of safety \\nmechanism used and the application.\\nEXAMPLE 2 \\nIn the case of a user PLD design in lock-step, approach a) can be sufficient because a non-uniform \\ndistributed value for the failure mode distribution will not affect the claimed diagnostic coverage. For a user \\nPLD design relying on a software test library to periodically test the PLD hardware, if arguments exist that one \\nof the failure modes is more likely than the other approaches b) or c) are used depending on the required level of \\naccuracy.\\nNOTE 4 \\nA detailed failure mode definition like the one provided by approach c) can help to provide rationale \\nfor diagnostic coverage.\\nNOTE 5 \\nFor transient faults, the resource utilization can consider the number of flip flops included in the logic \\nblocks and the number of user memory bits of the user PLD design and number of configuration bits utilised by \\nthe user PLD design\\nTable 47 shows an example, based on Annex E, of the three approaches described above. It considers a \\nSPI module implemented in a PLD.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n109\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 47 \\xe2\\x80\\x94 Example of approaches for PLD failure modes distribution computation at PLD \\nuser level\\nFailure mode\\nSubparts involved\\na)\\nb)\\nSee NOTE 1\\nc)\\nSee NOTE 2\\nWrong or no clock\\nClock generation\\n25 %\\n10/110 = 9,09 %\\n10/90 = 11,11 %\\nWrong or no data \\nreception\\nPeripheral bus interface\\nInput shift register\\nData received register\\nI/O pads\\n25 %\\n40/110 = 36,36 %\\n30/90 = 33,33 %\\nWrong or no data sent Peripheral bus interface\\nOutput shift register\\nData sent register\\nI/O pads\\n25 %\\n40/110 = 36,36 %\\n30/90 = 33,33 %\\nWrong configuration \\nof SPI\\nConfiguration registers\\nPeripheral bus interface\\n25 %\\n20/110 = 18,18 %\\n20/90 = 22,22 %\\nNOTE 1   For this example, it is estimated that each subpart consumes 10 logic blocks and therefore it is estimated that each \\nfailure mode has a failure mode distribution proportional to the sum of logic blocks consumed by each subpart involved in \\nthe failure mode.\\nNOTE 2   The difference between b) and c) is that the resource usage for the specific failure mode is not estimated, instead \\nthe actual number of resources which contribute to the failure mode is computed. This can be done on the subpart level and \\nalso down to the elementary subpart level, if the logic blocks contributing to the failure mode span different subparts. In \\nthe example, it is measured that: Input shift register, output shift register, data received register and data send register are \\ncontributing 100 % to the respective failure mode and 0 % to the others; peripheral bus interface is measured to contribute \\n50 % to each data related failure mode and 100 % to configuration failure mode; I/O pads are measured to contribute 50 % \\nto each data related failure mode.\\n5.3.3.1.4\\t\\nVerification\\tof\\tcompleteness\\tand\\tcorrectness\\tof\\tsafety\\tmechanism\\timplementation\\t\\nwith respect to hardware\\nAs described in 4.8, fault injection simulation during the development phase is a valid method to verify \\nthe completeness and correctness of the safety mechanism implementation with respect to hardware \\nsafety requirements and also to assist verification of safe faults and computation of their amount and \\nfailure mode coverage, as described in 5.1.10. This applies for PLD manufacturers as well.\\nWith respect to PLD users, in the case where fault injection is necessary and no detailed information is \\navailable about how the user PLD design is mapped to PLD logic blocks, fault injection can be performed \\non the logic design before mapping.\\nEXAMPLE \\nIf fault injection is necessary to provide a rationale for the diagnostic coverage claimed by a \\nsoftware test library periodically testing the user PLD design, then fault injection can be executed at a different \\nlevel. For example, starting from the RTL design describing the user PLD design and then synthesizing it to \\nobtain a reference netlist on which fault injection is performed. If the reference netlist does not correspond to the \\nPLD design, then an argument is provided to explain why the injected faults are meaningful with respect to the \\nassumed implementation of the PLD design.\\n5.3.3.2 \\nDependent failure analysis for a PLD\\nAs for any integrated circuit, it is important to consider dependent failures, especially if hardware \\nsafety mechanisms or requirements for redundancy are implemented in the same component.\\nNOTE \\nThe flow for DFA considered in this sub-clause is considered equivalent to the specificities in 4.7. \\nTable 48 describes specificities \\xe2\\x80\\x94 if any \\xe2\\x80\\x94 to be considered in addition with respect to the steps defined in 4.7, \\nfor both PLD manufacturer and PLD users.\\n \\n110 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable\\t48\\t\\xe2\\x80\\x94\\tSpecificities\\tof\\tDFA\\tfor\\tPLD\\tmanufacturers\\tand\\tPLD\\tusers\\twith\\trespect\\tto\\t4.7\\nStep (see Figure 23)\\nPLD manufacturer\\nPLD user\\nB1:   Identify hardware and software \\nelements.\\nAs defined in 4.7.\\nAs defined in 4.7.\\nB2:   Identify dependent failures \\ninitiators.\\nAnalysis considers also the inter-\\nactions between configurable and \\nfixed logic, including interactions \\nrelated to reset or the configura-\\ntion technologya.\\nAnalysis considers also the impact \\nof failures affecting the configu-\\nration technology and therefore \\npotentially affecting multiple logic \\nblocks at the same time.\\nB6:   Identify necessary safety meas-\\nures to control or mitigate dependent \\nfailures initiators.\\nAnalysis considers also the pos-\\nsibilities for providing separa-\\ntion between configurable and \\nfixed logic\\nAnalysis considers also the pos-\\nsibilities for providing separation \\nbetween logic blocks\\nB10:   Evaluate the effectiveness to \\ncontrol or to avoid the dependent \\nfailure.\\nAs defined in 4.7.\\nAs defined in 4.7.\\na \\nFor example, a fault in the fixed logic causing the configurable logic to lose the configuration\\nThe DFI listed in Table 49 and Table 50 are equivalent to the statements in 4.7. Any additions regarding \\nDFI or countermeasures are applicable to PLD manufacturers and users alike.\\nTable\\t49\\t\\xe2\\x80\\x94\\tSpecificities\\tof\\tDFI\\tfor\\tPLD\\tmanufacturer\\tand\\tPLD\\tuser\\twith\\trespect\\tto\\t4.7\\nDependent Failure \\nInitiators (DFI)\\nPLD manufacturer DFI\\nPLD user DFI\\nFailure of shared \\nresourcesa\\nAs defined in 4.7\\nPotential dependency of the available clock networks\\nFailures of configuration technology (e.g. shared short \\nor long distance common interconnects)\\nFailures of shared programmable I/Os\\nWrong PLD configuration due to failures of external \\nconfiguration memory or related interconnection\\nSingle physical root cause\\nAs defined in 4.7\\nFaults (e.g. in reset logic) causing the complete or \\npartial loss of the PLD configuration\\nDevelopment faults\\nInsufficient distance or \\nisolation between fixed \\nand configurable logic\\nWrong usage of tools provided by PLD manufacturerb\\nSee also 4.7\\nManufacturing faults\\nAs defined in 4.7\\nWrong usage of tools for configuration programming b\\nInstallation faults\\nAs defined in 4.7\\nAs defined in 4.7\\nService faults\\nAs defined in 4.7\\nWrong usage of on-line reconfiguration functions\\na \\nIn the context of PLD, \\xe2\\x80\\x9ccommon\\xe2\\x80\\x9d means not only shared resources within either configurable or fixed logic but also \\nshared resources between configurable and fixed logic.\\nb \\nFor example, user wrongly applies isolation/separation constraints.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n111\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 50 \\xe2\\x80\\x94 Countermeasures related to DFI for PLD manufacturer and PLD user\\nDFI\\nPLD manufacturer \\ncountermeasures\\nPLD user countermeasures\\nFailure of shared \\nresourcesa\\nAs defined in 4.7\\nAnalysis of dependency of clock networks and dedicat-\\ned clock monitors\\nAnalysis of failures of configuration technology and \\nconsequent adoption of separation/isolation techniques\\nAnalysis of failures of shared programmable I/Os and \\nconsequent adaptation of I/Os safety protocols\\nIntegrity check (e.g. via CRC check) of PLD configura-\\ntion during runtime\\nSingle physical root cause\\nAs defined in 4.7\\nAnalysis of dependency of the reset networks and dedi-\\ncated watchdogs\\nDevelopment faults\\nProper isolation or sep-\\naration between fixed \\nand configurable logic\\nAs defined in 4.7\\nManufacturing faults\\nAs defined in 4.7\\nProper instructions in PLD tool manual to prevent DFI\\nInstallation faults\\nAs defined in 4.7\\nAs defined in 4.7\\nService faults\\nAs defined in 4.7\\nRestricted use of on-line reconfiguration functions\\na \\nIn the context of PLD, \\xe2\\x80\\x9ccommon\\xe2\\x80\\x9d means not only shared resources within either configurable or fixed logic but also \\nshared resources between configurable and fixed logic.\\n5.3.4 \\nExamples of safety mechanisms for PLD\\nTable 51 lists examples of safety mechanisms that can be used to address PLD failure modes described \\nin Table 43.\\nNOTE \\nThis table is not exhaustive and other techniques can be used, provided evidence is available to \\nsupport the claimed diagnostic coverage.\\nTable 51 \\xe2\\x80\\x94 Mapping of PLD safety mechanisms with ISO 26262-5:2018, Annex D\\nElement\\nExamples of safety mechanisms\\nFixed function IP\\nTable 34.\\nClock\\nISO 26262-5:2018, Table D.8\\nOn-chip clock status indication a\\nPower supply\\nISO 26262-5:2018, Table D.7\\nSeparate voltage planes b\\nDigital I/O\\nISO 26262-5:2018, Table D.5\\nAnalogue I/O\\nISO 26262-5:2018, Table D.5\\na \\nMany PLDs offer clock generation and management resources and also provide monitoring of clock \\nfunctionality and associated status pins/register to indicate when a specific clock is functioning properly \\n(e.g. whether or not a clock output is in proper phase with a master clock input).\\nb \\nVoltage plane means electrically isolated voltage supply plane regions with each plane region being \\nconnectable to an external supply voltage.\\nc \\nRefers to the capability of many programmable devices to check the contents of their configuration \\nregisters and compare those to the intended (design specific) contents. If a mismatch is detected, this \\nfeature can change the status of an output pin or generate an interrupt so that the system can respond \\nappropriately. To improve the usability as an online monitoring safety mechanism an efficient read back test \\ncan prioritize between safety-related and non-safety-related parts within a device. Safety related parts can \\nbe checked more frequently to considerably shorten failure detection time.\\n \\n112 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nElement\\nExamples of safety mechanisms\\nLogic block\\nISO 26262-5:2018, Tables D.4\\nTable 34\\nMix of spatial and temporal redundancy by means of recon-\\nfiguration\\nOff-chip communication\\nISO 26262-5:2018, Tables D.6\\nConfiguration technology\\nTable 32, Table 33\\nRead-back on download by downloading device c\\nUser memory\\nTable 32, Table 33\\nSignal routing capability\\nTable 35\\na \\nMany PLDs offer clock generation and management resources and also provide monitoring of clock \\nfunctionality and associated status pins/register to indicate when a specific clock is functioning properly \\n(e.g. whether or not a clock output is in proper phase with a master clock input).\\nb \\nVoltage plane means electrically isolated voltage supply plane regions with each plane region being \\nconnectable to an external supply voltage.\\nc \\nRefers to the capability of many programmable devices to check the contents of their configuration \\nregisters and compare those to the intended (design specific) contents. If a mismatch is detected, this \\nfeature can change the status of an output pin or generate an interrupt so that the system can respond \\nappropriately. To improve the usability as an online monitoring safety mechanism an efficient read back test \\ncan prioritize between safety-related and non-safety-related parts within a device. Safety related parts can \\nbe checked more frequently to considerably shorten failure detection time.\\n5.3.5 \\nAvoidance of systematic faults for PLD\\n5.3.5.1 \\nAvoiding systematic faults in the implementation of PLD\\nSince there are no significant differences in the specification, design and verification flow used by \\nPLD manufacturers with respect to the flow used by digital component manufacturers, the same \\nrecommendations given in 5.1.9 (and related Table 31) can be applied.\\n5.3.5.2 \\nAbout PLD supporting tools\\nPLD related tools can be distinguished in two categories:\\n\\xe2\\x80\\x94 tools used prior to the production (i.e. used by PLD manufacturers); and\\n\\xe2\\x80\\x94 tools used by PLD users.\\nThe confidence in use of tools belonging to both categories are analysed according to the requirements \\nof ISO 26262-8:2018, Clause 11.\\nEXAMPLE 1 \\nAccording ISO 26262-8:2018, Clause 11, a tool used for place and route by the PLD manufacturer \\ncan be considered TI2, since its malfunction can introduce an error in a safety-related element being developed; \\nIf it can be shown that design rule check (DRC) and layout versus schematic (LVS) checks with appropriate rule \\nsets, as foreseen in state-of-the-art IC design flows, can detect possible errors introduced by the tool with a high \\ndegree of confidence, then a TD1 can be claimed. In this case it can be considered TCL1 based on ISO 26262-8:2018, \\nTable 3.\\nEXAMPLE 2 \\nAccording ISO 26262-8:2018, Clause 11, a tool used for place and route by the PLD users can be \\nconsidered TI2, since its malfunction can introduce an error in a safety-related element being developed. If the \\nerror can be detected with a medium degree of confidence by the consequent hardware and integration tests, due \\nto the complexity of the circuitry, it can be considered TD2. Therefore it can be considered as TCL2 based on the \\nISO 26262-8:2018, Table 3. If the ASIL of the respective item is for example ASIL B, the tool provider can qualify \\nthe software tool by using an appropriate combination of \\xe2\\x80\\x9cincreased confidence from use\\xe2\\x80\\x9d and \\xe2\\x80\\x9cevaluation of the \\ntool development process\\xe2\\x80\\x9d.\\n \\nTable 51 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n113\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.3.5.3 \\nAvoiding systematic faults for PLD users\\nFor PLD manufacturers, as for a microcontroller, a PLD is developed based on a standardised \\ndevelopment process for which the example in 5.1.9 applies.\\nThe two following approaches are examples of how to provide evidence that sufficient measures for the \\navoidance of systematic failures have been addressed by the PLD user during the development, by using \\nappropriate processes:\\n\\xe2\\x80\\x94 using a checklist (see Table 52); and\\n\\xe2\\x80\\x94 using field data from similar products, which were developed using the same process as the target \\ndevice (for example using ISO 26262-8:2018, Clause 14).\\nTable 52 \\xe2\\x80\\x94 Examples of measures to avoid systematic failures for PLD users\\nISO 26262-5:2018 re-\\nquirement\\nDesign phase\\nTechnique/Measure\\nAim\\n7.4.1.6 Modular design \\nproperties\\nDesign entry\\nStructured description and \\nmodularization\\nThe description of the PLD\\xe2\\x80\\x99s \\nfunctionality is structured in \\nsuch a fashion that it is easily \\nreadable, i.e. circuit function \\ncan be intuitively understood \\non basis of description without \\nsimulation efforts\\n7.4.1.6 Modular design \\nproperties\\n \\nDesign description in HDL\\nFunctional description at high \\nlevel in hardware description \\nlanguage, for example such like \\nVHDL or Verilog.\\n7.4.2.4 Robust design \\nprinciples\\n \\nObservation of coding guidelines Strict observation of the coding \\nstyle results in a syntactically \\nand semantically correct cir-\\ncuit code\\n7.4.2.4 Robust design \\nprinciples\\nDesign entry\\nRestricted use of asynchronous \\nconstructs\\nAvoidance of typical timing \\nanomalies during synthesis, \\navoidance of ambiguity during \\nsimulation and synthesis caused \\nby insufficient modelling, design \\nfor testability.\\nThis does not exclude that for \\ncertain types of PLD implemen-\\ntations, asynchronous logic \\ncould be useful; in this case, \\nthe aim is to suggest additional \\ncare to handle and verify those \\ncircuits.\\nThe timing of asynchronous re-\\nsets bears risks due to different \\npropagation times to a poten-\\ntially large number of attached \\nelements. Since the asynchro-\\nnous reset signal is not corre-\\nlated to the clock of attached \\nsynchronous elements, meta-\\nstability can be a problem upon \\nreset deassertion. Arising prob-\\nlems are expected to depend on \\ndesign and environment factors, \\nsuch as temperature and fanout \\nof the reset net.\\n \\n114 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nISO 26262-5:2018 re-\\nquirement\\nDesign phase\\nTechnique/Measure\\nAim\\n7.4.2.4 Robust design \\nprinciples\\n \\nSynchronisation of primary in-\\nputs and control of metastability\\nAvoidance of ambiguous circuit \\nbehaviour as a result of set-up \\nand hold timing violation\\n7.4.4 Verification of hard-\\nware design\\n \\nHDL simulation\\nPre-silicon verification of circuit \\ndescribed in VHDL or Verilog by \\nmeans of simulation\\n7.4.4 Verification of hard-\\nware design\\n \\nFunctional test on module level \\n(using for example HDL test \\nbenches)\\nPre-silicon verification \"Bot-\\ntom-up\"\\n7.4.4 Verification of hard-\\nware design\\n \\nFunctional test on top level\\nVerification of the PLD (entire \\nfunction)\\n7.4.4 Verification of hard-\\nware design\\n \\nFunctional and structural cov-\\nerage-driven verification (with \\ncoverage of verification goals in \\npercentage)\\nQuantitative assessment of the \\napplied verification scenarios \\nduring the functional test. The \\ntarget level of coverage is de-\\nfined and shown\\n7.4.4 Verification of hard-\\nware design\\n \\nApplication of code checker\\nAutomatic verification of coding \\nrules (\"coding style\") by code \\nchecker tool.\\n7.4.4 Verification of hard-\\nware design\\n \\nDocumentation of simulation \\nresults\\nDocumentation of each data \\nneeded for a successful sim-\\nulation in order to verify the \\nspecified circuit function.\\n7.4.4 Verification of hard-\\nware design\\n \\nIntegration and verification of \\nsoft IPs\\nSee 4.5 of this document.\\n7.4.4 Verification of hard-\\nware design\\nSynthesis, \\nmapping, \\nfloor\\tplan-\\nning, place-\\nment, routing\\nCheck of PLD vendor require-\\nments and constraints\\nRequirements and constraints \\ndefined by PLD vendor are con-\\nsidered during PLD design\\n7.4.4 Verification of hard-\\nware design\\nAnalysis of PLD supporting \\ntool outputs\\nOutputs of PLD supporting tools \\nare analysed. Arguments are \\nprovided to waive warnings \\nand Errors.\\n7.4.1.6 Modular design \\nproperties\\n \\nDocumentation of constraints, \\nresults and tools\\nDocumentation of each defined \\nconstraint that is necessary for \\nan optimal synthesis, mapping, \\nplacement and routing of the \\nPLD design\\n7.4.1.6 Modular design \\nproperties\\n \\nScript based procedures\\nReproducibility of results and \\nautomation of the synthesis, \\nmapping, placement and routing\\n7.4.4 Verification of hard-\\nware design\\n \\nSimulation and timing verifica-\\ntion of the final netlist\\nIndependent verification of the \\nnetlist after synthesis, mapping, \\nplacement and routing \\xe2\\x80\\x94 in-\\ncluding timing verification\\n7.4.4 Verification of hard-\\nware design\\n \\nComparison of the final netlist \\nwith the reference model (for-\\nmal equivalence check)\\nFunctional equivalence check of \\nthe final netlist with RTL.\\n7.4.2.4 Robust design \\nprinciples\\n \\nAdequate time margin for pro-\\ncess technologies in use for less \\nthan three years\\nAssurance of the robustness \\nof the implemented circuit \\nfunctionality even under strong \\nprocess and parameter fluctua-\\ntion. A time margin in the timing \\nanalysis is considered either in \\nthe libraries or by PLD user.\\n \\nTable 52 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n115\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nISO 26262-5:2018 re-\\nquirement\\nDesign phase\\nTechnique/Measure\\nAim\\n7.4.4 Verification of hard-\\nware design\\n \\nDesign rule check (DRC)\\nExecution of design rule checks \\non floor planned logic\\n9.4.1.2, 9.4.13 Dedicated \\nmeasures\\n10 Hardware integration \\nand verification\\nPLD inte-\\ngration and \\ntesting\\nPLD verification\\nVerification of the PLD proto-\\ntype, including verification of \\nPLD correct configuration (e.g. \\nusing checksums).\\n7.4.5 Production, opera-\\ntion, service and decom-\\nmissioning\\n9.4.1.2, 9.4.1.3 Dedicated \\nmeasures\\n10 Hardware integration \\nand verification\\nPLD integration\\nVerification and integration of \\nthe PLD in the system\\n5.3.6 \\nExample of safety documentation for a PLD\\nRecommendations for the safety documentation for an SEooC digital component are given in 5.1.11, this \\ncan be consolidated in a \\xe2\\x80\\x9cSafety Manual\\xe2\\x80\\x9d or \\xe2\\x80\\x9cSafety Application Note\\xe2\\x80\\x9d. Those recommendations can be \\nused also by PLD manufacturers and PLD users, with the following remarks:\\n\\xe2\\x80\\x95 \\nthe DIA between PLD manufacturer and PLD user specifies which documents are made available \\nand what level of detail is provided to the PLD user;\\n\\xe2\\x80\\x95 \\nthe main focus of the safety documentation provided by PLD manufacturer is:\\n\\xe2\\x80\\x95 \\nthe description of the results of the analyses of the development processes of the PLD \\nmanufacturer with respect to the applicable requirements of ISO 26262;\\n\\xe2\\x80\\x95 \\nthe description of the results of the analyses of the PLD supporting tools with respect to the \\napplicable requirements of ISO 26262;\\n\\xe2\\x80\\x95 \\nthe provision of information (for example the PLD failure rate, the PLD failure modes with the \\nrelated failure modes distribution, the claimed diagnostic coverage for safety mechanisms that \\nare already implemented in the PLD etc.) to be used by PLD users during their safety analyses;\\n\\xe2\\x80\\x95 \\nproposals or examples of safety mechanisms, for example with respect to dependent failures \\netc.; and\\n\\xe2\\x80\\x95 \\nthe list of assumptions of use to guide PLD users in the correct utilisation of the safety-related \\ninformation provided with the PLD;\\n\\xe2\\x80\\x95 \\nthe work products of the safety lifecycle are provided by the PLD user. The completeness of the \\nwork products depends on whether the PLD user also assumes the role of the item integrator.\\n5.3.7 \\nExample of safety analysis for PLD\\nA detailed example of a quantitative safety analysis for PLD is described in Annex E of this document.\\n5.4 Multi-core components\\n5.4.1 \\nTypes of multi-core components\\nThere are two types of multi-core component:\\n\\xe2\\x80\\x95 \\nhomogeneous multi core components which include only identical PE, and;\\n \\nTable 52 (continued)\\n116 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nheterogeneous multi-cores components which have non-identical PEs, typically with different \\nInstruction Set Architecture (ISA).\\nEXAMPLE \\nFigure 27 shows a diagram of a generic homogeneous dual-core system, with CPU-local level 1 \\ncaches, and a shared, on-die level 2 cache.\\nFigure 27 \\xe2\\x80\\x94 Generic diagram of a dual-core system\\n5.4.2 \\nImplications of ISO 26262 series of standards for multi-core components\\n5.4.2.1 \\nIntroduction\\nThis sub-clause provides guidance for cases where safety requirements \\xe2\\x80\\x94 previously allocated to \\nmultiple components \\xe2\\x80\\x94 are now allocated to a multi-core.\\n5.4.2.2\\t\\nClarifications\\ton\\tFreedom\\tfrom\\tinterference\\t(FFI)\\tin\\tmulti-core\\tcomponents\\nIf in a multi-core context multiple software elements with different ASIL ratings coexist, a freedom \\nfrom interference analysis according to ISO 26262-9:2018, Clause 6 is carried out.\\nThe exemplary faults listed in ISO 26262-6:2018, Annex D can be a starting point for the analysis.\\nNOTE 1 \\nThis sub-clause focuses only on cascading faults between software elements implemented in PEs. \\nInterferences can also be caused by hardware dependent failures, in this case ISO 26262-9:2018, Clause 7 applies.\\nWith respect to interference against \\xe2\\x80\\x9cMemory\\xe2\\x80\\x9d entries of ISO 26262-6:2018, D.2.3, the case of \\ninterference with private resources is considered. This type of interference can affect data or program \\nregions belonging to one of the PEs.\\nEXAMPLE 1 \\nPrivate data can be variables that belong to a safety-related software element in one of the PEs: \\nA corruption of such variables from the other PEs leads to a malfunction of the software. In this case, a safety \\nmechanism supervising the access and ensuring exclusive access helps to avoid interference. This example is \\nrelated to software interferences (i.e. the variable corruption is caused by a software error). Interferences can \\nalso be caused by hardware dependent failures, in this case ISO 26262-9:2018, Clause 7 applies.\\nEXAMPLE 2 \\nPrivate program regions can be related to the corruption of a program in a non-volatile memory. In \\nthis case a mechanism restricting programming only from the higher ASIL elements helps to avoid interferences. \\nThis example can be applied to software related interference (in a case where the program corruption is caused \\nby a software error; for example wrong permissions causing software to overwrite the program memory). In this \\ncase ISO 26262-9:2018, Clause 7 applies.\\nThis type of interference can also affect resources shared between different PEs.\\nEXAMPLE 3 \\nA CAN peripheral is used by more than one core to exchange information with other ECUs. \\nInterference can lead to an incorrect message transmission. In this case usage of robust end-to-end protection \\nmechanisms (for example those listed in ISO 26262-5:2018, Table D.6) can help to detect interferences.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n117\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nEXAMPLE 4 \\nThe task to read and monitor an external sensor is allocated to the software. The initial \\nrequirement is rated with an ASIL X. In the further development steps this requirement is allocated to software \\nelement software_mon.1 with an ASIL Y(X) and to software element software_mon.2 with an ASIL Z(X). A DFA \\nhas shown that issues with the shared resources (cores, RAM and a software driver \"software peripheral\" \\nforwarding the sensor values to software_mon.1 and software_mon.2) can threaten the independence \\nrequirement, i.e. causing memory, time, execution or exchange of information interferences between software_\\nmon.1 and software_mon.2. In this example the shared core issue is addressed by mapping software_mon.1 \\nand software_mon.2 to two different PEs, therefore un-sharing the cores. The memory interference aspect is \\naddressed by memory encapsulation via a MPU which is configured by the OS. Since in this case the OS is a safety \\nmechanism ensuring the independence between software_mon.1 and software_mon.2 it is developed compliant \\nwith ASIL X. The issue with the shared software resource \"software peripheral\" is addressed by developing it \\ncompliant with the initial ASIL, i.e. ASIL X.\\nWith respect to interference against \\xe2\\x80\\x9cTime and execution\\xe2\\x80\\x9d entries of ISO 26262-6:2018, D.2.2, the \\nprimary case to consider is interference that affects the execution latency or correct programming \\nsequence of one core.\\nEXAMPLE 5 \\nA CAN peripheral is used by more than one core to exchange information with other ECUs. If \\nthe PEs processing tasks with a lower ASIL continuously request transmissions from the CAN peripheral then \\nthe higher ASIL tasks running in another core are not able to receive and/or transmit required information. A \\ntime monitoring mechanism (for example using the principles described for the safety mechanisms listed in \\nISO 26262-5:2018, Table D.8) can help to identify such conditions.\\nNOTE 2 \\nAdditional requirements related to timing are described in 5.4.2.3.\\nWith respect to the interference against \\xe2\\x80\\x9cExchange of information\\xe2\\x80\\x9d entries of ISO 26262-6:2018, D.2.4, \\ninterferences manifesting as failures in \\xe2\\x80\\x9cMemory\\xe2\\x80\\x9d or \\xe2\\x80\\x9cTime and execution\\xe2\\x80\\x9d can be caused by failures in \\nexchange of information between different PEs.\\nEXAMPLE 6 \\nA message from a non-safety-related core is interpreted as safety-related (masquerading fault).\\nNOTE 3 \\nUsage of robust end-to-end protection mechanisms (for example those listed in ISO 26262-5:2018, \\nTable D.6) can help to detect interference.\\nWhen software partitioning, e.g. separation of functions or elements to avoid cascading failures, is used \\nto implement freedom from interference between software components, ISO 26262-6:2018, 7.4.9 is \\napplied.\\nTechniques such as hypervisors can help to achieve software partitioning (e.g. References [26] and [5]).\\nNOTE 4 \\nOther techniques are also possible, such as microkernels (e.g. Reference [12]).\\nIt is worth considering the following points during safety analyses of multi-core involving hypervisors \\ntechnologies:\\n\\xe2\\x80\\x95 \\nvirtualization technologies can support the argument to guarantee freedom from interference \\nbetween software elements running in multi-core. A dependent failure analysis on software level \\nis required and can be supported by consideration of the failure modes listed in ISO 26262-6:2018, \\nAnnex D; and\\nNOTE 5 \\nPositive effects of virtualization technologies with respect to freedom from interference can \\nbe compromised by systematic faults in hypervisor software. Similarly, virtualization technologies can be \\naffected by hardware faults in the supporting hardware resources (like memory management unit) or in the \\nrelated shared resources. Those faults are analysed according to the methods described in ISO 26262-9:2018, \\nClause 8 and dedicated guidance for digital components is described in 5.1. Virtualization technologies can \\nalso be affected by hardware dependent failures; in this case ISO 26262-9:2018, Clause 7 applies.\\nNOTE 6 \\nIf any of the hypervisor functions are delegated to tasks in the software partitions, then the \\nanalysis mentioned in NOTE 5 extends also to the partitions.\\n\\xe2\\x80\\x95 \\nvirtualization technologies are typically not able to provide sufficient prevention or detection of \\npermanent or transient faults affecting the multi-core.\\n \\n118 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 7 \\nIt is possible for virtualization technologies to detect random failures if they manifest as \\nviolations of software partitioning enforced through virtualization. Detection of specific hardware failure \\nmodes can be demonstrated by means of case by case detailed analyses based on the methods described in \\nISO 26262-9:2018, Clause 8. Dedicated guidance for digital components is described in 5.1.\\n5.4.2.3 \\nTiming requirements in multi-core component\\nISO 26262-6 include clauses related to execution timing requirements, for example:\\n\\xe2\\x80\\x95 \\nISO 26262-6:2018, 6.4.2 e) requires that the specification of the software safety requirements \\nconsiders timing constraints;\\n\\xe2\\x80\\x95 \\nISO 26262-6:2018, 7.4.13 requires that an upper estimation of required resources for the embedded \\nsoftware is made, including execution time;\\n\\xe2\\x80\\x95 \\nISO 26262-6:2018, Table 10 Note c) indicates that there are relations between hardware and \\nsoftware that can influence e.g. the average and maximum processor performance, minimum or \\nmaximum execution times; and\\n\\xe2\\x80\\x95 \\nISO 26262-6:2018, Annex D describes timing and execution failure modes (including incorrect \\nallocation of execution time) as potential initiators of interferences between software elements.\\nMulti-cores are potentially subject to timing faults (see Reference [26]) therefore the previous listed \\nclauses are considered with dedicated analyses and the implementation of adequate countermeasures.\\nEXAMPLE 1 \\nTypical dedicated analyses for the identification of timing faults potentially violating the safety \\ngoal are based on the upper estimation of execution time (e.g. Reference [6]).\\nEXAMPLE 2 \\nTypical hardware-based countermeasures for detection of violation of timing requirements \\nare watchdogs, timing supervision units and specific hardware circuits (e.g. Reference [26]). Software-based \\ncountermeasures are also possible (e.g. Reference [3]).\\n5.5 Sensors and transducers\\n5.5.1 \\nTerminology of sensors and transducers\\nAs defined in ISO 26262-1:2018, 3.172, a transducer is a hardware part that converts energy from \\none form to another and, as such, it is a critical element to be considered with respect to automotive \\nfunctional safety. The quantification of the output energy form as compared to the input energy form is \\ndependent upon the sensitivity of the transducer. Input energy includes energy which is stored within \\nchemical bonds.\\nA sensor is an element that includes at least a transducer and a hardware element that supports, \\nconditions or further processes the transducer output for utilization in an E/E system.\\nEXAMPLE 1 \\nDC bias, amplification, filtering.\\nThe relationship between a transducer and a sensor is shown in Figure 28.\\nNOTE 1 \\nThe transducer in Figure 28 can be a separate component and the supporting circuitry can be a \\nseparate component or multiple components. The functionality of the transducer and supporting circuitry \\ntogether would make up the sensor function.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n119\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 28 \\xe2\\x80\\x94 General relationship between sensor and transducer\\nLike other E/E elements, a sensor can be made up of parts and subparts, and be of varying complexity.\\nEXAMPLE 2 \\nA semiconductor component with analogue output consisting of a transducer and amplifier.\\nEXAMPLE 3 \\nAn element consisting of housing, a sensor IC with digital signal processing and digital output, \\nrequired external components (e.g. resistors, capacitors) and a connector which interfaces to a wiring harness \\n(see Figure 29). In this example, both the sensor IC and other elements can be classified as sensors but exist at \\ndifferent levels of hierarchy.\\nNOTE 2 \\nThe term \\xe2\\x80\\x98transducer\\xe2\\x80\\x99 in this sub-clause refers specifically to those transducers that are fabricated \\nusing semiconductor process technology, including Micro Electro Mechanical Systems (MEMS). The term \\xe2\\x80\\x99sensor\\xe2\\x80\\x99 \\nin this sub-clause refers specifically to those sensors containing transducers, as previously described, and having \\nan electrical output.\\nSensors can be classified in various ways, as indicated in Reference [43].\\nFigure 29 \\xe2\\x80\\x94 Example of a complex hierarchical sensor\\n5.5.2 \\nSensors and transducers failure modes\\nIn the scope of this sub-clause, the output of each transducer is in the electrical domain. It then follows \\nthat the failure modes of the transducer will be electrical failure modes regardless of cause. Any failure \\nof an element in the signal path starting at the transducer can have an effect on the sensor output.\\nFailure modes for transducers can be derived by the method mentioned in 4.3.2.\\nTable 53 includes failure modes that are common to a variety of different types and complexities of \\ntransducers (independent of measurement, detection means, conversion means, etc.)[42]. This table \\n \\n120 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nis not exhaustive as electrical failure modes of a transducer depend upon the type and function of \\nthe specific transducer and is used for example only. Failure modes of digital or analogue supporting \\ncircuitry that are contained in the sensor signal path are covered in 5.1 and 5.2.\\nThe failure modes of the transducer appear as deviations to the nominal sensor output. Failure modes \\nof the sensor also originate from faults in the supporting circuitry in the signal path between the \\ntransducer output and sensor output. The correlation between the failure modes of the transducer \\nand failure modes of the sensor output will depend on the specific implementation of the transducer \\nin the sensor. According to ISO 26262\\xe2\\x80\\x935:2018, Table D.1, a detailed analysis of the actual sensor type is \\nnecessary to identify each failure mode.\\nPossible effects of transducer failure modes on the system output are included in Table 53. Whether \\nthese effects are considered relevant failure modes of the sensor depends on the safety requirements \\nallocated to the sensor. In general, a deviation in nominal performance of a sensor within a specified \\nrange can be accounted for by a system or element as long as the deviation remains predictable. Any \\nperformance excursions outside of a predicted range or behavioural model can lead to violations of \\nsensor safety requirements.\\nTable 53 \\xe2\\x80\\x94 Example of transducer failure modes (electrical)\\nTechnical\\tSpecifi-\\ncation\\nFailure mode\\nDescription\\nOffset\\nOffset outside of spec-\\nified range\\nTransducer output is offset from the ideal value in the absence of \\nstimulus (input energy)\\nOffset error over tem-\\nperature\\nOffset error over temperature is beyond specified limits\\nOffset drift\\nOffset value changes over time\\nDynamic Range\\nOut of range\\nTransducer output is outside of prescribed operational range\\nSensitivity (Gain)\\nSensitivity too high/\\nlow\\nSensitivity deviates beyond specified limits\\nStuck at\\nSensitivity is zero due to mechanical and electrical failure (e. g. \\nparticle short, stiction)\\nNonparametric sen-\\nsitivity\\nSensitivity deviates from a mathematical relationship within its \\nspecified range including discontinuities or clipping of output \\nresponse\\nNoise, poor repeata-\\nbility\\nVariable threshold required to overcome dynamic noise floor\\nSensitivity error over \\ntemperature\\nSensitivity deviates beyond specified limits over temperature\\nNOTE 1   Possible effects at system level include: inaccurate switching threshold, changes in switching threshold over \\ntemperature, changes in switching threshold over time, loss of function, inaccurate switching threshold, phase shift \\n(leading, lagging), changes in duty cycle, variation of output switching threshold, changes in switching threshold over \\ntemperature, phase shift over temperature, changes in duty cycle over temperature.\\nEXAMPLE \\nA typical camera based image sensor can be composed of the following parts and subparts: pixel \\narray; analog chain, clock and power supply; configuration and calibration circuitries; memories including RAM, \\nOTP; special circuitries; digital control; and interface. Failure modes of digital control, memories and related \\ninterface are analysed according to what is described in 5.1, while the failure modes of analogue chain, clock and \\nsupply are analysed according to what is described in 5.2. The following are examples of failure modes that can \\naffect the pixel array and the remaining parts and subparts, based on the categories listed in Table 53:\\n\\xe2\\x80\\x95 \\nspecific failure modes: camera fault (intended as a major fault of the array leading to full image \\nfault); loss of single image rows or horizontal line failure; loss of single image columns or vertical \\nline failure; loss of image frames;\\n\\xe2\\x80\\x95 \\nrelated to sensitivity (gain): loss of pixel data or corrupted bits in the image; noise in the image;\\n\\xe2\\x80\\x95 \\nrelated to offset: horizontally or vertically shifted images; and\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n121\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nrelated to dynamic range: under or over exposed image/pixel, including issues related to \\ndynamic range.\\n5.5.2.1 \\nProduction processes and failure modes\\nThe manufacturing of semiconductor based sensors and transducers is a multi-step process including \\nmany mechanical procedures such as wafer grind/thinning, saw, pick and place, die attach, wire bond, \\ndie stacking, and encapsulation. The mechanical stresses induced by these processes can impact \\nmaterial properties such as mobility which then result in fluctuations of device parameters. The \\ntechnical specifications of a transducer/sensor, such as offset, are impacted directly by the stresses \\nof the assembly process. A sensor or transducer that does not exhibit a specific failure mode before a \\nmechanical production process is not guaranteed to be free of that failure mode after the process.\\nSensors are typically calibrated by various methods, such that their technical specifications (e.g. \\noffset, sensitivity) are centred within their respective ranges, before being shipped by the supplier. \\nThe supplier\\xe2\\x80\\x99s production processes, however, are not the only source of assembly-induced mechanical \\nstress. The production processes of the direct customer, and possibly those further down the supply \\nchain, can introduce mechanical stresses or other environmental factors that can result in a failure \\nmode of the sensor. Such processes can include, but are not limited to, surface mounting, clamping, pick \\nand place, reflow and conformal coating processes. If possible, it is verified that the sensor/transducer \\nis functioning within specification after the final stage of each successive supplier\\xe2\\x80\\x99s production flow.\\nTable 54 lists some occurring failure modes of sensors/transducers that can result from assembly \\nprocesses. This table is not exhaustive. The capability to detect any deviations in sensor performance \\nintroduced by these processes, as well as their mitigation, are considered during the design phase to \\nensure adequate robustness (e.g. offset cancellation, sensitivity adjustment, and test modes). Refer to \\n5.5.5 for more information concerning avoidance of systematic faults during the development phase.\\nTable 54 \\xe2\\x80\\x94 Sensor Anomalies which can be introduced during Production Processes\\nProduction-Related \\nFailure mode\\nPossible Effect\\nPossible Causes\\nSensitivity shift\\nInaccurate switching thresh-\\nold, Phase shift\\nDuty cycle shift\\nMechanical stress (piezo-resistance), temperature \\ninduced mechanical stress, mechanical short or open \\n(e.g. broken metal, foreign material, ILD void), trapped \\ncharge, drop, shock, compression/decompression, \\nvibration, moisture intrusion, plastic deformation \\ncaused by temperature cycling, material curing\\nLoss of sensitivity\\nLoss of system\\nOffset\\nInaccurate switching \\nthreshold\\n5.5.2.2 \\nMicroelectromechanical causes of failure\\nMEMS sensors are used in a variety of applications and employ a mechanical detection method to sense \\nthe environment by a typically elastoelectric (movement based) means of conversion. Because the \\nconversion method is mechanical, the performance of the transducer is directly affected by its physical \\nstructure and any deviations in the structure from the nominal specifications.\\nA representation of a generic MEMS transducer is shown in Figure 30 and Figure 31. Figure 30 shows \\nindividual parts of a generic MEMS transducer including electrodes, proof mass, anchors, springs and \\ncapacitive plates. Figure 31 shows additional detail from a side view including the cavity, sealing cap \\nand anti-stiction coating. Any non-ideal physical/mechanical characteristic of these parts will have an \\n(electrical) effect on the transducer output.\\n \\n122 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure 30 \\xe2\\x80\\x94 Example of a MEMS transducer (top-view)\\nKey\\n1\\nsealing cap\\n2\\nanti-stiction coating\\n3\\nhermetically sealed cavity - pressurized (positive or negative)\\n4\\nproof mass: poly silicon thin film (e.g. cantilevered)\\n5\\nanchor\\n6\\nsilicon substrate\\nFigure 31 \\xe2\\x80\\x94 Example of a MEMS transducer (side-view)\\nSome common mechanical root causes of failures and the associated failure modes of MEMS transducers \\nare listed in Table 55, which is not exhaustive.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n123\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable 55 \\xe2\\x80\\x94 Examples of Root Causes & Associated Modes of MEMS Transducer Failures[45]\\nMechanical Root Cause\\nTransducer Failure \\nMode\\nDescription\\nFractured spring\\nNon-parametric Sen-\\nsitivity\\nMEMS motion transducers are typically designed with \\na collection of springs to provide mechanical position-\\ning, establish linear sensitivity, and limit the travel. \\nIf a spring in the collection fractures, the proof mass \\nbecomes unbalanced such that portions of the travel \\nappear normal, but the portion nearest the fractured \\nspring would be relaxed or potentially unlimited, re-\\nsulting in non-linear sensitivity.\\nFractured finger\\nSensitivity shift, offset \\nshift, change of sensor \\ndynamics\\nMEMS motion transducers are typically designed with \\nmultiple sets of capacitive interdigitated fingers for \\nsensing the proof mass movement. The sensitivity is \\nproportional to the total device capacitance, which \\nis the summation of each of the individual finger ca-\\npacitances. If a finger fractures, the total capacitance \\nis reduced, resulting in a decrease of sensitivity and \\noffset shift.\\nCavity seal breach\\nThe gap between the fingers provides an aerody-\\nnamic dampening due to the sealed gas molecules \\ninside the MEMS cavity structure. The sensitivity is \\nproportional to the pressure of the sealed gas. If the \\nseal is breached, the pressure reduces, resulting in an \\nincrease of sensitivity and then eventually in a change \\nof sensor dynamics (e.g. change of cut-off frequency).\\nFractured diaphragm\\nOffset shift,  \\nStuck-at\\nMEMS pressure transducers are typically designed as \\ndiaphragms, either to exert a strain on piezo-resistive \\nelements or to change the capacitive gap. If the dia-\\nphragm fractures, an offset or a complete loss of sensi-\\ntivity can occur, resulting in a stuck-at ground fault.\\nFractured Anchor\\nMEMS motion transducers are typically designed with \\nanchors for the springs, or with similar structures \\nused to limit travel distance. If the anchor, or trav-\\nel-limiter fractures, the proof mass becomes mis-\\naligned or travels outside of the allowable boundary \\ncoming in contact with the inner surfaces of the cavity, \\nresulting in a stuck-at fault.\\nParticles\\nSensitivity shift \\nNon-parametric sen-\\nsitivity\\nOffset shift\\nStuck at\\nA particle is capable of introducing multiple failure \\nmodes depending on the conductivity of the particle \\nand the individual parts of the transducer that it is \\ncontacting. If a particle is conductive, it can short \\nparts together and if it is resistive, it can impede the \\nmovement of the parts. Particles can also account for \\ntransient faults and general unpredictability if the \\nparticle is free to move within the cavity. Particles can \\nbe generated during production processes or due to \\nbreakage/wear during operation.\\nAnti-stiction coating anomaly\\nSensitivity shift\\nNon\\xe2\\x80\\x93parametric sen-\\nsitivity\\nStuck-at\\nCapillary or electrostatic forces cause suspended/\\ncantilevered surfaces to become stuck to other moving \\nsurfaces or to fixed surfaces due to anomalies of coat-\\nings used to prevent such effects.\\nGeneral mechanical overstress\\nSensitivity shift \\nNon-parametric sen-\\nsitivity\\nOffset shift\\nStuck at\\nSources of mechanical overstress can include shock, \\nfatigue, vibration, corrosion or the effects of electrical \\noverstress (EOS) or electrostatic discharge (ESD) that \\nresult in structural damage to MEMS transducer parts \\nor subparts.\\n \\n124 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.5.3 \\nSafety analysis for sensors and transducers\\n5.5.3.1 \\nConsiderations in the determination and allocation of base failure rate\\nThere can be specific challenges in determining the failure rate of integrated transducers and allocating \\nbase failure rates to transducers and supporting circuitry. The following points are considered when \\nconducting a quantitative analysis:\\n\\xe2\\x80\\x95 \\npassive transducers that take up a substantial percentage of die area which also includes active \\ncircuitry;\\nEXAMPLE 1 \\nHall cell based sensor.\\nNOTE 1 \\nThere can be a disparity in the failure rates between active and passive elements as well as those \\ndevices with larger versus smaller geometries.\\n\\xe2\\x80\\x95 \\ntransducers that are manufactured on top of active circuitry taking no area of the active die;\\nEXAMPLE 2 \\nGMR (giant magnetoresistance).\\n\\xe2\\x80\\x95 \\nhandbooks do not typically cover MEMS elements since the technology has been subject to rapid \\nadvances;\\n\\xe2\\x80\\x95 \\ntransducer failure rate distribution is dependent on the structure;\\nEXAMPLE 3 \\nMEMS for pressure sensor with a cavity, relatively large diaphragm, and small piezo-\\nelectrical conversion element.\\n\\xe2\\x80\\x95 \\ntransducers can be assembled with no supporting circuitry and it is therefore not possible to apply \\ncommonly used reliability standards to determine the base failure rate;\\n\\xe2\\x80\\x95 \\nfor new technologies, field data is not available and reliability data is limited; and\\n\\xe2\\x80\\x95 \\nfailure rates for the transducers versus supporting circuitry can be derived from different sources.\\nNOTE 2 \\nAppropriate scaling is applied if the failure rates are not from same source and conditions.\\nIn each case, the method of determining the base failure rate of a sensor and how the failure rate is \\nallocated to the transducer element is based on a sound and documented rationale.\\nEXAMPLE 4 \\nThe following is an example of a method for determination of failure rate for new MEMS \\ntransducer (no field/reliability data):\\n1) \\nbegin with a failure mode of an established MEMS device that includes overall failure rate, failure \\nmechanisms (e.g. particles, stiction, cavity breach) and distribution based on established data (e.g. field \\nreturn or other similar reliability source);\\n2) \\nestablish the baseline failure rate for each failure mechanism;\\n3) \\nfor each failure mechanism, assign a susceptibility factor that compares the transducer under design/\\nevaluation to the transducer used to derive the data in steps 1 and 2 above. This susceptibility factor assesses \\nthe relative risk between the reference transducer(s) and the transducer under evaluation, e.g. higher, lower \\nor the same;\\n4) \\ncombine the data from steps 2 and 3 to produce a weighted failure rate for each failure mechanism for the \\ntransducer under evaluation; and\\n5) \\napply the failure mode distribution from step 1 to generate a single predicted failure rate for the new MEMS \\ntransducer.\\nNOTE 3 \\nThis is an example method only. The procedures defined are neither exhaustive nor restrictive nor \\nrestricted to MEMS and are assumed to be based on a rationale that has been documented and substantiated \\nwith appropriate evidence.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n125\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n5.5.3.2 \\nDFA for sensors and transducers\\nDFA is performed according to the flow described in 4.7, if independence or freedom from interference \\nis required. Table 56 gives examples for DFI for various types of sensors.\\nTable 56 \\xe2\\x80\\x94 DFI for sensors and transducers\\nDFI\\tclasses\\tdefined\\tin\\t4.7.5\\nExamples\\nDFI due to random hardware faults of \\nshared resources\\nCommon calibration and/or configuration resources (e.g. eFUSE to \\ncontrol the CMOS based image sensor)\\nDFI due to random physical root causes\\nTemporal noise or fixed pattern noise\\nSystematic DFI due to environmental \\nconditions\\nExtended exposure to excessive heat, humidity, or strong sunlight\\nElectrostatic discharge\\nSystematic DFI due to development faults Wrong design of image sensor\\nSystematic DFI due to manufacturing \\nfaults\\nSensor manufacturing defects\\nSystematic DFI due to installation faults\\nMagnetic sensor target wheel mounted off axis (runout)\\nIncorrect positioning of mirror in image sensor\\nMethods to evaluate the effectiveness of controlling or avoiding dependent failures for sensors and \\ntransducers can be derived from the exemplary methods described in 4.7.5.2.\\n5.5.3.3 \\nQuantitative analysis\\nThere are no procedural differences in the quantitative analysis concerning the evaluation of hardware \\narchitectural metrics and the evaluation of safety goal violations due to random hardware failures for a \\nsensor compared to any other hardware element.\\nThe significant difference is related to the inclusion of the transducer element within the analysis since \\nviolations of sensor safety requirements are significantly related to failure modes of the transducer \\nelements. The following points are considered for the inclusion of the transducer within a quantitative \\nanalysis:\\n\\xe2\\x80\\x95 \\nlevel of granularity (how it is categorized into part and/or subparts);\\n\\xe2\\x80\\x95 \\nquantified failure rate and derived source;\\nNOTE \\nReliability and HTOL tests can be used to derive failure rates besides data from handbooks as for \\nnew technologies and applications of transducers and implementation technology. See also 4.6.1.6.\\n\\xe2\\x80\\x95 \\nfailure mode distribution; and\\n\\xe2\\x80\\x95 \\ninclusion of sensor specific safety mechanisms (see 5.5.4).\\nQuantitative analysis is conducted for the electrical failure modes of the semiconductor part and the \\nmechanical part according to ISO 26262-5:2018, Clause 8 and ISO 26262-5:2018, Clause 9.\\nQuantitative analysis of supporting circuitry is conducted according to guidance contained within 5.1 \\nfor digital circuitry and 5.2 for analogue.\\n5.5.4 \\nExamples of safety measures for sensors and transducers\\nTable 57 provides examples of safety mechanisms that are commonly used with sensors/transducers \\nthat support the unique role of the transducer element in evaluating the environment.\\nBecause a sensor can include a wide range of supporting circuitry both in quantity and type, these \\nsafety mechanisms are in addition to any analogue or digital safety mechanisms contained in 5.1 for \\ndigital, 5.2 for analogue, 5.3 for PLD safety mechanisms respectively.\\n \\n126 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nThe examples included in Table 57 are not exhaustive and other techniques can be used. Rationale is \\nprovided to support the claimed diagnostic coverage.\\nNOTE \\nIt is not possible to give a general guidance on the DC for sensors/transducers because it strongly \\ndepends on the specific technology, type of circuit, use case.\\nTable 57 \\xe2\\x80\\x94 Example of Safety Mechanisms for Sensors/Transducers\\nSafety mechanism/ \\nmeasure\\nSee overview of \\ntechniques\\nNotes\\nSealed Proof mass Filter \\nwith High Pressure\\n5.5.4.1\\nMEMS specific implementation.\\nRedundant Diaphragms\\n5.5.4.2\\nMEMS specific on-chip calibrated reference.\\nOffset cancellation\\n5.5.4.3\\nAllows for offset optimization.\\nTransducer specific self-\\ntest\\n5.5.4.4\\nVarious methods to test signal path integrity.\\nAutomatic Gain Control\\n5.5.4.5\\nAccounts for low levels of environmental stimulus and in-\\ncreases dynamic range.\\nSensitivity adjustment\\n5.5.4.6\\nAllows for sensitivity centring.\\nMEMS specific non E/E \\nsafety measures\\n5.5.4.7\\nMeasures that assess physical properties of MEMS transducers.\\n5.5.4.1 \\nSealed Proof Mass Filter\\nAim: To provide a low-pass filter mechanism which rejects noise that could otherwise alias into the \\nband of interest. Commonly used on MEMS accelerometer transducers.\\nDescription: A proof mass chamber sealed with greater than atmospheric pressure dampens the \\nenvironmentally induced movement of MEMS transducer parts.\\nEXAMPLE \\nA MEMS transducer can consist of groups of \\xe2\\x80\\x98comb\\xe2\\x80\\x99 fingers with a gap defined at a close tolerance. \\nAs the proof mass chamber is sealed under pressure, the ambient gas provides a squeeze-film dampening effect, \\nsimilar to a shock absorber, filtering the high frequency vibrations. Higher pressures trap more gas molecules \\nand, in effect, lower the cut-off frequencies. Lower pressures trap fewer gas molecules allowing higher cut-off \\nfrequencies.\\n5.5.4.2 \\nRedundant Diaphragms\\nAim: \\nTo provide a permanent reference with which to compare to the primary transducing element \\nof the system.\\nDescription: Inclusion of a reference transducer to allow comparison of the primary sensing \\ndiaphragm which is allowed to displace due to environmental factors to an equal but non-moving \\ndiaphragm. Commonly used on MEMS pressure transducers.\\nEXAMPLE \\nA MEMS transducer could be fabricated with a non-moving \\xe2\\x80\\x98twin\\xe2\\x80\\x99 that is formed at the same time \\nunder the same process steps and critical dimensions, and would be subject to the same process tolerances. \\nAs such, common variables such as sensitivity due to temperature or applied voltage would be shared and \\nmathematically cancel each other, leaving the moving vs. non-moving reaction as the only remaining difference \\nwhen sampled.\\n5.5.4.3 \\nOffset Cancellation\\nAim: \\nTo minimize offset in the transducer output.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n127\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nDescription: There are various hardware and software methods that can be employed to cancel the \\nbuilt in offset caused by non-ideal characteristics of a transducer. The chosen method will depend on \\nthe type of transducer used.\\nEXAMPLE \\nA linear magnetic sensor provides a specified quiescent voltage of VCC/2 in the absence of a \\nmagnetic field. A calibration routine is run on each power-up cycle to quantify the offset voltage with no magnetic \\nstimulus. This value is stored and used to adjust readings taken during operating mode.\\n5.5.4.4\\t\\nTransducer\\tspecific\\tself-test\\nAim: \\nTo provide a means of evaluating a specific type of transducer.\\nDescription: Because transducers respond to the environment, it can be challenging to evaluate the \\nintegrity of a sensor/transducer in the absence of the environmental condition. There are various ways \\nto stimulate a transducer by self-test and the accuracy and availability of these tests depend upon the \\nspecific type of transducer used and technical specification being evaluated. In general, the test is set \\nup to evaluate the integrity of the entire signal path or to isolate a clause of the signal path such as the \\nanalogue front end close to the transducer or the digitally processed back end.\\nEXAMPLE \\nA MEMS transducer could contain two sets of sense electrodes, electrically connected in opposite \\npolarity. Summing of the two absolute values is set to zero (within specified tolerances) independent of the MEMS \\nmechanical movement. A value outside of the allowable zero range would indicate an imbalance or fracture of the \\nproof mass or sensing electrode integrity.\\n5.5.4.5 \\nAutomatic gain control\\nAim: \\nTo support sensor functionality over low levels of environmental stimulus.\\nDescription: Typically, the electrical output of transducers is amplified in order to be further utilised \\nin a sensing system. Automatic gain control (AGC) allows for the gain of transducer amplification to \\nbe adjusted based on the amplitude of the transducer output signal. At low transducer output levels, \\nthe gain is increased and at higher transducer output levels, the gain is decreased to allow for greater \\ndynamic range.\\n5.5.4.6 \\nSensitivity adjustment\\nAim: \\nTo maintain sensitivity within its specified range\\nDescription: The sensitivity of a sensor/transducer is within its specified range over the operating \\ntemperature range of the sensor in order to ensure an accurate output. There are various methods to \\nadjust the sensitivity of a transducer in order to account for environmental fluctuations.\\nEXAMPLE 1 \\nThe use of a micro-heater activated by current to maintain sensitivity of MEMS parts over \\ntemperature [46].\\nEXAMPLE 2 \\nThe modification of bias current through a hall cell to maintain sensitivity over temperature.\\nEXAMPLE 3 \\nThe application of an electrostatic potential to MEMS fingers which electrically dampens \\nmovement and decreases sensitivity when applied.\\nEXAMPLE 4 \\nThe component connected to the MEMS has a built-in temperature sensor. On the basis of the \\ntemperature information, a correction compensating the sensitivity variation of MEMS is applied.\\n5.5.4.7\\t\\nMEMS\\tspecific\\tnon\\tE/E\\tsafety\\tmechanisms\\nAim: To provide mechanical safety mechanisms specific to MEMS transducer parts\\nDescription: In most cases, detection of a non-electrical failure in the transducer by electronic means \\n(after the transducer interface of the signal chain) is done based upon estimations of the effect of failures \\nupon the signal itself. In these cases, direct observation of the failure is typically not possible, therefore \\n \\n128 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nonly inferences can be used to determine if the transducer has experienced a failure [see Figure 32 b)]. \\nThe nature of this inferential method can be susceptible to incorrect or missed detections.\\nEXAMPLE \\nIn-range faults of the transducer.\\nIt is plausible that methods and technologies other than post-transduction electrical or electronic \\ntechnologies can be permanently employed within a MEMS transducer to directly detect or control \\nfailure modes within the transducer itself [see Figure 32 a)]. For example, additional mechanical or \\noptical mechanisms (e.g. References [44] and [45]) can be used within the transducer as safety \\nmechanisms such as a simple stop or floating cantilevered finger.\\nThese simple mechanical mechanisms can optionally include a separate signal output to allow the \\ntransducer to enter a safe state upon detection of a failure mode thereby eliminating the transducer \\nas the DFI of a specific safety goal or hardware requirement in a system. This would be in addition to \\nany dedicated measures or traditional E/E safety mechanisms and could potentially provide coverage \\nagainst both random and systematic faults within the transducer.\\nSuch non-E/E safety mechanisms could be defined in the application of diagnostic coverage. The level \\nof diagnostic coverage afforded by a non-E/E safety mechanism for a specific use case would require \\nsound engineering evaluation by domain experts to derive the proper value with each rationale and \\nverification activity fully documented and included in the safety case. Once verified and validated, such \\nnon-E/E safety mechanisms in a component can contribute to the system or element achieving the ASIL \\nof a given safety requirement or safety goal.\\na) Mechanical (non-E/E) Safety Mechanism\\nb) Electrical Safety Mechanism\\nFigure 32 \\xe2\\x80\\x94 Distinction between mechanically detected and electrically inferred transducer \\nfailures\\n5.5.4.8 \\nDedicated measures for sensors\\nAs described in ISO 26262-5:2018, 9.4.1.2 and 9.4.1.3, dedicated measures can be considered to ensure \\nthe failure rate claimed in the evaluation of the probability of violation of safety goals or requirements.\\nExamples of dedicated measures for sensors and transducers include:\\n\\xe2\\x80\\x95 \\noverdesign of parts or subparts of a sensor or transducer for robustness (e.g. electrical or thermal \\nstress rating);\\n\\xe2\\x80\\x95 \\na special sample test or 100 % production test of a critical sensor or transducer specification to \\nreduce the risk of occurrence of the failure mode;\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n129\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nlayout related measures;\\nEXAMPLE 1 \\nQuad hall cell configuration to minimize stress related offsets.\\n\\xe2\\x80\\x95 \\nbond pad order that minimizes opportunity for interaction;\\nEXAMPLE 2 \\nCommon-mode stray capacitance or current leakage affecting switch capacitance proof \\nmass movement.\\n\\xe2\\x80\\x95 \\ntechnology measures.\\nEXAMPLE 3 \\nUse of wet etch instead of dry etch technique for the removal of buried oxide layer resulting \\nin smoother surfaces and increased strength of MEMS parts [46].\\n5.5.5 \\nAbout avoidance of systematic faults for sensors and transducers\\nIn addition to what is described in 5.1.9 and 5.2.5 for digital and analogue components, the measures \\ndescribed in Table 58 can be adopted for sensors and transducers.\\nTable 58 \\xe2\\x80\\x94 Example of techniques or measures to achieve compliance with ISO 26262-5:2018 \\nrequirements during the development of a sensors or transducers\\nISO 26262-5:2018 \\nrequirement\\nDesign phase\\nTechnique/Meas-\\nure\\nAim\\n7.4.4 Verification of \\nhardware design\\nVerification\\nVerification of inter-\\nnal interfaces\\nTo verify by means of dedicated tests the \\ncorrect integration between mechanical, \\nelectro-mechanical, opto-electrical, magnetic \\npart of the sensor or transducer and related \\nanalogue and/or digital part.\\n10.5.1 hardware inte-\\ngration and verifica-\\ntion\\nHardware \\nintegration and \\nverification\\nTesting of influenc-\\nes of package\\nTo test the influences of package (for example \\nsupports like mirrors) to the sensor/trans-\\nducer characteristics.\\n7.4.4 Verification of \\nhardware design\\nDesign\\nFinite Element Anal-\\nysis (FEA)\\nTo mitigate influences of induced stress. To \\nensure the validity of the analysis, correlation \\nbetween FEA results and the measured value \\navailable at a later stage of the product devel-\\nopment or from a previous sample or product \\nis shown.\\n7.4.3 Safety Analyses\\nDesign\\nFMEA\\nTo consider the completeness and correct-\\nness of the transducer failure mode including \\nfailure modes, distributions and their effects \\non sensor output\\n7.4.2.4 Robust design \\nprinciples\\nDesign\\nDesign for manu-\\nfacturing\\nTo consider manufacturing process variations \\non sensor/transducer electrical characteris-\\ntics in order to increase robustness.\\n7.4.4 Verification of \\nhardware design\\nDesign\\nDesign for testa-\\nbility\\nTo design in necessary hardware to allow for \\nfull evaluation of transducer performance \\nand sensor/transducer safety mechanisms.\\n \\n130 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nISO 26262-5:2018 \\nrequirement\\nDesign phase\\nTechnique/Meas-\\nure\\nAim\\n7.4.5 Production, \\noperation, service and \\ndecommissioning\\n9.4.1.2, 9.4.1.3 Dedi-\\ncated measures\\nSafety-related \\nspecial charac-\\nteristics during \\nchip production\\nOptical pattern \\ninspection to de-\\ntect and cull early \\nfailures\\nSpecific layers of the semiconductor process \\nare optically compared to reference geome-\\ntries in order to detect patterning anomalies.\\n10.5.1 hardware inte-\\ngration and verifica-\\ntion activities\\nEvaluation of \\nhardware ele-\\nment\\nEnvironmental \\ntesting to simulate \\nactual operating \\nconditions\\nExtended reliability testing is performed that \\nsimulates environmental conditions of use \\ne.g. vibration test.\\n10.5.1 hardware inte-\\ngration and verifica-\\ntion activities\\nHardware inte-\\ngration\\tverifica-\\ntion\\nUnique test for sen-\\nsors with environ-\\nmental stimulus\\nAbility to expose sensor/transducer to the \\nenvironmental stimulus that it is sensing e.g. \\nacceleration, magnetic field, pressure\\n5.5.6 \\nExample of safety documentation for sensors and transducers\\nSafety documentation for sensors and transducers is produced in line with the documentation described \\nfor digital (see 5.1.11) and analogue components (see 5.2.6). It includes:\\n\\xe2\\x80\\x95 \\nbase failure rates, including assumptions and rationale with which they have been estimated;\\nNOTE \\nIt is useful if the base failure rate shows how the failure rate is distributed over the different fault \\nmodels that can affect the sensor and transducer.\\nEXAMPLE \\nIn the case of an image sensor based camera, the percentage with which a fault in the pixel \\narray can affect a single pixel, a whole column, a whole row, many pixels or the full array is provided.\\n\\xe2\\x80\\x95 \\nthe list of transducer failure modes, with end effect and failure mode distribution; and\\n\\xe2\\x80\\x95 \\nuser information such as safety manual or safety application note, with specific emphasis on:\\n\\xe2\\x80\\x95 \\nsafety mechanisms integrated in the device and their availability;\\n\\xe2\\x80\\x95 \\nconfiguration or calibration parameters (and related procedures) that can influence the safety \\ncharacteristics of the device; and\\n\\xe2\\x80\\x95 \\nproduction related instructions affecting functional safety.\\n \\nTable 58 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n131\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nAnnex A \\n(informative) \\n \\nExample on how to use digital failure modes for diagnostic \\ncoverage evaluation\\nA.1 Example of evaluation of a DMA safety mechanism\\nA.1.1 Description of the use case\\nThe following is the DMA use case considered in this example:\\n\\xe2\\x80\\x95 \\na message is received by a communication peripheral every X ms;\\n\\xe2\\x80\\x95 \\nas soon as the message is received by the communication peripheral, it triggers a DMA request;\\n\\xe2\\x80\\x95 \\nthe DMA transfers the message from the peripheral receive buffer to a RAM region;\\n\\xe2\\x80\\x95 \\nthe transfer is always to the same RAM region, independent from the message content;\\n\\xe2\\x80\\x95 \\nafter the DMA is finished with the transfer, it triggers a CPU interrupt; and\\n\\xe2\\x80\\x95 \\nthe CPU copies the message into a different buffer within the RAM depending on the message ID.\\nA.1.2 Description of the safety mechanisms\\nIn this example, the following safety mechanisms are available to monitor the correct DMA activity:\\n\\xe2\\x80\\x95 \\nSafMech_01_DMA_MPU: Dedicated memory protection unit defining the memory regions which \\nare accessible via DMA:\\n\\xe2\\x80\\x95 \\nwrite access is restricted to the destination addresses; and\\n\\xe2\\x80\\x95 \\nread access is restricted to the source addresses;\\n\\xe2\\x80\\x95 \\nSafMech_02_E2E_Protection:\\n\\xe2\\x80\\x95 \\nthe DMA transfers messages which are end-to-end protected by:\\n\\xe2\\x80\\x95 \\na 8 bit CRC over the data content, the message ID and the message counter;\\n\\xe2\\x80\\x95 \\nmessage ID (4 bit); and\\n\\xe2\\x80\\x95 \\nmessage counter (4 bit);\\n\\xe2\\x80\\x95 \\nout of the 24 = 16 message IDs only 12 are valid;\\n\\xe2\\x80\\x95 \\nthe counter is reset to zero after reaching its maximum value of 0xF; and\\n\\xe2\\x80\\x95 \\nthe message is copied to a different RAM region by the CPU after receiving the data transfer \\ncomplete signal. This memory region is not accessible by the DMA. The E2E protection \\nmechanisms are checked after the copy operation by the CPU. The application only uses this \\ncopy; it does not use the data in the destination address of the DMA;\\n\\xe2\\x80\\x95 \\nSafMech_03_Timeout_Mon: The data transfer is supposed to occur periodically. The frequency is \\nknown by the system. It monitors if a data transfer occurs within the specified time frame; and\\n \\n132 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nSafMech_04_IR_Source_Mon: In the case of an interrupt request this safety mechanism checks if \\nthe trigger came from a legal source.\\nA.1.3\\t Definition\\tof\\tthe\\tfailure\\tmodes\\tand\\testimation\\tof\\tdiagnostic\\tcoverage\\nBased on the described use case and safety mechanisms, the following failure modes are defined and \\nthe following values for diagnostic coverage can be estimated.\\nA.1.3.1 DMA_FM1: no requested data transfer\\nThis failure mode is detected by SafMech_03_Timeout_Mon since there is no data transfer completed \\nsignal within the specified time frame. The FMCDMA_FM1 is estimated as 100 %.\\nA.1.3.2 DMA_FM2: data transfer without a request\\nThe DMA transfers data from the source to the destination address. It signals the data transfer \\ncompletion. Depending on the content of the source address this could be a previous message (DMA_\\nFM2.1) or a random value (DMA_FM2.2; modelled as \\xe2\\x80\\x9cwhite noise\\xe2\\x80\\x9d i.e. each possible error state is \\nequally probable).\\nIn more detail:\\n\\xe2\\x80\\x95 \\nDMA_FM2.1: The previous message will be detected via the message counter or the message ID of \\nthe E2E protection (SafMech_02_E2E_Protection). The FMCDMA_FM2.1 is estimated as 100 %;\\n\\xe2\\x80\\x95 \\nDMA_FM2.2: In the case of a random value:\\n\\xe2\\x80\\x95 \\nthe probability pCRC,legal of randomly matching a legal CRC value is 1/28;\\n\\xe2\\x80\\x95 \\nthe probability pID,legal of randomly matching a legal ID is 12/16;\\n\\xe2\\x80\\x95 \\nthe probability pCounter,legal of randomly matching the correct counter value is 1/24 (since \\nonly one of the 24 values is the correct one);\\n\\xe2\\x80\\x95 \\nthe \\noverall \\nprobability \\npRF \\nthat \\nno \\nerror \\nis \\ntriggered \\nis \\npRF = pCRC,legal \\xc3\\x97 pID,legal \\xc3\\x97 pCounter,legal = 0,000 183; and\\n\\xe2\\x80\\x95 \\nthe FMCDMA_FM2.2 is estimated as 1 \\xe2\\x88\\x92 pRF so equal to 99,98 %.\\nTo derive an accurate estimation of the overall failure mode coverage FMCDMA_FM2, the failure mode \\ndistribution between the two failure modes DMA_FM2.1 and DMA_FM2.2 is estimated.\\nSince here both values are very high and very close to each other, the effort of estimating the failure \\nmode distribution of these two failure modes is omitted and just the lower value is used: \\nFMCDMA_FM2 and FMCDMA_FM2.2 are estimated as 99,98 %.\\nA.1.3.3 DMA_FM3: data transfer too early/too late\\nFor the evaluation, the failure modes are further elaborated:\\n\\xe2\\x80\\x95 \\nDMA_FM3.1: The data transfer is triggered before the correct request. This failure mode is \\nequivalent to DMA_FM2 and is not further evaluated here. FMCDMA_FM3.1 is estimated as 100 %;\\n\\xe2\\x80\\x95 \\nDMA_FM3.2: The data transfer is triggered too late after the correct request. Depending on the \\ndelay the effect could be one of the following:\\n\\xe2\\x80\\x95 \\nDMA_FM3.2a: Depending on the communication peripheral either the message gets \\noverwritten by the following message before it is fetched by the DMA or the following message \\ncannot be received. Both cases result in a loss of a message. This will be detected by either by \\nSafMech_03_Timeout_Mon or by SafMech_02_E2E_Protection (via the message counter) with \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n133\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\na FMC = 100 %. Depending on the communication peripheral additional error signals can be \\ngenerated by the communication peripheral itself;\\n\\xe2\\x80\\x95 \\nDMA_FM3.2b: During the fetch operation by the DMA the next message is received partially \\noverwriting the previous one. This results in a corrupted message consisting partly of the two \\nmessages:\\n\\xe2\\x80\\x95 \\nthe ID is legal (pID,legal = 1);\\n\\xe2\\x80\\x95 \\nthe counter of the successive message could have a high probability of being the same as \\nthe counter of the predecessor message (if both messages have the same transmission \\nfrequency). Here the worst case probability of pCounter,legal = 1 is assumed;\\n\\xe2\\x80\\x95 \\nthe data corruption is modelled as \\xe2\\x80\\x9cwhite noise\\xe2\\x80\\x9d rendering a probability pCRC,legal of \\nrandomly matching a legal CRC value of 1/28; and\\n\\xe2\\x80\\x95 \\nFMC = 1 \\xe2\\x88\\x92 pCRC,legal \\xc3\\x97 pID,legal \\xc3\\x97 pCounter,legal = 99,6 %.\\n\\xe2\\x80\\x95 \\ndepending on the communication peripheral:\\n\\xe2\\x80\\x95 \\nadditional error signals can be generated, increasing the effective FMC, or\\n\\xe2\\x80\\x95 \\nthis failure mode is not possbile, leaving only DMA_FM3.2a.\\nFor an accurate estimation of FMCDMA_FM3.2 the failure mode distribution between DMA_FM3.2a \\nand DMA_FM3.2b is derived. For a conservative first estimation the lower FMC of the two can be used: \\nFMCDMA_FM3.2 = 99,6 %.\\n\\xe2\\x80\\x95 \\nDMA_FM3.3: The data transfer completed signal is provided before the transfer is complete. This \\nwould result in a partially corrupted message where the message in the destination buffer consists \\nof a mix of two messages. As far as detection by SafMech_02_E2E_Protection is concerned, the \\nargument is analogue to DMA_FM3.2b: FMCDMA_FM3.3 is estimated as 99,6 %;\\n\\xe2\\x80\\x95 \\nDMA_FM3.4: The data transfer completed signal is provided too late after the transfer is complete. \\nThis failure mode can lead to:\\n\\xe2\\x80\\x95 \\nDMA_FM3.4a: The message is overwritten by the successive message before the CPU can fetch \\nit. This results in a loss of message and is detected by either SafMech_03_Timeout_Mon or \\nSafMech_02_E2E_Protection with an FMC = 100 %. This is analogue to DMA_FM3.2a; and\\n\\xe2\\x80\\x95 \\nDMA_FM3.4b: The message is overwritten by the DMA during the fetch by the CPU. This results \\nin a partially corrupted message. FMC = 99,6 % (analogue to DMA_FM3.2b).\\nWith the same argument as before the overall FMCDMA_FM3.4 can be estimated as 99,6 %.\\nA.1.3.4 DMA_FM4: incorrect output\\nIn contrast to the previous failure modes which were timing related this failure mode addresses \\nincorrect outputs but with the right timing. In this example the DMA has the following outputs:\\n\\xe2\\x80\\x95 \\ncontrol signal: read or write;\\n\\xe2\\x80\\x95 \\ncontrol signal: access width (8 bit, 16 bit, 32 bit);\\n\\xe2\\x80\\x95 \\ncontrol signal: address to be accessed;\\n\\xe2\\x80\\x95 \\ndata (in the case of writes); and\\n\\xe2\\x80\\x95 \\nfour different interrupt request signals.\\nThe following sub failure modes can be distinguished:\\n\\xe2\\x80\\x95 \\nDMA_F4.1a: read instead of write;\\n \\n134 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\ninstead of writing to the RAM destination, the DMA will execute a read access from this address. \\nThere will be no more updates of the messages. After the \\xe2\\x80\\x9ctransfer\\xe2\\x80\\x9d the DMA still triggers the CPU \\ninterrupt request. The old message will be detected by SafMech_02_E2E_Protection either by \\nchecking the ID or by checking the counter. In addition SafMech_01_DMA_MPU will detect an illegal \\naccess (read instead of a write). FMCDMA_FM4.1a is estimated as 100 %.\\n\\xe2\\x80\\x95 \\nDMA_F4.1b: write instead of read;\\n\\xe2\\x80\\x95 \\nwrite instead of read: the DMA will perform a write access to the communication peripheral \\ninstead of a read access. Depending on the communication peripheral this can already lead to \\nan error reaction by the communication peripheral. In addition the illegal write access will be \\ndetected by SafMech_01_DMA_MPU. FMCDMA_FM4.1b is estimated as 100 %.\\n\\xe2\\x80\\x95 \\nDMA_F4.2: incorrect access width;\\n\\xe2\\x80\\x95 \\nincorrect access width: This failure mode will result in a corrupted message, which is detectable \\nvia the CRC of SafMech_02_E2E_Protection. ID check and illegal message counter can also lead \\nto an error detection (see also SafMech_01_DMA_MPU). FMCDMA_FM4.2 is estimated as 99,6 %.\\n\\xe2\\x80\\x95 \\nDMA_F4.3: incorrect access address;\\n\\xe2\\x80\\x95 \\nincorrect access address: This failure mode will lead to the access of an illegal address by the \\nDMA and will be detected by SafMech_01_DMA_MPU. FMCDMA_FM4.3 is estimated as 100 %.\\n\\xe2\\x80\\x95 \\nDMA_F4.4: incorrect data output; and\\n\\xe2\\x80\\x95 \\nincorrect data output: This failure mode will lead to randomly corrupted message, similar to \\nDMA_FM2.2. FMCDMA_FM4.4 is estimated as 99,98 %.\\n\\xe2\\x80\\x95 \\nDMA_F4.5: incorrect interrupt request\\n\\xe2\\x80\\x95 \\nincorrect interrupt request: In this example the DMA triggers just one CPU interrupt \\nrequest. Therefore SafMech_04_IR_Source_Mon will detect this fault. FMCDMA_FM4.5 is \\nestimated as 100 %.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n135\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b' \\nISO 26262-11:2018(E)\\nAnnex B \\n(informative) \\n \\nExamples of dependent failure analysis\\nB.1 Microcontroller example\\nB.1.1 Description\\nThe microcontroller component described in Figure B.1 is used to illustrate the dependent failure \\nanalysis methodology for a digital component.\\nFigure B.1 \\xe2\\x80\\x94 Microcontroller component example\\n \\n136 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFirst an introduction to the hardware and software elements is done to highlight the hardware safety \\nmechanisms that are going to be used for the DFA. It is not in the scope of this example to provide a \\ncomprehensive specification of the hardware safety requirements and the safety mechanisms.\\n\\xe2\\x80\\x94 Hardware Element 1.1: Interface processing element that enables to receive information from \\nhardware elements connecting to the Microcontroller (e.g. Signal 1 from External Element 1).\\n\\xe2\\x80\\x94 Hardware Element 1.2: Interface processing element identical to Hardware Element 1.1 from a \\nfunctional point of view.\\n\\xe2\\x80\\x94 Hardware Element 2: This element is used to control the External Element 2.\\n\\xe2\\x80\\x94 Control: This element provides the select signals that enable to control the connectivity of Hardware \\nElement 1.1 and 1.2 with different input interfaces of the microcontroller.\\n\\xe2\\x80\\x94 CPU: Central Processing Unit where software elements are executed.\\n\\xe2\\x80\\x94 Data SRAM: Memory where software elements store their own private variables. It also contains \\ncommunication buffers between software and DMA and between software elements themselves.\\n\\xe2\\x80\\x94 Code ROM: Read-only Memory containing the code that is executed by the software elements and \\npossibly constant data used by the software elements.\\n\\xe2\\x80\\x94 Software Elements: In this example three software elements are listed: software1, software2 and \\nsoftware3.\\n\\xe2\\x80\\x94 Watchdog Interface: It enables to communicate with an external watchdog hardware element.\\n\\xe2\\x80\\x94 Shared Resources: The following shared resources are identified:\\n\\xe2\\x80\\x94 DMA (Direct Memory Access) hardware element: The DMA can be used by each software \\nelement and has read and write access to any addressable resource (Memory, Configuration \\nRegister).\\n\\xe2\\x80\\x94 EVR (Embedded Voltage Regulator): The EVR provides the power supply to each hardware \\nelement inside the microcontroller with the exception of the input/output pads that are powered \\nby the \\xe2\\x80\\x9cExternal Power Supply\\xe2\\x80\\x9d.\\n\\xe2\\x80\\x94 Reset Generation & Distribution: Controls the reset state of the microcontroller based on reset \\ncommands originating from the external reset source or internal reset actions controlled by \\nhardware or software elements.\\n\\xe2\\x80\\x94 Clock Generation & Distribution: Delivers the intended clocks for each hardware element based \\non a PLL using an \\xe2\\x80\\x9cExternal Clock Source\\xe2\\x80\\x9d.\\n\\xe2\\x80\\x94 Test Logic: Test structures required for the production tests of the microcontroller.\\nThe functional safety concept and requirement concept is defined as follows. The Signal S1 is an \\nanalogue signal that indicates the state of an actuator. The requirement is \\xe2\\x80\\x9cAn unintended state shall be \\nrecognized and shall lead to the de-activation of the actuator\\xe2\\x80\\x9d. This is considered to be the safe state. \\nFor that purpose, the Signal S1 is converted into digital information and then processed by a software \\nelement software1 to identify a possible hazardous state of the actuator. The software element \\nsoftware2 is responsible to redundantly acquire information from Hardware Element 1.1 and 1.2. The \\nmain task of software2 is to control the DMA to fetch the conversion results from Hardware Element \\n1.1 and 1.2 and store as separated data sets in a shared buffer located in Data SRAM. DMA informs \\nsoftware2 about the completion of transfers by sending an interrupt to the ICU. Upon reception of \\nthis event software2 compares the plausibility of the data sets and in the case of mismatch it provides \\npredefined error information to software1. The software element software3 is responsible for a \\nperiodic refresh of the external watchdog. The refresh requires sending a dynamic code with a given \\nsequence. The code to be sent is only provided by software element software1. If software3 fails to \\nrefresh the watchdog or sends an incorrect code, the external watchdog enters timeout state that leads \\nto the de-activation of the actuator.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n137\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nThis annex provides exemplary safety requirements. The specification of the set of safety requirements \\nis reduced to a minimum set that is suitable for the DFA:\\n\\xe2\\x80\\x94 MCU-REQ-1: \\xe2\\x80\\x9cFaults during the processing of Signal 1 by Hardware Element 1.1 shall be detected \\nwithin 20 milliseconds [ASIL X]\\xe2\\x80\\x9d:\\n\\xe2\\x80\\x94 MCU-REQ-1.1: \\xe2\\x80\\x9cSignal 1 shall be redundantly processed by Hardware Element 1.2\\xe2\\x80\\x9d; and\\n\\xe2\\x80\\x94 MCU-REQ-1.2: \\xe2\\x80\\x9cResults of Hardware Element 1.1 and 1.2 shall be monitored by software. In the \\npresence of a mismatch software shall send an error message to the external watchdog through \\nthe watchdog interface\\xe2\\x80\\x9d; and\\n\\xe2\\x80\\x94 MCU-REQ-2: \\xe2\\x80\\x9cRandom hardware fault leading to a wrong output of CPU shall be detected within 20 \\nmilliseconds [ASIL X]:\\xe2\\x80\\x9d\\n\\xe2\\x80\\x94 MCU-REQ-2.1: \\xe2\\x80\\x9cCPU shall be monitored by a Redundant CPU. Outputs of CPU and Redundant \\nCPU shall be compared every clock cycle by a hardware comparator\\xe2\\x80\\x9d; and\\n\\xe2\\x80\\x94 MCU-REQ-2.2: \\xe2\\x80\\x9cIn the presence of a mismatch between CPU and Redundant CPU an error event \\nshall be generated\\xe2\\x80\\x9d.\\nB.1.2 Dependent failure analysis\\nThe DFA will only focus on the DFI that have the potential to lead to a violation of the safety requirement \\nMCU-REQ-2. The analysis will follow the proposed workflow. To simplify the analysis, each step will \\nnot be considered. With respect to the requirements MCU-REQ-2, this step focuses on analysing the \\narchitecture focusing on steps B1 and B2 of the DFA workflow. The analysis is supported by a qualitative \\nfault tree (see Figure B.2) that identifies the shared resources and the redundant elements.\\nFigure B.2 \\xe2\\x80\\x94 Shared elements overview\\nFor the shared resources, each failure base event or AND gate is analysed on its own. For the CPU \\nand Redundant CPU a base event Dependent Failures has already been introduced because the safety \\nmechanism is already visible on the proposed architectural level. It is recommended to analyse the \\nGeneric Infrastructure Elements that have a global effect separately, in order to avoid considering \\nthem for each shared element independently. This is possible for the power supply and clock generation \\nbecause they have their own safety mechanisms. However, for the Reset Generation, Test Signals and \\nDebug Infrastructure it is necessary to analyse them at a lower level where their influence on the shared \\nelements\\xe2\\x80\\x99 safety mechanisms can be analysed. For the Generic Infrastructure Elements the analysis \\nwill concentrate on the power supply and clock generation.\\n \\n138 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable B.1 shows an example for a microcontroller DFA.\\nTable B.1 \\xe2\\x80\\x94 DFA for microcontroller example\\nID\\nElement\\nRedundant \\nelement\\nDependent failure initiators\\nDFA\\nShort \\nname and \\ndescrip-\\ntion\\nShort name \\nand descrip-\\ntion\\nShared resourc-\\nes\\nSingle physical \\nroot cause\\nMeasure for fault \\n(A)voidance or \\n(C)ontrol\\nVerification\\t\\nmethod\\nGeneric Infrastructure Elements\\nPS1\\nPower \\nSupply\\nPower Supply \\nMonitor:\\nmeasurement \\nof voltage levels \\nwithin operat-\\ning conditions\\nShared Bandgap \\nhas the poten-\\ntial to lead to \\nundetected over \\nvoltage.\\n \\n(C) Add a Band-\\ngap Monitor\\nSilicon-level \\nrobustness \\ntest\\nPLL1\\nClock\\nClock Monitor\\nFrequency \\nMeasurement\\nShared Input \\nFrequency has \\nthe potential to \\nprevent accurate \\nfrequency meas-\\nurement.\\n \\n(C) Add an inde-\\npendent clock \\nsource (Oscillator) \\nto measure the \\nPLL frequency\\n(A) Design dissim-\\nilarity: dissimilar-\\nity between drift \\nbehaviour of PLL \\nand drift behav-\\niour of reference \\noscillator used \\nby Clock Monitor \\nthanks to different \\nimplementation.\\nDesign in-\\nspection\\nSilicon-level \\nrobustness \\ntest\\nPLL2\\nClock\\nClock Monitor\\nFrequency \\nMeasurement\\nLoss of Clock that \\nprevents Monitor \\nto report failure \\ncondition\\n \\n(C) Semiconductor \\nmonitoring by Ex-\\nternal Watchdog.\\n \\nPLL3\\nClock\\nClock Monitor\\nFrequency \\nMeasurement\\n \\nIt is analysed \\nbased on a \\ndetailed block di-\\nagram of the clock \\ngeneration and \\nclock monitoring \\nwhere the relevant \\ninterfaces, side-\\nband signals and \\nconfiguration reg-\\nisters are visible.\\n \\n \\nProcessing Elements\\nCPU1\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\nPower Supply\\n \\nCovered by Power \\nSupply Analysis\\n \\nCPU2\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\nClock: incorrect \\nfrequency\\n \\nCovered by PLL \\nAnalysis\\n \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n139\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nID\\nElement\\nRedundant \\nelement\\nDependent failure initiators\\nDFA\\nShort \\nname and \\ndescrip-\\ntion\\nShort name \\nand descrip-\\ntion\\nShared resourc-\\nes\\nSingle physical \\nroot cause\\nMeasure for fault \\n(A)voidance or \\n(C)ontrol\\nVerification\\t\\nmethod\\nCPU3\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\nClock: clock \\nglitch\\n \\n \\n \\nCPU4\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\nShared Bus\\n \\n \\n \\nCPU5\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\nData SRAM\\n \\nSafety Mecha-\\nnisms for Data \\nSRAM (e.g. ECC) \\nare covered by \\nSafety Analysis.\\nECC is evaluated \\nby Redundant CPU \\nenabling to con-\\ntrol this depend-\\nent failure related \\nto interface to \\nData SRAM.\\n \\nCPU6\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\nCode SRAM\\n \\n \\n \\nCPU7\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\nICU\\n \\n \\n \\nCPU8\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\n \\nShort-circuit be-\\ntween signals be-\\nlonging to CPU and \\nsignals belonging \\nto Redundant CPU\\n(A) Physical sep-\\naration according \\nto technology \\ndesign rules\\nAnalysis of \\ndesign rules\\nPhysical lay-\\nout inspection\\nCPU9\\nCPU, Com-\\nputation\\nRedundant \\nCPU + Hard-\\nware Compar-\\nator\\n \\nLatch-up affecting \\nlogic belonging \\nto CPU and logic \\nbelonging to Re-\\ndundant CPU\\n(A) Physical sep-\\naration according \\nto technology \\ndesign rules for \\nisolation of stand-\\nard cells against \\nlatch-up\\n(A) Physical sep-\\naration related to \\nsoft error induced \\nlatch-up\\nAnalysis of \\ndesign rules\\nPhysical Lay-\\nout inspection\\nAfter the architectural enhancements resulting from the DFA the microcontroller component block \\ndiagram is updated to show:\\n\\xe2\\x80\\x94 the new Bandgap Monitor element to mitigate the dependent failures related to the Bandgap drift \\nfailure mode; and\\n\\xe2\\x80\\x94 the new Oscillator element to mitigate the dependent failures related to the Clock drift failure mode.\\n \\nTable B.1 (continued)\\n140 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure B.3 \\xe2\\x80\\x94 Enhanced microcontroller component\\nB.2 Analogue example\\nB.2.1 Description\\nThe analogue example is intended to provide guidance on the application of a DFA to analogue \\ncomponents, parts or subparts. The detailed failure modes, relevant DFI, safety requirements \\nand choices of considered safety and mitigation measures are typical examples, but they are not to \\nbe considered as exhaustive and can change depending on the details of the application, system \\narchitecture, circuit design and IC-technology.\\nThe DFA of an analogue part is explained in the following clauses based on an assumed architecture \\nof a switched output stage. The architecture of this output stage is sketched in Figure B.4 It uses high \\nvoltage N-DMOS switch transistors to activate the current path through a load which can for example \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n141\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nbe part of an actuator in a safety application. In order to avoid that faults of a switch transistor or its \\ngate driver can activate the actuator inadvertently, the switches are redundantly placed in the high side \\nand low side current paths to the load. The high side and low side drivers are supplied by a regulated \\nVreg Vdd which is significantly lower than the external supply Vbat coming from the board net connected \\nto the 12 V battery of the vehicle. The output of the supply voltage regulator is already monitored by a \\nvoltage monitor which is used for non-safety purposes like the provision of a power on reset. The gate \\nvoltage that is needed to turn on the high side N-DMOS switch transistor is delivered by a charge pump \\nin order to make the driver insensitive to EMC on the board net.\\nFigure B.4 \\xe2\\x80\\x94 Analogue output driver example\\nIn order to be able to identify dependent failure mechanisms, the following safety requirement is assumed: \\n\\xe2\\x80\\x9cIn the inactive state, the load connected between the high side switch transistor output and low side \\nswitch transistor output shall not be supplied with a current of more than 1 mA for longer than 1 ms\\xe2\\x80\\x9d.\\nNOTE \\nThe current of 1 mA is assumed to be much lower than the current that is drawn by the load in the \\ncase that the switches are turned on (e.g. 1 A).\\nB.2.2 Dependent failures by shared supply voltage regulator\\nThe primary fault that leads to the exemplary dependent failures is illustrated in Figure B.5. The supply \\nvoltage regulator, that supplies the internal driver circuitry for the control of the switch transistor \\ngate voltages, fails in a way that the pass device (pass device is the transistor that is in the supply \\ncurrent path) is permanently turned on. The fault mechanism could be a defect of the pass transistor \\nitself or a fault of the control loop that causes instability like e.g. loss of a compensation capacitor. The \\nconsequence is a rise of the internal supply level Vdd to the external supply level Vbat.\\n \\n142 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure B.5 \\xe2\\x80\\x94 Dependent failures by shared supply voltage regulator\\nThe fault is assumed to violate the safety requirement in the case of its appearance, since the complex \\ndriver circuit that we assume for this example cannot be realized in a way that allows operating it \\nshorted to the external supply.\\nThus, severe damage of the driver is assumed and the driver output cannot be assumed to keep the gate \\nvoltages of the switch transistors at a level that keeps the switch transistors in a high impedance state. \\nThus, the dependent failure that is caused by the \\xe2\\x80\\x9covervoltage\\xe2\\x80\\x9d that is applied to the supply of the driver \\nstages is assumed to have worst case consequences for the driver stages. Consequently, it propagates to \\nthe top level failure in the fault tree shown in Figure B.6.\\nIn quantitative safety analysis the SPFM of the \\xe2\\x80\\x9covervoltage\\xe2\\x80\\x9d failure mode of the supply voltage regulator \\n(not necessarily each failure mode of the supply voltage regulator e.g. under voltage) would be added \\ndirectly to the SPFM for violating the defined safety goal, as shown by the grey under laid base event for \\novervoltage from the Vdd supply voltage regulator connected to the top level \\xe2\\x80\\x9cOR\\xe2\\x80\\x9d gate in the FTA.\\nNOTE \\nThere are other dependent failures that could appear as a consequence of overvoltage delivered by the \\nsupply voltage regulator. The first one is a fault induced in the charge pump, which is shown as a dotted line in \\nthe block diagram. In the worst case this fault can have the same effect than a damage of the high side driver due \\nto overvoltage at its Vdd supply input and is therefore already included in the way the Vdd supply overvoltage fault \\nwas introduced in the FTA (see Figure B.6). Another dependent failure that could be induced by the overvoltage \\nis the damage of the voltage monitor which can cause that the overvoltage stays undetected; this will be handled \\nlater on in the discussion of the measures to mitigate the dependent failures of the gate drivers.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n143\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure B.6 \\xe2\\x80\\x94 FTA including shared supply\\nThe following freedom from interference requirement could be derived in order to assure the \\nachievement of the safety requirement for the case that the described fault in the supply voltage \\nregulator appears: \"A failure in the supply voltage regulator block shall not cause an activation of either \\nthe high side or the low side switch transistor in a way that the corresponding output could deliver a \\ncurrent of more than 1 mA to the load for longer than 1 ms.\"\\nTo achieve the freedom from interference, safety measures are defined in order to avoid a violation \\nof the safety goal in the case of a connection between the internal supply of the driver stages and the \\nexternal supply voltage Vbat. Examples of taken measures as shown in Figure B.7:\\n\\xe2\\x80\\x94 introduce subparts to pull down the switch transistor gate source voltages below their threshold \\nvoltages. The pull down blocks are activated by the supply monitoring block; and\\n\\xe2\\x80\\x94 limit of the current that can pass through the connection between the driver output and the switch \\ntransistor gate to assure that the pull down is able to keep the gate source voltage sufficiently low \\nfor the case of a short to the supply at the gate driver output.\\nAs a consequence of the introduction of the above mentioned safety mechanisms, the architecture \\nof the system is changed and a rise of the internal supply to the level of the board net is no longer \\ncausing a violation of the safety requirement by the initial dependent failures as long as the pull down \\nsubparts are activated. If there is no other cascading effect which could impact the function of this \\nsafety mechanism the mitigation of the dependent failures would be sufficient. The adaptation of the \\nfault tree according to the defined mitigation measures that result from the DFA is shown in Figure B.8.\\n \\n144 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure B.7 \\xe2\\x80\\x94 Shared supply fault mitigation\\nAn additional freedom from interference requirement is needed if the change of the architecture \\nintroduces other additional dependent failure mechanisms that could impact the effectiveness of the \\nnew safety mechanisms (a) and (b) that were introduced to mitigate the initial dependent fault. For this \\ncase the new freedom from interference requirement could be formulated as follows: \\xe2\\x80\\x9cA failure of the \\nsupply voltage regulator that shorts the internal supply Vdd to the external supply voltage Vbat shall not \\ncause a failure in the voltage monitor or a failure of the pull down blocks, which disables the pull down \\ncurrent paths in a way that the threshold of the switch transistors can be exceeded longer than 1 ms.\\xe2\\x80\\x9d\\nFor the achievement of this new freedom from interference requirement additional safety measures are \\ninstalled for the switch transistors. These pull down blocks are not affected by the initial fault (short of \\nthe internal supply Vdd to the external board net supply Vbat) in a way that prevents them from keeping \\nthe gates of the output switch transistor pulled down.\\nExample of taken measures:\\n\\xe2\\x80\\x94 introduction of a high voltage protection block for the supply monitor (a); and\\n\\xe2\\x80\\x94 design of the gate pull down dimensioned for operation at the external supply voltage (b).\\nFor this example it is assumed that the IC technology allows to implement these measures in a way that \\nprovides sufficient safety margin. This assumption is justifiable in a qualitative evaluation, since the \\nsupply monitor and the pull down blocks are small and can be realized in a way (e.g. increased channel \\nlength, cascaded HV transistors, serial resistors) that allows increased safety margin compared to the \\nsupply voltage regulator (higher absolute maximum rating for supply voltage). Of course the safety \\nrequirements, fault mechanisms and suggested mitigation method are just exemplary and based on \\nassumptions of the following boundary conditions:\\n\\xe2\\x80\\x94 a circuit architecture;\\n\\xe2\\x80\\x94 application requirements; and\\n\\xe2\\x80\\x94 capabilities of an IC technology which will be used to fabricate the circuit.\\nThe aim of the example is to explain how to perform a DFA of an analogue part and not as reference \\nfor the mitigation of dependent failures caused by overvoltage faults of the supply voltage regulator \\nin real switched output stages. Other methods or variants to mitigate the same fault can be used \\ndepending on the final knowledge of the real boundary conditions (e.g. technology options, external \\nsafety mechanisms). Finally, a latent fault analysis is performed on the new elements that have been \\nintroduced to mitigate the dependent failures caused by the supply overvoltage. The analysis could \\nidentify the need to test them in repeated time intervals (e.g. at each system start-up).\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n145\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure B.8 \\xe2\\x80\\x94 FTA including shared supply fault mitigation\\nB.2.3 Dependent failures by coupling mechanism\\nThe primary fault that leads to the second exemplary dependent failure is illustrated in Figure B.9. It is \\na random hardware fault that appears in the high side driver. It leads to a failure of the high side path, \\nwhich results in a conductance of the high side switch transistor. It further activates a coupling effect \\nthat can initiate a dependent failure in the low side path.\\n \\n146 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure B.9 \\xe2\\x80\\x94 Dependent failures by coupling mechanism\\nAn independence requirement could be stated as: \\xe2\\x80\\x9cA failure of the high side path shall not induce a \\nfailure in the low side path that leads to an activation of the low side switch transistor in a way that \\nit can deliver more than 1 mA.\\xe2\\x80\\x9d As a result of the evaluation of the DFI list, the following relevant \\ninitiators (see Table B.2) and their corresponding coupling mechanisms that require a definition of \\nspecial mitigation measures are identified.\\nNOTE \\nThis is an example and does of course not imply that these 3 DFI are the only relevant for gate drivers.\\nFor each dependent failure listed in Table B.2, the fault tree in Figure B.10 is used. It shows that besides \\nindependent random faults in every channel, a coupling between the channels can lead to a fault in the \\nsecond channel that is not directly affected by the initial fault.\\nIn the case of temperature increases (reference number 1 in Table B.2) or break down of the supply \\n(reference number 2 in Table B.2) the dependent failures can be avoided by implementation of a safety \\nmechanism that detects the coupling effect and brings the system or element into a safe state. In the \\ncase of the substrate current injection (reference number 3 in Table B.2) mitigation could be achieved \\nby technology and/or layout measures that break the coupling mechanism.\\nTable\\tB.2\\t\\xe2\\x80\\x94\\tExample\\tof\\tidentified\\trelevant\\tcoupling\\tmechanisms\\nReference number\\nDFI\\nCoupling mechanism\\n1\\nLocal hot spot in one of the gate driver \\ncircuits (e.g. caused by a defect of a \\ndevice inside the gate driver block that \\nheats up due to increased power con-\\nsumption of the defective device).\\nHeat propagation via the substrate causes \\nan exceedance of the maximum rating of the \\ntemperature range of the other gate driver.\\n2\\nShort circuit in one of the gate drivers \\nleading to current consumption above \\nthe specification of the supply voltage \\nregulator.\\nBreak down of the supply of the other gate \\ndriver causes an undefined state (neither \\nwithin the operating range nor in the range \\nthat leads to power on reset).\\n3\\nInjection of current into the substrate \\nwithin one of the gate drivers e.g. \\ncaused by defects of substrate pn \\njunctions or by activation of parasitic \\nbipolar transistor of power devices.\\nLatch up induced including circuit elements \\nof the other gate driver due to increasing \\nvoltage drop along the path of the substrate \\ncurrent to GND.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n147\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure B.10 \\xe2\\x80\\x94 Fault tree including coupling effect\\nIn order to achieve a mitigation of the identified dependent failures, additional safety mechanisms are \\ndefined in Table B.3.\\nNOTE \\nThe mitigation of the dependent failures can require one or a combination of the mitigation measures, \\na final proof of the evidence of the chosen measures is made available with respect to the real design, layout, \\ntechnology, package and application.\\n \\n148 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable B.3 \\xe2\\x80\\x94 Examples for the mitigation of coupling effects\\nReference number\\nDependent failures mitigation\\n1\\nTemperature measurement in the proximity of the gate drivers (the acceptable dis-\\ntance depends on the thermal resistance of the heat sink path and can be found by \\nthermal simulation, sensor elements can be resistors or bipolar transistors) and shut \\ndown of the gate driver supply in the case of over temperature.\\nCurrent limitation in the supply voltage regulator to limit the power that is available \\nto heat up the chip and brings it into a defined under voltage reset state.\\nA thermal segregation (e.g. sufficient distance in combination with a backside heat \\nsink via an exposed die pad) of the independent paths (high side & low side path, each \\nconsisting of a switch transistor and its associated gate driver) that is sufficient to \\nprevent the overheating of the fault free path (the one that is not affected by the initial \\nfault). Dimension of the required segregations can be evaluated (e.g. based on thermal \\nsimulations).\\n2\\nCurrent measurement of the block supplies and shut down of the gate driver supply in \\nthe case of overcurrent.\\nVoltage monitor with under voltage reset that avoids undefined states by setting the \\nreset threshold inside the safe operation range of the circuit.\\nPassive pull down of the gates e.g. with resistors to keep switch transistors in off state \\nif the supply is low.\\n3\\nPhysical separation (e.g. spacing, guard rings, separate wells, trenches, buried layer, \\nsinkers \\xe2\\x80\\x94 depending on the IC technology) with the target to interrupt the latch up \\nmechanisms between the parts that are claimed to be independent.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n149\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nAnnex C \\n(informative) \\n \\nExamples of quantitative analysis for a digital component\\nC.1 Description\\nThe following is an example of a quantitative analysis using the method described in 5.1.7.\\nNOTE 1 \\nNumbers used in this example (e.g. failure rates, amount of safe faults and failure mode coverage) are \\nexamples. They can vary from architecture to architecture.\\nNOTE 2 \\nThe following examples divide a portion of the digital component into the subparts level. As discussed \\nin 5.1.7, the necessary level of detail can depend on the stage of the analysis and on the safety mechanisms used.\\nNOTE 3 \\nThe following examples use the quantitative approach to compute a dedicated target \\xe2\\x80\\x9csingle-\\npoint fault metric\\xe2\\x80\\x9d value for transient faults. As discussed in 5.1.7.2, transient faults can be also addressed by \\nqualitative rationale. The rationale includes the reason why the qualitative approach is adequate.\\nThe example considers a small portion of a digital component, i.e. only two parts:\\n\\xe2\\x80\\x95 \\na small CPU, divided in five subparts: register bank, ALU, load-store unit, control logic and debug. \\nEach subpart is further divided in several subparts; and\\n\\xe2\\x80\\x95 \\n16 KB of RAM divided in three subparts: cell array, address decoder and logic for end-of-line test, \\nand management of spare rows (redundancies) of RAM.\\nNOTE 4 \\nThe FIT numbers shown in the example do not include peripherals or other features such as package, \\nhandling or overstress. They are given just as an example of a possible method for FIT rate computation. For this \\nreason, those values are not comparable with FIT rates of a complete packaged digital component as shown for \\nexample in SN 29500.\\nNOTE 5 \\nThe aim of the following example is to avoid a requirement that each smallest digital component \\nsubpart be addressed in the system-level analysis. At system-level analysis, component or part level detail can \\nbe sufficient. The aim of this example is to provide evidence that for a digital component at stand-alone level, a \\ndeeper analysis (e.g. at subpart level) can be needed in order to compute with the required accuracy the failure \\nrates and failure mode coverage of parts and subparts, to be used afterwards by system engineers. In other \\nwords, without an accurate and detailed digital component stand-alone level analysis, it can be very difficult to \\nhave good data for system-level analysis.\\nThe following four safety mechanisms are considered:\\n\\xe2\\x80\\x95 \\na hardware safety mechanism (SM1) performing logical monitoring of the program sequence of the \\nCPU. This safety mechanism is able to detect with certain coverage the faults in the control logic \\nthat could cause the software to run out of sequence. However, this safety mechanism is poor at \\ndetecting faults (such as wrong arithmetic operations) leading to wrong data;\\nNOTE 6 \\nIn this example, it is assumed that each detected permanent single bit fault affecting the CPU is \\nsignalled to the system (e.g. by activating an output signal of the digital component). As a consequence of \\nthis assumption, the failure mode coverage w.r.t. latent faults can be assumed 100 % in alignment with what \\nis described in ISO 26262-5. A requirement is set at system or element level to make proper use of this signal \\n(e.g. to enter a safe state and inform the driver). For suspect transient faults, the CPU can try to remove these \\nfaults by a reset. If the fault persists, it means it is permanent, and therefore it can be signalled to the system \\nas previously described. If the fault disappears (i.e. it was really transient), the CPU can continue.\\n\\xe2\\x80\\x95 \\na software-based safety mechanism (SM2) addressing random hardware failures executed at key-\\non to verify the absence of latent faults in the logical monitoring of the program sequence of the \\nCPU (SM1);\\n \\n150 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n\\xe2\\x80\\x95 \\nan error detection-correction logic ECC (SM3) with the capability to correct all single bit faults \\n(single error correction, SEC) and detect all double bit faults (double error detection, DED) for the \\nRAM; and\\nNOTE 7 \\nIn this example, it is assumed that each detected permanent single bit fault \\xe2\\x80\\x94 even if corrected \\nby the ECC \\xe2\\x80\\x94 is signalled to the software (e.g. by an interrupt), and the software reacts accordingly. As \\na consequence of this assumption, the failure mode coverage w.r.t. latent faults can be assumed 100 % in \\nalignment with what is described in ISO 26262-5. A requirement is set at system or element level to make \\nproper use of this event (e.g. to go into a safe state and inform the driver). For suspected transient faults \\ncorrected by ECC, the CPU can try to remove these faults by writing back in the memory the correct value. If \\nthe fault persists, it means it is permanent and therefore is signalled to the system as previously described. \\nIf the fault disappears (i.e. it was transient), the CPU can continue. To distinguish intermittent and transient \\nfaults, counting numbers of corrections could be a possible method.\\n\\xe2\\x80\\x95 \\na software-based safety mechanism (SM4) addressing random hardware failures executed at key-\\non to verify the absence of latent faults in the ECC (SM3).\\nFigure C.1 is divided in three separate calculations for better visibility.\\nFigure C.1 gives the view of failure modes at subparts level. Figure C.2 shows how the low-level failure \\nmodes can be identified and therefore how the overall failure distribution can be computed, following \\nthe approach described in 4.4.\\nEXAMPLE 1 \\nThe table shows that the failure rate of a permanent fault in the flip-flop X1 and its related fan-in is \\n0,01 FIT. Summing each of those low-level failure modes, it is possible to compute the failure rate of a permanent \\nfault of the ALU logic as a whole (0,0348 FIT). With the same procedure, by summing up each of the failure rates \\nrelated to the subpart, it is possible to compute the FIT rate for a permanent fault in the ALU.\\nNOTE 8 \\nGoing up in the failure modes abstraction tree (i.e. from the low-level failure modes to the higher \\nones), failure rates of different subparts\\xe2\\x80\\x99 failure modes could be combined to compute the failure rate for the \\nhigher-level failure mode, especially if those higher-level failure modes are defined in a more generic way.\\nEXAMPLE 2 \\nIf a higher-level failure mode (e.g. at part-level) is defined as \\xe2\\x80\\x9cwrong instruction processed by \\nCPU\\xe2\\x80\\x9d, the failure rate of this failure mode can be a combination of the failure rates of many failure modes at \\nsubparts level, such as a permanent fault in the pipeline, a permanent fault in the register bank, etc. Therefore, if \\nthe low-level failure rates are available, the higher-level failure rate can be computed with a bottom-up approach \\n(assumes independent faults).\\nNOTE 9 \\nColumns of tables can be correlated to the flow diagram for fault classification and fault class \\ncontribution calculation described in ISO 26262-10 [61]:\\n\\xe2\\x80\\x95 \\nfailure rate (FIT) is equal to \\xce\\xbb;\\n\\xe2\\x80\\x95 \\namount of safe faults is equal to Fsafe;\\n\\xe2\\x80\\x95 \\nfailure mode coverage with respect to violation of safety goal is equal to KFMC,RF;\\n\\xe2\\x80\\x95 \\nresidual or single-point fault failure rate is equal to \\xce\\xbbSPF or \\xce\\xbbRF depending on whether the failure is single-point \\nor residual. In the example, no single-point faults are considered, so this failure rate is always equal to \\xce\\xbbRF;\\n\\xe2\\x80\\x95 \\nfailure mode coverage with respect to latent failures is equal to KFMC,MPF; and\\n\\xe2\\x80\\x95 \\nlatent multiple-point fault failure rate is equal to \\xce\\xbbMPF.\\nNOTE 10 The amount of safe faults is the fraction of the failure mode that has neither the potential to violate the \\nsafety goal in absence of safety mechanisms nor in combination with independent failures of another subpart.\\nNOTE 11 The failure mode coverage is computed with a detailed analysis of the capability of SM1 to cover each \\nsubpart. In this example, R0 and R1 are registers chosen by the compiler to pass function parameters, so they \\nhave a slightly higher probability to cause a program sequence error detectable by SM1. The aim of this example \\nis to provide evidence that by means of a detailed analysis, it is possible to identify differences in the coverage of \\nthe subparts.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n151\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nNOTE 12 The failure mode coverage of the ECC (SM3) is computed, for example, with a detailed analysis \\ncombining the high probability of ECC of detecting single and double bit errors with the lower probability of \\ndetection (it could be less than 90 %) of multiple-bit errors. This is shown in Figure C.2.\\nNOTE 13 Certain subparts can be covered by several safety mechanisms: in such cases, the resulting failure \\nmode coverage combines the coverage for each failure mode determined by means of a detailed analysis.\\nNOTE 14 \\nThe example shows that without proper coverage of the ECC (SM3) with respect to multiple bit errors \\nand without the coverage of the RAM address decoder, it can be difficult to achieve a high single-point fault metric.\\nNOTE 15 The example shows that some safety mechanisms can cause a direct violation of the safety goal, and \\ntherefore they are considered in the computation of residual faults. In this example, a fault in the ECC (SM3) can \\ncorrupt the mission data without a corresponding fault in the memory.\\nNOTE 16 The example shows that, in a digital component, subparts could coexist which potentially are not \\nsafety-related but for which it is impossible to establish a clear separation or distinction from the safety-related \\nsubparts (the debug inner logic). Instead, other parts (the debug interface) could be easily isolated and disabled \\nin a way that they can be considered not safety-related without risks.\\nNOTE 17 The amount of safe faults is determined according to the classification method described in \\nISO 26262-10 [61]. These calculations can be done, for example, with design analysis or fault injection simulation. \\nThis represents the case that certain low-level failure modes (e.g. a single-event upset and single-event transient \\nfault in flip-flop X2 and its fan-in) are safe (e.g. because that bit is seldom used by the ALU architecture).\\nNOTE 18 The failure rate of the memory for a single permanent fault causing n>2 bit errors is computed, for \\nexample, considering memory layout information, structure of the address decoder, etc.\\nNOTE 19 The ECC (SM3) coverage for >2 bit errors is computed with a detailed analysis considering the number \\nof bits in each coded word (in this case 32) and the number of code bits (in this case 7). Depending on those \\nparameters, coverage can be much higher.\\n \\n152 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b' \\nISO 26262-11:2018(E)\\nFigure C.1 \\xe2\\x80\\x94 Example of quantitative analysis (at subparts level)\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n153\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure C.2 \\xe2\\x80\\x94 Example of quantitative analysis (at low-level failures level)\\n \\n154 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nAnnex D \\n(informative) \\n \\nExamples of quantitative analysis for analogue component\\nD.1 Description\\nThe following is an example of a quantitative analysis using the method described in 5.2.3 in order \\nto calculate the single-point fault metric and the latent-fault metric for a given safety requirement \\nallocated to the mixed signal hardware element depicted in Figure D.1.\\nThe example consists of a mixed signal hardware element composed of:\\n\\xe2\\x80\\x95 \\na low drop voltage regulator (low drop voltage regulator in Figure D.2) providing an output voltage \\nwithin a prescribed range;\\n\\xe2\\x80\\x95 \\na voltage monitor (voltage monitor in Figure D.3) capable of detecting overvoltage (VA > OVth) and \\nunder-voltage (VA < UVth) on the LDO output by monitoring the regulated voltage VA and comparing \\nit with two predefined thresholds; the predefined thresholds are generated from a reference \\nvoltage provided by an independent bandgap (voltage bandgap2 in Figure D.3) in order to ensure \\nindependence with respect to the voltage regulator;\\n\\xe2\\x80\\x95 \\nan analogue BIST controlled through the digital system (the digital controller is not depicted in the \\nblock diagram in Figure D.1); and\\n\\xe2\\x80\\x95 \\nan ADC channel.\\nThe ASIL B safety requirement is: \"The regulated voltage output does not go out of regulation, i.e. the \\nregulated voltage VA is not outside the UVth-OVth range for more than 1 ms.\"\\nThe component can be considered in a safe state when an out of regulation condition is detected \\nand signalled to an external element of the system/item. The external system is responsible for fault \\nreaction including transitioning the system or element to a safe state.\\nAs shown in Figure D.3 the voltage monitor is composed of two voltage comparators, a passive network \\nand a bandgap; the low drop regulator includes a bandgap, a current limiter, the bias generator and the \\nregulator core as shown in Figure D.2.\\nThe ADC is included in the mixed signal hardware element but it is not used for any function related \\nto the safety requirement and so its potential failure cannot contribute to the violation of such \\nrequirement; therefore the ADC is assumed not safety-related.\\nThe following safety mechanisms are considered:\\n\\xe2\\x80\\x95 \\nthe voltage monitor detecting overvoltage (safety mechanism SM2) and under-voltage (safety \\nmechanism SM1) failures with a diagnostic coverage of 99,9 %. The safety mechanism is described \\nin 5.2.4.2.\\n\\xe2\\x80\\x95 \\nthe analogue BIST detecting failures affecting the voltage monitor with a diagnostic coverage of \\n60 % (safety mechanism SM6). The safety mechanism is described in 5.2.4.10.\\nThe coverage levels claimed by the safety mechanisms are reported in Table D.1. They are assumed to \\nbe proven with simulations, testing to characterize and confirm the behaviour of the silicon and the \\nrelated evidences are documented in the product safety case. It is out of the scope of this example to \\nprovide those evidences.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n155\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nEach safety mechanism signals the detection of a fault to an element of the system/item which is then \\nresponsible to transition the system or element to a safe state.\\nUnder this assumption, the failure mode coverage with respect to latent failures related to the low drop \\nregulator is claimed to be 100 % based on the example in ISO 26262-5:2018, Annex E.\\nFigure D.1 \\xe2\\x80\\x94 Example of analogue and mixed signal hardware element (circuit under analysis)\\nFigure D.2 \\xe2\\x80\\x94 Detailed block diagram of the low drop regulator part\\nFigure D.3 \\xe2\\x80\\x94 Detailed block diagram of the voltage monitor part\\n \\n156 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable D.1 \\xe2\\x80\\x94 Safety mechanisms considered in the example and related coverage for \\nhardware element\\nID\\nSafety mechanism\\nClaimed failure mode coverage\\nSM1\\nUnder-voltage (UV) Monitor\\n99,9 %\\nSM2\\nOver-voltage (OV) Monitor\\n99,9 %\\nSM6\\nAnalogue BIST diagnostics\\n60 %\\nNOTE 1 \\nThe example shows that parts which could be easily isolated and disabled in a way that they can be \\nconsidered not safety-related without risk, can coexist with parts that are safety-related.\\nNOTE 2 \\nThe effectiveness of safety mechanisms could be affected by dependent failures. Adequate measures \\nare considered as described in 5.2.3.6.\\nBased on the guidelines provided in 5.2.3, the failure rates and the metrics can be computed in the \\nfollowing way for analogue and mixed signal hardware elements:\\n\\xe2\\x80\\x95 \\nfirst, the hardware element is divided into parts or subparts;\\nNOTE 3 \\nThe validity of assumptions on the independence of identified parts is established during the \\ndependent failure analysis.\\nNOTE 4 \\nThe necessary level of detail (e.g. if analysis at part level or subpart level) can depend on the \\nstage of the analysis and on the safety mechanisms.\\n\\xe2\\x80\\x95 \\nsecond, the failure rates of each part or subpart can be computed using one of the methods \\ndescribed in 4.6.2.4 and 5.2.3.3;\\nNOTE 5 \\nIn this example the failure rate distribution is assumed to be proportional to the area both for \\npermanent and transient faults using the values reported in Table D.6.\\n\\xe2\\x80\\x95 \\nfor each part/subpart the relevant failure modes are listed and a failure mode distribution is \\nassigned to each of them;\\nNOTE 6 \\nThe failure mode distribution in the examples of Table D.2 and Table D.3 is considered equally \\ndistributed over the failure modes belonging to each part/subpart. This assumption is understood as \\nreference only, valid for the specific examples.\\n\\xe2\\x80\\x95 \\nthe evaluation is completed by classifying the faults into safe faults, residual faults, detected dual-\\npoint faults and latent dual-point faults; and\\n\\xe2\\x80\\x95 \\nfinally, the failure mode coverage with respect to residual and latent faults of that part or subpart is \\ndetermined.\\nNOTE 7 \\nNumbers used in this example (e.g. failure rates, amount of safe faults and failure mode coverage) \\ncan vary from architecture to architecture.\\nThe example of quantitative analysis, limited to permanent faults, is reported in Table D.2 and \\nTable D.3 using the same format as Figure C.1. The quantitative analysis gives the view of failure modes \\nat subpart level.\\nNOTE 8 \\nIn this example a separate analysis with respect to transient faults is not reported but it can be added \\nwhen relevant.\\nDepending on the system functions and safety requirements, different operating phases can be relevant \\nand so additional failure modes can be considered.\\nEXAMPLE \\nFor systems that need to comply with start-stop requirements, the regulator start phase can be \\nsafety-related and the failure mode \"Incorrect start-up time (i.e. outside the expected range) \\xe2\\x80\\x94 Voltage ramp too \\nfast\" can be added.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n157\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nTable D.2 \\xe2\\x80\\x94 Example of quantitative analysis \\xe2\\x80\\x94 mission parts\\nPart\\nSubpart\\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent or \\nNot \\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent\\nFailure Mode\\nPotential Effect of \\nFailure Mode in  \\nAbsence of Safety \\nMechanism (SM) on \\nIC levela\\nFault \\nMod-\\nelb\\nFailure \\ndistribu-\\ntion\\nFailure \\nrate (FIT)\\nAmount \\nof Safe \\nFaults\\nSafety \\nmecha-\\nnism(s) \\nprevent-\\ning the \\nviola tion \\nof the \\nsafety \\nrequire-\\nment\\nFailure \\nmode cov-\\nerage with \\nrespect to \\nviolation \\nof safety re-\\nquirement\\nResidual or \\nSingle Point \\nFault \\nfailure \\nrate/FIT\\nSafety \\nmecha-\\nnism(s) \\nto \\npre vent \\nlatent \\nfaults\\nFailure \\nmode cov-\\nerage with \\nrespect to  \\nlatent fail-\\nures\\nLatent Mul-\\ntiple Point \\nFault \\nfailure \\nrate/FIT\\nLinear \\nVoltage \\nRegula-\\ntor\\nLow \\nDrop \\nRegula-\\ntor\\nSR\\nOutput voltage high-\\ner than a predefined \\nhigh threshold of the \\nprescribed range (i.e. \\nOver voltage \\xe2\\x80\\x94 OV)\\nRegulated voltage \\nhigher than VA_OV\\nP\\n14 %\\n2,16E-03\\n0 %\\nSM2\\n99,9 %\\n2,16E-06\\nSM2\\n100 %\\n0,0E+00\\nSR\\nOutput voltage lower \\nthan a predefined \\nlow threshold of the \\nprescribed range (i.e. \\nUnder voltage \\xe2\\x80\\x94 UV)\\nRegulated voltage \\nlower than VA_UV\\nP\\n14 %\\n2,16E-03\\n0 %\\nSM1\\n99,9 %\\n2,16E-06\\nSM1\\n100 %\\n0,0E+00\\n \\n \\nSR\\nOutput voltage af-\\nfected by spikes\\nRegulated voltage \\nout of the expected \\nrange (VA_UV-VA_OV)\\nP\\n14 %\\n2,16E-03\\n0 %\\nSM1 SM2\\n99,9 %\\n2,16E-06\\nSM1 SM2\\n100 %\\n0,0E+00\\n \\n \\nSR\\nOutput voltage \\noscillation within the \\nprescribed range\\nNo effect- Regulated \\nvoltage within the \\nexpected range but \\nwith low accuracy\\nP\\n14 %\\n2,16E-03\\n100 %\\n0,0E+00\\n0,0E+00\\n \\n \\nSR\\nOutput voltage fast \\noscillation outside \\nthe prescribed range \\nbut with average \\nvalue within the \\nprescribed range\\nRegulated voltage \\nout of the expected \\nrange (VA_UV-VA_OV)\\nP\\n14 %\\n2,16E-03\\n0 %\\nSM1 SM2\\n99,9 %\\n2,16E-06\\nSM1 SM2\\n100 %\\n0,0E+00\\n \\n \\nSR\\nOutput voltage drift \\nwithin the pre-\\nscribed range\\nNo effect- Regulated \\nvoltage within the \\nexpected range but \\nwith low accuracy\\nP\\n14 %\\n2,16E-03\\n100 %\\n0,0E+00\\n0,0E+00\\n \\n \\nSR\\nIncorrect start-up \\ntime (i.e. outside the \\nexpected range) \\xe2\\x80\\x94 \\nVoltage ramp too fast\\nno effect \\xe2\\x80\\x94 as-\\nsuming during the \\nvoltage regulator \\nstart up the item is \\nin safe state\\nP\\n0 %\\n0,00E+00\\n100 %\\n0,00E+00\\n0,0E+00\\n \\n \\nSR\\nIncorrect start-up \\ntime (i.e. outside the \\nexpected range) \\xe2\\x80\\x94 \\nVoltage ramp too \\nslow\\nno effect \\xe2\\x80\\x94 as-\\nsuming during the \\nvoltage regulator \\nstart up the item is \\nin safe state\\nP\\n0 %\\n0,00E+00\\n100 %\\n0,00E+00\\n0,0E+00\\n158 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nPart\\nSubpart\\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent or \\nNot \\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent\\nFailure Mode\\nPotential Effect of \\nFailure Mode in  \\nAbsence of Safety \\nMechanism (SM) on \\nIC levela\\nFault \\nMod-\\nelb\\nFailure \\ndistribu-\\ntion\\nFailure \\nrate (FIT)\\nAmount \\nof Safe \\nFaults\\nSafety \\nmecha-\\nnism(s) \\nprevent-\\ning the \\nviola tion \\nof the \\nsafety \\nrequire-\\nment\\nFailure \\nmode cov-\\nerage with \\nrespect to \\nviolation \\nof safety re-\\nquirement\\nResidual or \\nSingle Point \\nFault \\nfailure \\nrate/FIT\\nSafety \\nmecha-\\nnism(s) \\nto \\npre vent \\nlatent \\nfaults\\nFailure \\nmode cov-\\nerage with \\nrespect to  \\nlatent fail-\\nures\\nLatent Mul-\\ntiple Point \\nFault \\nfailure \\nrate/FIT\\n \\n \\nSR\\nQuiescent current \\n(i.e. current drawn \\nby the regulator in \\norder to control its \\ninternal circuitry for \\nproper operation) \\nexceeding the maxi-\\nmum value\\nRegulated voltage \\npotentially with low \\naccuracy or out of \\nregulation depend-\\ning on the actual \\nquiescent current\\nP\\n14 %\\n2,16E-03\\n50 %\\n1,08E-03\\nSM1 SM2\\n100 %\\n0,0E+00\\nADC\\nADC\\nNSR\\nP\\n100 %\\n7,00E-03\\n0,0E+00\\n0,0E+00\\n\\xce\\xa3\\n0,00109\\n0,0E+00\\nTotal failure rate\\n0,022 1\\nTotal Safety-related\\n0,015 1\\nTotal Not Safety-related\\n0,007 0\\nSingle-Point Fault Metric\\n92,8 %\\nLatent-Fault Metric\\n100 %\\na   Depending on complexity it can be beneficial to have a dedicated entry in the FMEA giving more details about the potential root causes and the end effect of each failure mode.\\nb   Fault model can be permanent fault (P) or transient fault (T); the example is limited to permanent faults.\\nTable D.2 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n159\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nTable D.3 \\xe2\\x80\\x94 Example of quantitative analysis \\xe2\\x80\\x94 safety mechanisms\\nPart\\nSub-\\npart\\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent or \\nNot Safe-\\nty-re-\\nlated \\nCompo-\\nnent\\nFailure Mode\\nPotential Effect of \\nFailure Mode in  \\nAbsence of Safety \\nMechanism (SM) on \\nIC levela\\nFault \\nMod-\\nelb\\nFailure \\ndistribu-\\ntion\\nFailure \\nrate (FIT)\\nAmount \\nof Safe \\nFaults\\nSafety \\nmecha-\\nnism(s) \\nprevent-\\ning the \\nviolation \\nof the \\nsafety \\nrequire-\\nment\\nFailure \\nmode cov-\\nerage with \\nrespect to \\nviolation \\nof safety re-\\nquirement\\nResidual or \\nSingle Point \\nFault \\nfailure \\nrate/FIT\\nSafety \\nmecha-\\nnism(s) \\nto \\npre vent \\nlatent \\nfaults\\nFailure \\nmode cov-\\nerage with \\nrespect to  \\nlatent fail-\\nures\\nLatent Mul-\\ntiple Point \\nFault \\nfailure \\nrate/FIT\\nLinear \\nVoltage \\nRegula-\\ntor\\nVoltage \\nMonitor \\n(SM1, \\nSM2)\\nSR\\nUV Monitor (SM1) \\nfalsely triggering \\nUV event\\nNuisance shutdown \\nat nominal regulator \\nloads.\\nP\\n25 %\\n1,45E-03\\n100 %\\n0,0E+00\\n \\n \\nSR\\nUV Monitor (SM1) \\nnot triggering valid \\nUV event\\nRegulated voltage \\nlower than VA_UV\\nP\\n25 %\\n1,45E-03\\n0 %\\nSM6\\n60 %\\n5,80E-04\\n \\n \\nSR\\nOV Monitor (SM2) \\nfalsely triggering \\nOV event\\nNuisance shutdown \\nat nominal regulator \\nloads.\\nP\\n25 %\\n1,45E-03\\n100 %\\n0,0E+00\\n \\n \\nSR\\nOV Monitor (SM2) \\nnot triggering valid \\nOV event\\nRegulated voltage \\nhigher than VA_OV\\nP\\n25 %\\n1,45E-03\\n0 %\\nSM6\\n60 %\\n5,80E-04\\nAnalog \\nBIST\\nAnalog \\nBIST\\n(SM6)\\nSR\\nAnalogue BIST \\n(SM6) falsely detects \\nmisbehaviour of \\nthe linear voltage \\nregulator\\nNo effectc\\nP\\n50 %\\n3,50E-03\\n100 %\\n0,0E+00\\n160 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nPart\\nSub-\\npart\\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent or \\nNot Safe-\\nty-re-\\nlated \\nCompo-\\nnent\\nFailure Mode\\nPotential Effect of \\nFailure Mode in  \\nAbsence of Safety \\nMechanism (SM) on \\nIC levela\\nFault \\nMod-\\nelb\\nFailure \\ndistribu-\\ntion\\nFailure \\nrate (FIT)\\nAmount \\nof Safe \\nFaults\\nSafety \\nmecha-\\nnism(s) \\nprevent-\\ning the \\nviolation \\nof the \\nsafety \\nrequire-\\nment\\nFailure \\nmode cov-\\nerage with \\nrespect to \\nviolation \\nof safety re-\\nquirement\\nResidual or \\nSingle Point \\nFault \\nfailure \\nrate/FIT\\nSafety \\nmecha-\\nnism(s) \\nto \\npre vent \\nlatent \\nfaults\\nFailure \\nmode cov-\\nerage with \\nrespect to  \\nlatent fail-\\nures\\nLatent Mul-\\ntiple Point \\nFault \\nfailure \\nrate/FIT\\n \\nSR\\nAnalogue BIST \\n(SM6) does not \\ndetect misbehaviour \\nof the linear voltage \\nregulator\\nNo effectc\\nP\\n50 %\\n3,50E-03\\n100 %\\n0,0E+00\\n\\xce\\xa3\\n1.16E-03\\nTotal failure rate\\n0,012 80\\nTotal Safety-related\\n0,012 80\\nTotal Not Safety-related\\n0,000 00\\nSingle-Point Fault Metric\\n100 %\\nLatent-Fault Metric\\n90,0 %\\na   Depending on complexity it can be beneficial to have a dedicated entry in the FMEA giving more details about the potential root causes and the end effect of each failure mode.\\nb   Fault model can be permanent fault (P) or transient fault (T); the example is limited to permanent faults.\\nc   It requires more than two faults before it becomes safety-related: #1 fault: Failure on main safety mechanism (SM1, SM2 or SM6), #2 fault: LDO out of regulation, #3 fault: BIST Diagnostic failure.\\nTable D.3 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n161\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nCombining together the results of Table D.2 and Table D.3, the overall values are:\\n\\xe2\\x80\\x95 \\nSingle-Point Fault Metric = 96,1 %; and\\n\\xe2\\x80\\x95 \\nLatent-Fault Metric = 95,7 %.\\nThe following example considers the benefit of finer subpart granularity for the same hardware element \\nwith a more stringent safety requirement: \"The accuracy and the stability of the regulated voltage is \\nsuch that VA < VA0+\\xe2\\x88\\x86 and VA > VA0-\\xe2\\x88\\x86 where VA0 is within Vmin \\xe2\\x80\\x93 Vmax and \\xe2\\x88\\x86 = 5mV.\"\\nThe component can be considered in a safe state when the low accuracy/stability condition is detected \\nand signalled to an external element of the system/item. The external system is responsible for fault \\nreaction including transitioning the system or element to a safe state.\\nThe example of quantitative analysis limited to permanent faults is reported in Table D.5 using the \\nsame format as Figure C.1. The safety mechanisms considered in the analysis are:\\n\\xe2\\x80\\x95 \\nthe voltage monitor detecting overvoltage (safety mechanism SM2) and under-voltage (safety \\nmechanism SM1) failures;\\n\\xe2\\x80\\x95 \\nthe independent ADC channel detecting variation of the regulated voltage higher than \\xe2\\x88\\x86\\xc2\\xa0= 5mV \\n(safety mechanism SM3). The safety mechanism is described in 5.2.4.11;\\n\\xe2\\x80\\x95 \\na current limiter detecting failures affecting circuits supplied by the low drop voltage regulator \\n(safety mechanism SM5). The safety mechanism is described in 5.2.4.5; and\\n\\xe2\\x80\\x95 \\nan analogue BIST detecting failures affecting the voltage monitor.\\nNOTE 8 \\nEvidence is provided to show the independence of the current limiter with respect to the regulator core.\\nNOTE 9 \\nThe ADC used as safety mechanism SM3 is assumed to be external to the hardware element under \\nanalysis and so it is not considered in the FMEA. There is an ADC included in the hardware element which is not \\nSM3: It is therefore reported in the FMEA as not safety-related.\\nThe coverage levels claimed by the safety mechanisms are reported in Table D.4.\\nTable D.4 \\xe2\\x80\\x94 Safety mechanisms considered in the example with the new safety requirement\\nID\\nSafety mechanism\\nClaimed failure mode coverage\\nSM1\\nUnder-voltage (UV) Monitor\\n99,9 %\\nSM2\\nOver-voltage (OV) Monitor\\n99,9 %\\nSM3\\nIndependent ADC monitoring\\n97 %\\nSM5\\nCurrent limiter\\n98 %\\nSM6\\nAnalogue BIST diagnostics\\n90 %\\nNOTE 10 The effectiveness of safety mechanisms could be affected by dependent failures. Adequate measures \\nare considered as described in 5.2.3.6.\\nMoreover, each safety mechanism signals the detection of a fault to an external element of the system/\\nitem which is then responsible to transition the system or element to a safe state.\\nUnder this assumption, the failure mode coverage with respect to latent failures related to the mission \\ncircuit is claimed to be 100 % according to ISO 26262-5:2018, Annex E.\\nTable D.5 shows the quantitative analysis for the mission part conducted at a finer level of granularity \\nthan the one in Table D.2 and Table D.3. The examples show that a different safety requirement impacts \\nthe level of partitioning and the diagnostic coverage requirement for one or more safety mechanisms.\\nNOTE 11 In this example the analysis with respect to transient faults is not reported but it can be added when \\nrelevant.\\n \\n162 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nTable\\tD.5\\t\\xe2\\x80\\x94\\tExample\\tof\\tquantitative\\tanalysis\\tin\\tthe\\tcase\\tof\\tfine\\tgranularity\\t\\xe2\\x80\\x94\\tmission\\tparts\\nPart\\nSubpart\\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent or \\nNot \\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent\\nFailure Mode\\nPotential Effect of \\nFailure Mode in  \\nAbsence of Safety \\nMechanism (SM) on \\nIC levela\\nFault \\nModelb\\nFailure \\ndistri-\\nbution\\nFailure \\nrate \\n(FIT)\\nAmount \\nof Safe \\nFaults\\nSafety \\nmecha-\\nnism(s) \\nprevent-\\ning the \\nviola tion \\nof the \\nsafety \\nrequire-\\nment\\nFailure \\nmode cov-\\nerage with \\nrespect to \\nviolation \\nof safety \\nrequire-\\nment\\nResidual \\nor Single \\nPoint Fault \\nfailure \\nrate/FIT\\nSafety \\nmecha-\\nnism(s) \\nto \\npre vent \\nlatent \\nfaults\\nFailure \\nmode cov-\\nerage with \\nrespect to  \\nlatent \\nfailures\\nLatent Mul-\\ntiple Point \\nFault \\nfailure \\nrate/FIT\\nLow drop \\nregulator\\nRegula-\\ntor core\\nSR\\nOutput voltage higher \\nthan a predefined high \\nthreshold of the pre-\\nscribed range (i.e. Over \\nvoltage \\xe2\\x80\\x94 OV)\\nRegulated voltage \\nhigher than VA_OV\\nP\\n14 %\\n1,49E-03\\n0 %\\nSM2\\n99,9 %\\n1,49E-06\\nSM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOutput voltage lower \\nthan a predefined \\nlow threshold of the \\nprescribed range (i.e. \\nUnder voltage \\xe2\\x80\\x94 UV)\\nRegulated voltage \\nlower than VA_UV\\nP\\n14 %\\n1,49E-03\\n0 %\\nSM1\\n99,9 %\\n1,49E-06\\nSM1\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOutput voltage affect-\\ned by spikes\\nRegulated voltage out \\nof the expected range \\n(VA_UV-VA_OV)\\nP\\n14 %\\n1,49E-03\\n0 %\\nSM1 SM2\\n99,9 %\\n1,49E-06\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOutput voltage \\noscillation within the \\nprescribed range\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n14 %\\n1,49E-03\\n0 %\\nSM3\\n97,0 %\\n4,46E-05\\nSM3\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOutput voltage fast \\noscillation outside the \\nprescribed range but \\nwith average value \\nwithin the prescribed \\nrange\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n14 %\\n1,49E-03\\n0 %\\nSM1 SM2\\n99,9 %\\n1,49E-06\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOutput voltage drift \\nwithin the prescribed \\nrange\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n14 %\\n1,49E-03\\n0 %\\nSM3\\n97,0 %\\n4,46E-05\\nSM3\\n100 %\\n0,00E+00\\n \\n \\nSR\\nQuiescent current (i.e. \\ncurrent drawn by the \\nregulator in order to \\ncontrol its internal \\ncircuitry for proper \\noperation) exceeding \\nthe maximum value\\nRegulated voltage \\npotentially with low \\naccuracy depending \\non the actual quies-\\ncent current\\nP\\n14 %\\n1,49E-03\\n50 %\\nSM3\\n97,0 %\\n2,23E-05\\nSM3\\n100 %\\n0,00E+00\\n \\nBandgap \\n1\\nSR\\nOutput is stuck (high \\nor low)\\nRegulated voltage out \\nof the expected range \\n(VA_UV-VA_OV)\\nP\\n20 %\\n6,00E-04\\n0 %\\nSM1 SM2\\n99,9 %\\n6,00E-07\\nSM1 SM2\\n100 %\\n0,00E+00\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n163\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nPart\\nSubpart\\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent or \\nNot \\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent\\nFailure Mode\\nPotential Effect of \\nFailure Mode in  \\nAbsence of Safety \\nMechanism (SM) on \\nIC levela\\nFault \\nModelb\\nFailure \\ndistri-\\nbution\\nFailure \\nrate \\n(FIT)\\nAmount \\nof Safe \\nFaults\\nSafety \\nmecha-\\nnism(s) \\nprevent-\\ning the \\nviola tion \\nof the \\nsafety \\nrequire-\\nment\\nFailure \\nmode cov-\\nerage with \\nrespect to \\nviolation \\nof safety \\nrequire-\\nment\\nResidual \\nor Single \\nPoint Fault \\nfailure \\nrate/FIT\\nSafety \\nmecha-\\nnism(s) \\nto \\npre vent \\nlatent \\nfaults\\nFailure \\nmode cov-\\nerage with \\nrespect to  \\nlatent \\nfailures\\nLatent Mul-\\ntiple Point \\nFault \\nfailure \\nrate/FIT\\n \\n \\nSR\\nOutput is floating (e.g. \\nopen circuit)\\nRegulated voltage out \\nof the expected range \\n(VA_UV-VA_OV)\\nP\\n20 %\\n6,00E-04\\n0 %\\nSM1 SM2\\n99,9 %\\n6,00E-07\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOutput voltage \\noscillation within the \\nexpected range\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n20 %\\n6,00E-04\\n0 %\\nSM3\\n97,0 %\\n1,80E-05\\nSM3\\n100 %\\n0,00E+00\\n \\n \\nSR\\nIncorrect output volt-\\nage value (i.e. outside \\nthe expected range)\\nRegulated voltage out \\nof the expected range \\n(VA_UV-VA_OV)\\nP\\n20 %\\n6,00E-04\\n0 %\\nSM1 SM2\\n99,9 %\\n6,00E-07\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOutput voltage \\naccuracy too low, \\nincluding drift\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n20 %\\n6,00E-04\\n50 %\\nSM3\\n97,0 %\\n9,00E-06\\nSM3\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOutput voltage affect-\\ned by spikes\\nNot applicable due \\nto circuit implemen-\\ntation\\nP\\n0 %\\n0,00E+00\\n0 %\\n0,00E+00\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\nBias \\ncurrent \\ngenerator\\nSR\\nOne or more outputs \\nare stuck (high or low)\\nRegulated voltage out \\nof the expected range \\n(VA_UV-VA_OV)\\nP\\n10 %\\n2,00E-05\\n0 %\\nSM1 SM2\\n99,9 %\\n2,00E-08\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOne or more outputs \\nare floating (e.g. open \\ncircuit)\\nRegulated voltage out \\nof the expected range \\n(VA_UV-VA_OV)\\nP\\n10 %\\n2,00E-05\\n0 %\\nSM1 SM2\\n99,9 %\\n2,00E-08\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nIncorrect reference \\ncurrent (i.e. outside \\nthe expected range)\\nRegulated voltage out \\nof the expected range \\n(VA_UV-VA_OV)\\nP\\n10 %\\n2,00E-05\\n0 %\\nSM1 SM2\\n99,9 %\\n2,00E-08\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nReference current \\naccuracy too low , \\nincluding drift\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n10 %\\n2,00E-05\\n0 %\\nSM3\\n97,0 %\\n6,00E-07\\nSM3\\n100 %\\n0,00E+00\\n \\n \\nSR\\nReference current \\naffected by spikes\\nRegulated voltage \\nwith low accuracy for \\na limited time period \\nif the spike is not \\nfiltered out; No effect \\notherwise\\nP\\n10 %\\n2,00E-05\\n50 %\\n1,00E-05\\nSM1 SM2\\n100 %\\n0,00E+00\\nTable D.5 (continued)\\n164 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nPart\\nSubpart\\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent or \\nNot \\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent\\nFailure Mode\\nPotential Effect of \\nFailure Mode in  \\nAbsence of Safety \\nMechanism (SM) on \\nIC levela\\nFault \\nModelb\\nFailure \\ndistri-\\nbution\\nFailure \\nrate \\n(FIT)\\nAmount \\nof Safe \\nFaults\\nSafety \\nmecha-\\nnism(s) \\nprevent-\\ning the \\nviola tion \\nof the \\nsafety \\nrequire-\\nment\\nFailure \\nmode cov-\\nerage with \\nrespect to \\nviolation \\nof safety \\nrequire-\\nment\\nResidual \\nor Single \\nPoint Fault \\nfailure \\nrate/FIT\\nSafety \\nmecha-\\nnism(s) \\nto \\npre vent \\nlatent \\nfaults\\nFailure \\nmode cov-\\nerage with \\nrespect to  \\nlatent \\nfailures\\nLatent Mul-\\ntiple Point \\nFault \\nfailure \\nrate/FIT\\n \\n \\nSR\\nReference current \\noscillation within the \\nexpected range\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n10 %\\n2,00E-05\\n0 %\\nSM3\\n97,0 %\\n6,00E-07\\nSM3\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOne or more bias \\ncurrents outside the \\nexpected range while \\nreference current is \\ncorrect\\nRegulated voltage \\nwith low accuracy or \\nout of regulation\\nP\\n10 %\\n2,00E-05\\n0 %\\nSM3\\n97,0 %\\n6,00E-07\\nSM3\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOne or more bias cur-\\nrents accuracy too low \\n, including drift\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n10 %\\n2,00E-05\\n0 %\\nSM3\\n97,0 %\\n6,00E-07\\nSM3\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOne or more bias \\ncurrents affected by \\nspikes\\nRegulated voltage \\nwith low accuracy for \\na limited time period \\nif the spike is not \\nfiltered out; No effect \\notherwise\\nP\\n10 %\\n2,00E-05\\n50 %\\n1,00E-05\\nSM1 SM2\\n100 %\\n0,00E+00\\n \\n \\nSR\\nOne or more bias cur-\\nrents oscillation within \\nthe expected range\\nRegulated voltage \\nwithin the expected \\nrange but with low \\naccuracy\\nP\\n10 %\\n2,00E-05\\n0 %\\nSM3\\n97,0 %\\n6,00E-07\\nSM3\\n100 %\\n0,00E+00\\nADC\\nADC\\nNSR\\nP\\n100 %\\n7,00E-03\\n0,0E+00\\n0,0E+00\\nTable D.5 (continued)\\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n165\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\n \\nPart\\nSubpart\\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent or \\nNot \\nSafe-\\nty-re-\\nlated \\nCompo-\\nnent\\nFailure Mode\\nPotential Effect of \\nFailure Mode in  \\nAbsence of Safety \\nMechanism (SM) on \\nIC levela\\nFault \\nModelb\\nFailure \\ndistri-\\nbution\\nFailure \\nrate \\n(FIT)\\nAmount \\nof Safe \\nFaults\\nSafety \\nmecha-\\nnism(s) \\nprevent-\\ning the \\nviola tion \\nof the \\nsafety \\nrequire-\\nment\\nFailure \\nmode cov-\\nerage with \\nrespect to \\nviolation \\nof safety \\nrequire-\\nment\\nResidual \\nor Single \\nPoint Fault \\nfailure \\nrate/FIT\\nSafety \\nmecha-\\nnism(s) \\nto \\npre vent \\nlatent \\nfaults\\nFailure \\nmode cov-\\nerage with \\nrespect to  \\nlatent \\nfailures\\nLatent Mul-\\ntiple Point \\nFault \\nfailure \\nrate/FIT\\n\\xce\\xa3\\n0,000 17\\n0,0E+00\\nTotal failure rate\\n0,020 6\\nTotal Safety-related\\n0,013 6\\nTotal Not Safety-related\\n0,007 0\\nSingle-Point Fault Metric\\n98,8 %\\nLatent-Fault Metric\\n100 %\\na   Depending on complexity it can be beneficial to have a dedicated entry in the FMEA giving more details about the potential root causes and the end effect of each failure mode.\\nb   Fault model can be permanent fault (P) or transient fault (T); the example is limited to permanent faults.\\nTable D.5 (continued)\\n166 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nD.1.1 Example of computation of failure rate for analogue component\\nCalculation methods to derive the base failure rate for analogue and mixed signal components are \\ndescribed in 4.6.\\nThe base failure rate is allocated to the different elements composing the hardware component. \\nDifferent allocation methods can be applied depending on the type of elements considered.\\nThe base failure rate can be considered proportional to the area of the circuit.\\nEXAMPLE 1 \\nThe base failure rate is divided by the overall area of the component in order to obtain FIT/mm2 \\nfor each relevant fault model.\\nTable D.6 \\xe2\\x80\\x94 Base failure rate allocation based on area\\nFault model\\nFailure rate \\nvalue\\nUnit\\nPermanent faults\\n2,00E-02\\nFIT/mm2\\nTransient faults\\n2,00E-05\\nFIT/mm2\\nThe failure rate of each subpart of the analogue and mixed signal component shown in the previous \\nexample is computed by using the FIT/mm2 reported in Table D.6.\\nThe results of the computation, considering the block diagrams of the previous example, are reported \\nin Table D.7.\\nTable D.7 \\xe2\\x80\\x94 Failure rate for each part/subpart\\nPart\\nSubpart\\nBlock Area\\n(mm2)\\nFailure rate  \\nPermanent faults \\n(FIT)\\nFailure rate  \\nTransient faults (FIT)\\nLow Drop \\nRegulator\\nRegulator Core\\n0,52\\n0,0104\\n0,0000104\\nBandgap 1\\n0,15\\n0,0030\\n0,0000030\\nBias Current Gener-\\nator\\n0,01\\n0,0002\\n0,0000002\\nCurrent Limiter\\n0,075\\n0,0015\\n0,0000015\\nTOTAL\\n0,755\\n0,0151\\n0,0000151\\nVoltage \\nMonitor\\nCMP1\\n0,03\\n0,0006\\n0,0000006\\nCMP2\\n0,03\\n0,0006\\n0,0000006\\nPassive Network\\n0,08\\n0,0016\\n0,0000016\\nBandgap 2\\n0,15\\n0,0030\\n0,0000030\\nTOTAL\\n0,29\\n0,0058\\n0,0000058\\nADC\\nADC\\n0,85\\n0,0170\\n0,0000170\\nAnalogue \\nBIST\\nAnalogue BIST\\n0,35\\n0,0070\\n0,0000070\\nTOTAL\\n2,535\\n0,0507\\n0,000 0507\\nNOTE 1 \\nThe numbers reported here are only examples.\\nNOTE 2 \\nBlock area reported here includes internal routing. Routing at top level, if relevant, is included in a \\nseparate block.\\nAs an alternative to the area-based approach, as seen in 5.1.7.1, the failure rate and failure mode \\ndistribution can be estimated based on the number of equivalent transistors for each subpart or \\nelementary subpart. In the case of mixed signal or analogue components, distinction between active \\ndevices, passive devices and routing can be taken into account in the estimation of the number of \\nequivalent transistors. The selection of the method used can be based on the layout (or planned layout) \\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n167\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nof the circuit under analysis or on the analysis of how failure modes are shared between the hardware \\nelements.\\nNOTE 3 \\nFor a transient fault model, the base failure rate proportional to area is a simplified example because, \\nin reality, not each element in a mixed signal circuit has the same probability of failure.\\nEXAMPLE 2 \\nIn switched-capacitor architectures, the capacitors holding the signal are more sensitive with \\nrespect to transient faults than other portions of the circuit because they are used as memory elements.\\n \\n168 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nAnnex E \\n(informative) \\n \\nExamples of quantitative analysis for PLD component\\nE.1 Architecture of the example\\nFigure E.1 shows the system used in the following examples. The system is intended for a safety-\\nrelated application where two microcontrollers are used for redundancy and the final control output \\nis implemented using a PLD. The two microcontrollers send their values to the PLD via SPI (Serial \\nPeripheral Interface) and the PLD communicates via CAN (Controller Area Network) bus. For this \\nexample, it is assumed that a calculated output too high (i.e. greater than the value that would have \\nbeen determined by a non-faulted system plus a threshold) is a potential hazard but an output too low is \\nacceptable from a functional safety point-of-view. It is also assumed that the components receiving the \\nCAN message can detect the loss of CAN messages and take appropriate action such as defaulting the \\nreceive signal to its minimum value and that the receiving module can tolerate corrupt CAN messages \\n(i.e. values higher than intended) for X number of messages.\\nFigure E.1 \\xe2\\x80\\x94 Example of PLD usage \\xe2\\x80\\x94 output switch\\nNOTE \\nThe hardware component \\xe2\\x80\\x9cController\\xe2\\x80\\x9d is implemented using two microcontrollers and one PLD.\\nDerived safety requirements for hardware \\xe2\\x80\\x9cController\\xe2\\x80\\x9d:\\n\\xe2\\x80\\x95 \\nSafReq_hardware_Comp_Controller_001: \\xe2\\x80\\x9cThe output of a wrong value which is larger than the \\ncorrect value plus a threshold for X number of messages in-a-row shall be avoided\\xe2\\x80\\x9d; and\\n\\xe2\\x80\\x95 \\nSafReq_hardware_Comp_Controller_002: \\xe2\\x80\\x9cUndetected lack of CAN outputs for longer than y ms \\nshall be avoided\\xe2\\x80\\x9d.\\nThe hardware component \\xe2\\x80\\x9cController\\xe2\\x80\\x9d is implemented using two microcontrollers (\\xc2\\xb5Controller1 and \\n\\xc2\\xb5Controller2) and one PLD. Both \\xc2\\xb5Controller1 and \\xc2\\xb5Controller2 have the same input/output history and \\ntransmit their result to the PLD. Both outputs agree within the threshold when no fault has occurred. \\nThe PLD is responsible for taking the minimum of the two signals and communicating this output to the \\nrest of the system via CAN. SafReq_hardware_Comp_Controller_002 can be fulfilled by entities outside \\nof the controller (e.g. timeout supervision).\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n169\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nThe derived safety requirement for the PLD could be:\\n\\xe2\\x80\\x95 \\nSafReq_PLD_001: \\xe2\\x80\\x9cOutput of a value larger than the minimum of the two input values from \\n\\xc2\\xb5Controller1 and \\xc2\\xb5Controller2 shall be avoided\\xe2\\x80\\x9d (derived from SafReq_hardware_Comp_\\nController_001); and\\n\\xe2\\x80\\x95 \\nSafReq_PLD_002: \\xe2\\x80\\x9cUndetected corruption of the CAN output value from PLD which leads to an \\noutput too high shall be avoided\\xe2\\x80\\x9d (derived from SafReq_hardware_Comp_Controller_001).\\nThe following clause addresses, as an example, two different approaches for the PLD\\xe2\\x80\\x99s safety and \\ndependent failure analysis. The safety analysis and the dependent failure analysis concerning \\n\\xc2\\xb5Controller1 and \\xc2\\xb5Controller2 are out of scope of this document.\\nFailures of the PLD can be addressed by two approaches:\\n\\xe2\\x80\\x94 utilizing safety measures which are external to the PLD, or\\n\\xe2\\x80\\x94 utilizing safety measures which are internal to the PLD. The PLD includes diagnostic measures to \\ndetect faults of the PLD. Faults are communicated via the status signal to \\xc2\\xb5Controller1, which can \\ndisable the PLD based on the severity of the fault.\\nE.2 PLD external measures\\nThe following safety mechanisms are implemented by elements other than the PLD:\\n\\xe2\\x80\\x95 \\nSafMech_PLD_001: CAN Read back and comparison. The CAN output of the PLD is read back by \\n\\xc2\\xb5Controller1. \\xc2\\xb5Controller1 checks if the PLD has output a value equal or less than its output. If this \\ncheck fails, the \\xc2\\xb5Controller1 disables the PLD via the Disable signal; and\\n\\xe2\\x80\\x95 \\nSafMech_Network_001: The receivers implement a time-out monitoring.\\nAs a first step of the safety analysis the relevant failure modes can be identified. Since none of the safety \\nmechanisms are implemented within the PLD it is sufficient to describe the observable failure modes \\non its output level:\\n\\xe2\\x80\\x95 \\nFM_PLD_OP_01: no output;\\n\\xe2\\x80\\x95 \\nFM_PLD_OP_02: output of old message;\\n\\xe2\\x80\\x95 \\nFM_PLD_OP_03: corrupt output;\\n\\xe2\\x80\\x95 \\nFM_PLD_OP_04: does not output minimum value;\\n\\xe2\\x80\\x95 \\nFM_PLD_OP_05: always outputs \\xc2\\xb5Controller1 value;\\n\\xe2\\x80\\x95 \\nFM_PLD_OP_06: always outputs \\xc2\\xb5Controller2 value; and\\n\\xe2\\x80\\x95 \\nFM_PLD_OP_07: active \\xe2\\x80\\x9cDisable\\xe2\\x80\\x9d discrete signal does not prevent CAN transmission.\\nAs described in 5.3.3.1.3, to derive a probability distribution over the above-mentioned failure modes \\ntypically detailed knowledge of the PLD internal structure is necessary. If this information is not \\navailable and no argument can be given why one of the failure modes is more likely than the other, the \\napproach described in 5.3.3.1.3 a) can be adopted, as shown in Table E.1 below.\\n \\n170 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable E.1 \\xe2\\x80\\x94 Example of a PLD safety analysis in the case of PLD external measures\\nFailure mode\\nPermanent \\ndistribution\\nTransient \\ndistribution\\nPVSG?\\nMPF?\\nSafety mechanisms\\nFM_PLD_OP_01: no output\\n14,3 %\\n14,3 %\\n1\\n0\\nSafMech_Network_001\\nFM_PLD_OP_02: output of old \\nmessage\\n14,3 %\\n14,3 %\\n1\\n0\\nSafMech_PLD_001\\nFM_PLD_OP_03: corrupt output\\n14,3 %\\n14,3 %\\n1\\n0\\nSafMech_PLD_001\\nFM_PLD_OP_04: does not out-\\nput minimum value\\n14,3 %\\n14,3 %\\n0\\n1\\nSafMech_PLD_001\\nFM_PLD_OP_05: always out-\\nputs \\xc2\\xb5Controller1 value\\n14,3 %\\n14,3 %\\n0\\n1\\n \\nFM_PLD_OP_06: always out-\\nputs \\xc2\\xb5Controller2 value\\n14,3 %\\n14,3 %\\n0\\n1\\nSafMech_PLD_001\\nFM_PLD_OP_07: active \\xe2\\x80\\x9cDisa-\\nble\\xe2\\x80\\x9d discrete signal does not \\nprevent CAN transmission\\n14,3 %\\n14,3 %\\n0\\n1\\n \\nNOTE   PVSG = potential to directly violate the safety goal; MPF = multiple-point failure\\nAs far as the dependent failure analysis (out of scope of this document) is concerned the correlation of \\nthe following elements could be of interest:\\n\\xe2\\x80\\x94 PLD & \\xc2\\xb5Controller1;\\n\\xe2\\x80\\x94 PLD & \\xc2\\xb5Controller2;\\n\\xe2\\x80\\x94 \\xc2\\xb5Controller1 & \\xc2\\xb5Controller2.\\nE.3 PLD internal measures\\nThe rest of the example considers utilizing safety measures which are internal to the PLD. The internal \\narchitecture of the PLD is presented in Figure E.2. The data sent from the \\xc2\\xb5Controller is buffered before \\nit can be transferred via the CAN bus. The buffers are implemented as user memory, whereas the state \\nmachine controlling the buffer operation and the multiplexer are implemented by logic blocks and the \\nCAN module is a fixed function IP. The functionality of the logic blocks and the routing between the \\nblocks and memory are controlled by the configuration technology. For simplicity, the switch control \\nlogic, which determines whether data from Buffer 1 or Buffer 2 is sent, is not covered in this example.\\nThe design is also susceptible to intermittent and permanent hardware failures. Any chip infrastructure \\nsuch as clock or power could be a source of a common mode failure. These failures can be addressed by \\nredundancy with detection and reporting for single mode failures. Other examples include incorrect \\nload of code at initialization and bit flip in memory. These could be detected using checksums and \\nparity; however, some of these failures could result in a possible violation of the safety goal and would be \\nan unacceptable risk. Error-detection-correction codes (ECC) are a superior technique as they correct \\nerrors and could report after correction that a potential problem exists in the chip. Single failures in the \\nI/O of the chip only impact one output and represent less risk.\\nNOTE 1 \\nDepending on the functionality of the implemented circuitry it is necessary to perform further \\nactivities besides correcting the fault to restore the functionality of the design (e.g. a fault in the configuration \\ntechnology leads to a non-recoverable state of a state-machine, even though the fault in the configuration \\ntechnology was corrected).\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n171\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nFigure E.2 \\xe2\\x80\\x94 PLD architecture\\nIf the fault has the potential to violate the safety goal without being detected by the internal safety \\nmechanisms it is detected by \\xc2\\xb5Controller1 through loss of the CAN signal or a mismatch between its \\nSPI output and the CAN read. This is acceptable if \\xc2\\xb5Controller1 can disable the PLD via the \\xe2\\x80\\x9cDisable\\xe2\\x80\\x9d \\nsignal. A dependent failures analysis is done to ensure that the risk of the PLD violating a safety goal in \\ncombination with the failure of the deactivation via the disable signal is sufficiently low.\\nEXAMPLE \\nA potential hazard could occur if the switch is unable to respond to the disable command from \\n\\xc2\\xb5Controller1. This would be a multiple-point fault situation as if both \\xc2\\xb5Controller1 and 2 were good, the PLD \\noutput would still represent safe values. There would not be a potential risk until one of the \\xc2\\xb5Controllers fails \\nand the PLD responds incorrectly. To detect this multiple-point fault, a periodic test of the disable logic can be \\nimplemented. Since this would be performed at system or element level, the specific details are out of scope of \\nthis document and are not described further.\\nNOTE 2 \\nIn this simple example, the external measures can replace the internal safety mechanisms. In general, \\ncases exist in which the internal measures are necessary to reach target diagnostic coverage and therefore the \\ndetailed analysis of internal safety mechanisms described in this sub-clause is applied.\\nRandom hardware faults can be analysed by applying an inductive fault analysis (e.g. FMEA) on the \\ndesign. Faults of the user design, but also faults of the PLD technology are taken into account and \\nconsider permanent and transient faults. The qualitative analysis of the design is followed up with a \\nquantitative analysis, similar to the one described in Annex C of this document.\\nAs described in 5.3.3.1, inputs to the quantitative analysis can be made available by the PLD \\nmanufacturer with regard to the failure rates of the elementary subparts of the PLD and the failure \\nmode distribution.\\nNOTE 3 \\nIn this case of PLD internal measures, for failure mode distribution determination the approaches as \\ndescribed in 5.3.3.1.3 b) or c) are preferable.\\nTable E.2 provides a framework for a quantitative analysis of the above design, which can be augmented \\nwith information similar to Figure C.1.\\nNOTE 4 \\nAs discussed in 5.1.7, the necessary level of detail can depend on the stage of the analysis and on the \\nsafety mechanisms used.\\n \\n172 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nTable E.2 \\xe2\\x80\\x94 Example framework for quantitative analysis of scenario 2\\nPart\\nSubpart\\nSafety-related (SR) or not safe-\\nty-related (NSR) element?\\nFailure modes\\nI/O interface\\nI/O buffer\\nSR\\nPermanent\\nConfiguration technology\\nSR\\nPermanent\\nTransient\\nRouting resources\\nSR\\nPermanent\\nTransient\\nBuffer 1\\nRAM data bits\\nSR\\nPermanent\\nTransient\\nAddress decoder\\nSR\\nPermanent\\nTransient\\nTest/redundancy\\nSR\\nPermanent\\nTransient\\nConfiguration technology\\nSR\\nPermanent\\nTransient\\nRouting resources\\nSR\\nPermanent\\nTransient\\nBuffer 2\\nRAM data bits\\nSR\\nPermanent\\nTransient\\nAddress decoder\\nSR\\nPermanent\\nTransient\\nTest/redundancy\\nSR\\nPermanent\\nTransient\\nConfiguration technology\\nSR\\nPermanent\\nTransient\\nRouting resources\\nSR\\nPermanent\\nTransient\\nState Machine 1\\nLogic blocks\\nSR\\nPermanent\\nTransient\\nConfiguration technology\\nSR\\nPermanent\\nTransient\\nRouting resources\\nSR\\nPermanent\\nTransient\\nState Machine 2\\nLogic blocks\\nSR\\nPermanent\\nTransient\\nConfiguration technology\\nSR\\nPermanent\\nTransient\\nRouting resources\\nSR\\nPermanent\\nTransient\\nNOTE 1   Depending on the role of each PLD part in the system, a more detailed analysis can be necessary.\\nNOTE 2   The example does not list the quantitative numbers for simplicity.\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n173\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nPart\\nSubpart\\nSafety-related (SR) or not safe-\\nty-related (NSR) element?\\nFailure modes\\nMultiplexer\\nLogic blocks\\nSR\\nPermanent\\nTransient\\nConfiguration technology\\nSR\\nPermanent\\nTransient\\nRouting resources\\nSR\\nPermanent\\nTransient\\nCAN\\nLogic\\nSR\\nPermanent\\nTransient\\nRAM data bits\\nSR\\nPermanent\\nTransient\\nAddress decoder\\nSR\\nPermanent\\nTransient\\nNOTE 1   Depending on the role of each PLD part in the system, a more detailed analysis can be necessary.\\nNOTE 2   The example does not list the quantitative numbers for simplicity.\\nThe analysis also includes PLD related external components such as power supplies, clocks and reset \\ncircuitry. Further, if the configuration of the PLD is loaded from an external device, it is analysed if the \\nloading of the configuration into the PLD is considered safety-related or if the process of loading the \\nconfiguration can lead to a failure of the item.\\nIn particular, if the PLD is loaded from \\xc2\\xb5Controller1, common cause failures in \\xc2\\xb5Controller1 that affect \\nthe loading mechanism and \\xc2\\xb5Controller1 functionality is considered. A dependent failure analysis is \\nperformed if separate channels or diagnostic measures are implemented in the PLD. An example of such \\nan analysis can be found in Annex B of this document. In this example independence of the individual \\nsubparts is not considered as the detection of a fault of the PLD is performed by reading back the output \\nof the CAN module with a \\xc2\\xb5Controller.\\n \\nTable E.2 (continued)\\n174 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b' \\nISO 26262-11:2018(E)\\nBibliography\\n[1] \\nAskari S., Nourani M. Design methodology for mitigating transient errors in analogue and mixed-\\nsignal circuits. Circuits, Devices & Systems [online]. IET. November 2012, 6(6), 447-456 [viewed \\n2017-10-10]. Available at: 10.1049/iet-cds.2012.0053\\n[2] \\nBaumann R.C. Radiation-Induced Soft Errors in Advanced Semiconductor Technologies. IEEE \\nTransactions\\xc2\\xa0 on\\xc2\\xa0 device\\xc2\\xa0 and\\xc2\\xa0 materials\\xc2\\xa0 reliability [online]. IEEE. December 2005, 5(3), 305-316 \\n[viewed 2017-10-10]. Available at: 10.1109/TDMR.2005.853449\\n[3] \\nBaruah S.K., Goossens J. Rate-monotonic scheduling on uniform multiprocessors. Proceedings \\nof the 23rd International Conference on Distributed Computing Systems [online]. IEEE. May 2003, \\n360-366 [viewed 2017-10-10]. Available at: 10.1109/ICDCS.2003.1203485\\n[4] \\nB\\xc3\\xb6rcs\\xc3\\xb6k J., Schaefer S., Ugljesa E. Estimation and Evaluation of Common Cause Failures. \\nSecond International Conference on Systems [online]. IEEE. April 2007, 41 [viewed 2017-10-10]. \\nAvailable at: 10.1109/ICONS.2007.25\\n[5] \\nBressoud T.C., Schneider F.B. Hypervisor-based fault tolerance. Proceedings\\xc2\\xa0of\\xc2\\xa0the\\xc2\\xa0fifteenth\\xc2\\xa0ACM\\xc2\\xa0\\nsymposium on Operating systems principles [online]. ACM. December 1995, 1\\xe2\\x80\\x9311 [viewed 2017-10-\\n10]. Available at: 10.1145/224057.224058\\n[6] \\nChattopadhyay S., Kee C.L., Roychoudhury A., Kelter T., Marwedel P., Falk H. A Unified \\nWCET Analysis Framework for Multi-core Platforms. IEEE\\xc2\\xa0 18th\\xc2\\xa0 Real-Time\\xc2\\xa0 and\\xc2\\xa0 Embedded\\xc2\\xa0\\nTechnology\\xc2\\xa0and\\xc2\\xa0Applications\\xc2\\xa0Symposium [online]. IEEE. April 2012, 99-108 [viewed 2017-10-10]. \\nAvailable at: 10.1109/RTAS.2012.26\\n[7] \\nClegg J.R. Arguing the safety of FPGAs within safety critical systems. Incorporating the SaRS \\nAnnual\\xc2\\xa0Conference,\\xc2\\xa04th\\xc2\\xa0IET\\xc2\\xa0International\\xc2\\xa0Conference\\xc2\\xa0on\\xc2\\xa0Systems\\xc2\\xa0Safety [online]. IET. October 2009, \\n1-6 [viewed 2017-10-10]. Available at: 10.1049/cp.2009.1569\\n[8] \\nConmy P.M., Pygott C., Bate I. VHDL guidance for safe and certifiable FPGA design. 5th\\xc2\\xa0IET\\xc2\\xa0\\nInternational Conference on System Safety [online]. IET. October 2010, 1-6 [viewed 2017-10-10]. \\nAvailable at: 10.1049/cp.2010.0832\\n[9] \\nFIDES Guide 2009 Edition A September 2010, Reliability\\xc2\\xa0Methodology\\xc2\\xa0for\\xc2\\xa0Electronic\\xc2\\xa0Systems\\n[10] \\nFleming, P.R., Olson, B.D., Holman, W.T., Bhuva, B.L., Massengill, L.W. Design Technique for \\nMitigation of Soft Errors in Differential Switched-Capacitor Circuits. IEEE\\xc2\\xa0 Transactions\\xc2\\xa0 on\\xc2\\xa0\\nCircuits and Systems II: Express Briefs [online]. IEEE. May 2008, 55(9), 838-842 [viewed 2017-10-\\n10]. Available at: 10.1109/TCSII.2008.923437\\n[11] \\nFranklin M. Incorporating Fault Tolerance in Superscalar Processors. Proceedings of \\nInternational Conference on High Performance Computing [online]. IEEE. December 1996 [viewed \\n2017-10-10]. Available at: 10.1109/HIPC.1996.565839\\n[12] \\nHayek A., Borcsok J. SRAM-based FPGA design techniques for safety-related systems conforming \\nto IEC 61508 a survey and analysis. 2nd International Conference on Advances in Computational \\nTools\\xc2\\xa0for\\xc2\\xa0Engineering\\xc2\\xa0Applications\\xc2\\xa0(ACTEA) [online]. IEEE. December 2012, 319-324 [viewed 2017-\\n10-10]. Available at: 10.1109/ICTEA.2012.6462892\\n[13] \\nHeiser G. The role of virtualization in embedded systems. Proceedings of the 1st workshop on \\nIsolation and integration in embedded systems [online]. ACM. April 2008, 11-16 [viewed 2017-10-\\n10]. Available at: 10.1145/1435458.1435461\\n[14] \\nIEC 61508-2:2010, Functional safety of electrical/electronic/programmable electronic safety-\\nrelated systems\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n175\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b\" \\nISO 26262-11:2018(E)\\n[15] \\nIEC 61709:2017, Electrical components \\xe2\\x80\\x94 Reliability \\xe2\\x80\\x94 Reference conditions for failure rates and \\nstress models for conversion\\n[16] \\nJEDEC JEP122H, Failure\\xc2\\xa0Mechanisms\\xc2\\xa0and\\xc2\\xa0Models\\xc2\\xa0for\\xc2\\xa0Semiconductor\\xc2\\xa0Devices\\n[17] \\nJEDEC JESD89A, Measurement\\xc2\\xa0and\\xc2\\xa0Reporting\\xc2\\xa0of\\xc2\\xa0Alpha\\xc2\\xa0Particle\\xc2\\xa0and\\xc2\\xa0Terrestrial\\xc2\\xa0Cosmic\\xc2\\xa0Ray-Induced\\xc2\\xa0\\nSoft Errors in Semiconductor Devices\\n[18] \\nKeckler, S.W., Olukotun, K., Hofstee, H.P. Multicore Processors and Systems. 2009. Springer\\n[19] \\nKervarreca, G., et al. A universal field failure based reliability prediction model for SMD \\nIntegrated Circuits. Microelectronics\\xc2\\xa0 Reliability [online]. Elsevier. June-July 1999, 765-771 \\n[viewed 2017-10-10]. Available at: https: //doi .org/10 .1016/S0026 -2714(99)00099 -2\\n[20] \\nLazzari C. ET AL. Phase-Locked Loop Automatic Layout Generation and Transient Fault \\nInjection Analysis: A Case Study. 12th\\xc2\\xa0IEEE\\xc2\\xa0International\\xc2\\xa0On-Line\\xc2\\xa0Testing\\xc2\\xa0workshop [online]. IEEE. \\nJuly 2006, 117-127 [viewed 2017-10-10]. Available at: 10.1109/IOLTS.2006.48\\n[21] \\nBenso A., Bosio A., Di Carlo S., Mariani R. A Functional Verification based Fault Injection \\nEnvironment. 22nd\\xc2\\xa0IEEE\\xc2\\xa0International\\xc2\\xa0Symposium\\xc2\\xa0on\\xc2\\xa0Defect\\xc2\\xa0and\\xc2\\xa0Fault-Tolerance\\xc2\\xa0in\\xc2\\xa0VLSI\\xc2\\xa0Systems \\n[online]. IEEE. September 2007 [viewed 2017-10-10]. Available at: 10.1109/DFT.2007.31\\n[22] \\nMariani R. Soft\\xc2\\xa0Errors\\xc2\\xa0on\\xc2\\xa0Digital\\xc2\\xa0Components.\\xc2\\xa0Fault\\xc2\\xa0Injection\\xc2\\xa0Techniques\\xc2\\xa0and\\xc2\\xa0Tools\\xc2\\xa0for\\xc2\\xa0Embedded\\xc2\\xa0\\nSystems Reliability Evaluation [online]. Springer. 2003 [viewed 2017-10-10]. Available at: https: \\n//doi .org/10  .1007/0  -306 -48711  -X  _3\\n[23] \\nMIL-HDBK-217, Military\\xc2\\xa0Handbook\\xc2\\xa0\\xe2\\x80\\x94\\xc2\\xa0Reliability\\xc2\\xa0Prediction\\xc2\\xa0of\\xc2\\xa0Electronic\\xc2\\xa0Equipment\\n[24] \\nMitra, S., Saxena, N.R., Mccluskey, E.J. Common-mode failures in redundant VLSI systems: a \\nsurvey. IEEE\\xc2\\xa0Transactions\\xc2\\xa0on\\xc2\\xa0Reliability [online]. IEEE. September 2000, 49(3), 285-295 [viewed \\n2017-10-10]. Available at: 10.1109/24.914545\\n[25] \\nMukherjee S.S. ET AL. A systematic methodology to compute the architectural vulnerability \\nfactors for a high-performance microprocessor in microarchitecture. Proceedings. 36th Annual \\nIEEE/ACM\\xc2\\xa0International\\xc2\\xa0Symposium\\xc2\\xa0on\\xc2\\xa0Microarchitecture [online]. IEEE. December 2003, 29-40 \\n[viewed 2017-10-10]. Available at: 10.1109/MICRO.2003.1253181\\n[26] \\nNiimi Y. ET AL. Virtualization Technology and Using Virtual CPU in the Context of ISO 26262: The \\nE-Gas Case Study. SAE\\xc2\\xa0Technical\\xc2\\xa0Paper [online]. SAE. April 2013 [viewed 2017-10-10]. Available \\nat: https: //doi .org/10 .4271/2013 -01 -0196\\n[27] \\nPaolieri M., Mariani R. Towards functional-safe timing-dependable real-time architectures. \\nIEEE\\xc2\\xa0 17th\\xc2\\xa0 International\\xc2\\xa0 On-Line\\xc2\\xa0 Testing\\xc2\\xa0 Symposium\\xc2\\xa0 (IOLTS) [online]. IEEE. July 2011, 31-36 \\n[viewed 2017-10-10]. Available at: 10.1109/IOLTS.2011.5993807\\n[28] \\nSingh M. ET AL. Transient Fault Sensitivity Analysis of Analog-to-Digital Converters (ADCs). \\nProceedings of the IEEE Workshop on VLSI (WVLSI '01) [online]. IEEE. April 2001 [viewed 2017-10-\\n10]. Available at: 10.1109/IWV.2001.923153\\n[29] \\nWhite M., Bernstein J.B. Microelectronics Reliability: Physics-of-Failure Based Modeling and \\nLifetime Evaluation. JPL Publication [online]. February 2008 [viewed 2017-10-10]. Available \\nat: \\nhttp: //www .acceleratedreliabilitysolutions .com/images/ _NASA _Physics _of _Failure _for \\n_Microelectronics .pdf\\n[30] \\nArlat J., et al. Fault Injection and Dependability Evaluation of Fault-Tolerant Systems. IEEE \\nTransactions\\xc2\\xa0on\\xc2\\xa0Computers [online]. IEEE. August 1993, 42(8), 913 [viewed 2017-10-10]. Available \\nat: 10.1109/12.238482\\n[31] \\nBenso A. and Prinetto P. Fault\\xc2\\xa0Injection\\xc2\\xa0Techniques\\xc2\\xa0and\\xc2\\xa0Tools\\xc2\\xa0for\\xc2\\xa0Embedded\\xc2\\xa0Systems\\xc2\\xa0Reliability\\xc2\\xa0\\nEvaluation. Springer. 2003 [viewed 2017-10-10]. Available at: https: //doi .org/10 .1007/0 -306 \\n-48711 -X _3\\n \\n176 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n\"\n",
      "b' \\nISO 26262-11:2018(E)\\n[32] \\nWei Jiesheng, et al. Quantifying the accuracy of high-level fault injection techniques for hardware \\nfaults. Dependable Systems and Networks (DSN), 2014 44th Annual IEEE/IFIP International \\nConference [online]. IEEE. June 2014 [viewed 2017-10-10]. Available at: 10.1109/DSN.2014.2\\n[33] \\nKejun Wu, Pahlevanzadeh H., Peng Liu, Qiaoyan Yu. A new fault injection method for evaluation \\nof combining SEU and SET effects on circuit reliability. Circuits and Systems (ISCAS), 2014 IEEE \\nInternational Symposium on [online]. IEEE. June 2014, 602,605 [viewed 2017-10-10]. Available at: \\n10.1109/ISCAS.2014.6865207\\n[34] \\nVan De Goor A.J. Testing\\xc2\\xa0Semiconductor\\xc2\\xa0Memories,\\xc2\\xa0Theory\\xc2\\xa0and\\xc2\\xa0Practice,\\xc2\\xa02nd. ComTex Publishing\\n[35] \\nEnamul Amyeen M., et al. Evaluation\\xc2\\xa0of\\xc2\\xa0the\\xc2\\xa0Quality\\xc2\\xa0of\\xc2\\xa0N-Detect\\xc2\\xa0Scan\\xc2\\xa0ATPG\\xc2\\xa0Patterns\\xc2\\xa0on\\xc2\\xa0a\\xc2\\xa0Processor.\\xc2\\xa0\\nProceedings\\xc2\\xa0of\\xc2\\xa0the\\xc2\\xa0International\\xc2\\xa0Test\\xc2\\xa0Conference 2004, ITC\\'04 [online]. IEEE. October 2004, 669-\\n678 [viewed 2017-10-10]. Available at: 10.1109/TEST.2004.1387328\\n[36] \\nBenware B., et al. Impact of Multiple-Detect Test Patterns on Product Quality, Proc. of the \\nInternational\\xc2\\xa0Test\\xc2\\xa0Conference 2003,\\xc2\\xa0ITC\\'03 [online]. IEEE. October 2003, 1031-1040 [viewed 2017-\\n10-10]. Available at: 10.1109/TEST.2003.1271091\\n[37] \\nPatel J.H. Stuck-At Fault: A Fault Model for the Next Millennium? Proceedings of the International \\nTest\\xc2\\xa0Conference 1998,\\xc2\\xa0ITC\\'98 [online]. IEEE. August 1988, 1166 [viewed 2017-10-10]. Available at: \\n10.1109/TEST.1998.743358\\n[38] \\nSN 29500:2004, Siemens\\xc2\\xa0AG,\\xc2\\xa0\"Failure\\xc2\\xa0Rates\\xc2\\xa0of\\xc2\\xa0Components\\xc2\\xa0\\xe2\\x80\\x94\\xc2\\xa0Expected\\xc2\\xa0Values,\\xc2\\xa0General\"\\n[39] \\nPaschalis A., and Gizopoulos D. Effective Software-Based Self-Test Strategies for On-Line Periodic \\nTesting of Embedded Processors. IEEE\\xc2\\xa0 Transactions\\xc2\\xa0 on\\xc2\\xa0 Computer-Aided\\xc2\\xa0 Design\\xc2\\xa0 of\\xc2\\xa0 Integrated\\xc2\\xa0\\nCircuits and Systems [online]. IEEE. December 2004, 88-99[viewed 2017-10-10]. Available at: \\n10.1109/TCAD.2004.839486\\n[40] \\nIEC/TR 62380:2004, Reliability data handbook \\xe2\\x80\\x94 Universal model for reliability prediction of \\nelectronics components, PCBs and equipment\\n[41] \\nITRS 2009, The International Technology Roadmap For Semiconductors (ITRS), 2009 Edition\\n[42] \\nIEEE STD 2700-2014, IEEE\\xc2\\xa0Standard\\xc2\\xa0for\\xc2\\xa0Sensor\\xc2\\xa0Performance\\xc2\\xa0Parameter\\xc2\\xa0Definitions\\n[43] \\nWhite Richard M. A Sensor Classification Scheme. IEEE\\xc2\\xa0Transactions\\xc2\\xa0On\\xc2\\xa0Ultrasonics,\\xc2\\xa0Ferroelectrics,\\xc2\\xa0\\nAnd Frequency Control [online]. IEEE. March 1987, 34(2), 124-126 [viewed 2017-10-10]. Available \\nat: 10.1109/T-UFFC.1987.26922\\n[44] \\nGupta Vijay, R. Snow, M.C. Wu, A. Jain, J. Tsai. Recovery of Stiction-Failed MEMS Structures Using \\nLaser-Induced Stress Waves. Journal\\xc2\\xa0of\\xc2\\xa0Microelectromechanical\\xc2\\xa0Systems [online]. IEEE. August \\n2004, 13(4), 696-700 [viewed 2017-10-10]. Available at: 10.1109/JMEMS.2004.832185\\n[45] \\nWalraven Jeremy A. Failure Mechanisms in MEMS. IEEE\\xc2\\xa0ITC\\xc2\\xa0International\\xc2\\xa0Test\\xc2\\xa0Conference [online]. \\nIEEE. October 2003, 828-833 [viewed 2017-10-10]. Available at: 10.1109/TEST.2003.1270915\\n[46] \\nJ. Iannacci. Reliability of MEMS: A perspective on failure mechanisms, improvement solutions \\nand best practices at development level. Elsevier Displays [online]. Elsevier. April 2015, 37, 62-71 \\n[viewed 2017-10-10]. Available at: https: //doi .org/10 .1016/j .displa .2014 .08 .003\\n[47] \\nVonkyoung Kim, Chen T. Assessing SRAM test coverage for sub-micron CMOS technologies. VLSI \\nTest\\xc2\\xa0Symposium, 1997, 15th IEEE [online]. IEEE. May 1997, 24-30 [viewed 2017-10-10]. Available \\nat: 10.1109/VTEST.1997.599437\\n[48] \\nGinez O. ET AL. An overview of failure mechanisms in embedded flash memories. VLSI\\xc2\\xa0 Test\\xc2\\xa0\\nSymposium, 2006. Proceedings. 24th [online]. IEEE. April 2006 [viewed 2017-10-10]. Available at: \\n10.1109/VTS.2006.19\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n177\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b\" \\nISO 26262-11:2018(E)\\n[49] \\nDi Carlo S., Fabiano M. PIAZZA, ROBERTO; PRINETTO, P. Exploring modeling and testing \\nof NAND flash memories. Design\\xc2\\xa0 &\\xc2\\xa0 Test\\xc2\\xa0 Symposium\\xc2\\xa0 (EWDTS), 2010 East-West [online]. IEEE. \\nSeptember 2010, 47-50 [viewed 2017-10-10]. Available at: 10.1109/EWDTS.2010.5742059\\n[50] \\nAl-Ars, Z.; Hamdioui, S.; Van De Goor, A.J., Space of DRAM Fault Models and Corresponding \\nTesting. Design,\\xc2\\xa0Automation\\xc2\\xa0and\\xc2\\xa0Test\\xc2\\xa0in\\xc2\\xa0Europe, 2006.\\xc2\\xa0DATE\\xc2\\xa0'06. IEEE. March 2006, 1, 1-6 [viewed \\n2017-10-10]. Available at: 10.1109/DATE.2006.244080\\n[51] \\nIATF 16949:2016, Quality management system requirements for automotive production and \\nrelevant service parts organizations\\n[52] \\nDaniel J. Sorin, Mark D. Hill, David A. Wood. A Primer on\\xc2\\xa0Memory\\xc2\\xa0Consistency\\xc2\\xa0and\\xc2\\xa0Cache\\xc2\\xa0Coherence\\xc2\\xa0\\n(1st ed.). Morgan & Claypool Publishers\\n[53] \\nJEDEC JESD94, Application\\xc2\\xa0Specific\\xc2\\xa0Qualification\\xc2\\xa0Using\\xc2\\xa0Knowledge\\xc2\\xa0Based\\xc2\\xa0Test\\xc2\\xa0Methodolog.\\n[54] \\nG. Kervarrec, et al. A universal reliability prediction model for SMD integrated circuits based on \\nfield failures. European Symposium on Reliability of Electron Devices, Failure Physics and Analysis \\n[online]. Microelectronics Reliability Elsevier. July 1999, 39(6), 765-771 [viewed 2017-10-10]. \\nAvailable at: https: //doi .org/10  .1016/S0026 -2714(99)00099 -2\\n[55] \\nE-GAS. Standardized E-GAS Monitoring Concept for Gasoline and Diesel Engine Control Units. \\n[viewed 2017-10-10]. Available at: https: //www  .iav  .com/sites/default/files/attachments/seite//ak \\n-egas -v6 -0 -en -150922 .pdf\\n[56] \\nIEEE P1804, IEEE\\xc2\\xa0Draft\\xc2\\xa0Standard\\xc2\\xa0for\\xc2\\xa0Fault\\xc2\\xa0Accounting\\xc2\\xa0and\\xc2\\xa0Coverage\\xc2\\xa0Reporting\\xc2\\xa0to\\xc2\\xa0Digital\\xc2\\xa0Modules\\xc2\\xa0\\n[viewed 2017-10-10]\\n[57] \\nR. Leveugle, A. Calvez, P. Maistri and P. Vanhauwaert, Statistical fault injection: Quantified error \\nand confidence. 2009 Design,\\xc2\\xa0Automation\\xc2\\xa0&\\xc2\\xa0Test\\xc2\\xa0in\\xc2\\xa0Europe\\xc2\\xa0Conference\\xc2\\xa0&\\xc2\\xa0Exhibition [online]. IEEE. \\nApril 2009, 502-506 [viewed 2017-10-10]. Available at: 10.1109/DATE.2009.5090716\\n[58] \\nPhilip Mayfield. Understanding Binomial Confidence Intervals [viewed 2017-10-10]. Available at: \\nhttp: //www .sigmazone .com/binomial _confidence _interval .htm\\n[59] \\nSAE J1211: 201211, Handbook for Robustness Validation of Automotive Electrical/Electronic \\nModules, SAE\\n[60] \\nJEDEC JESD88E, Dictionary\\xc2\\xa0of\\xc2\\xa0Terms\\xc2\\xa0for\\xc2\\xa0Solid-State\\xc2\\xa0Technology\\xc2\\xa0\\xe2\\x80\\x94\\xc2\\xa06th\\xc2\\xa0Edition\\n[61] \\nISO 26262-10:2018, Road\\xc2\\xa0vehicles\\xc2\\xa0\\xe2\\x80\\x94\\xc2\\xa0Functional\\xc2\\xa0safety\\xc2\\xa0\\xe2\\x80\\x94\\xc2\\xa0Part\\xc2\\xa010:\\xc2\\xa0Guideline\\xc2\\xa0on\\xc2\\xa0ISO\\xc2\\xa026262\\n[62] \\nAEC, AEC-Q100:\\xc2\\xa0Failure\\xc2\\xa0Mechanism\\xc2\\xa0Based\\xc2\\xa0Stress\\xc2\\xa0Test\\xc2\\xa0Qualification\\xc2\\xa0For\\xc2\\xa0Integrated\\xc2\\xa0Circuits\\n[63] \\nISO 26262-2:2018, Road\\xc2\\xa0Vehicles\\xc2\\xa0\\xe2\\x80\\x94\\xc2\\xa0Functional\\xc2\\xa0Safety\\xc2\\xa0\\xe2\\x80\\x94\\xc2\\xa0Part\\xc2\\xa02:\\xc2\\xa0Management\\xc2\\xa0of\\xc2\\xa0functional\\xc2\\xa0safety\\n[64] \\nISO 26262-3:2018, Road vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94 Part 3: Concept phase\\n[65] \\nISO 26262-4:2018, Road vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94 Part 4: Product development at the \\nsystem level\\n[66] \\nISO 26262-5:2018, Road vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94 Part 5: Product development at the \\nhardware level\\n[67] \\nISO 26262-6:2018, Road vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94 Part 6: Product development at the \\nsoftware level\\n[68] \\nISO 26262-7:2018, Road vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94 Part 7: Production, operation, service and \\ndecommissioning\\n[69] \\nISO 26262-8:2018, Road vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94 Part 8: Supporting processes\\n \\n178 \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n\"\n",
      "b' \\nISO 26262-11:2018(E)\\n[70] \\nISO 26262-9:2018, Road vehicles \\xe2\\x80\\x94 Functional safety \\xe2\\x80\\x94 Part 9: Automotive Safety Integrity Level \\n(ASIL)-oriented and safety-oriented analyses\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved \\n179\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n",
      "b'Tm9ybWVuLURvd25sb2FkLUJldXRoLUxpc2EgRHLDg8KkeGxtYWllciBHbWJILUtkTnIuMjgwNDM3 LUlELlFUUURKRjRGVFNOT0NBUVY5MkUyRUs1RC4xLTIwMTktMDEtMjMgMTE6MDM6NDA= \\n \\nISO 26262-11:2018(E)\\n \\n\\xc2\\xa9 ISO 2018 \\xe2\\x80\\x93 All rights reserved\\nICS\\xe2\\x80\\x8243.040.10\\nPrice based on 179 pages\\nNormen-Download-Beuth-Lisa Dr\\xc3\\xa4xlmaier GmbH-KdNr.280437-ID.QTQDJF4FTSNOCAQV92E2EK5D.1-2019-01-23 11:03:40\\n'\n"
     ]
    }
   ],
   "source": [
    "import sys, fitz\n",
    "fname = sys.argv[1]  # get document filename\n",
    "doc = fitz.open(\"C:/Users/XJS09914403/Desktop/Files/ISO_26262-11_Dez.-2018.pdf\")  # open document\n",
    "out = open(fname + \".txt\", \"wb\")  # open text output\n",
    "for page in doc:  # iterate the document pages\n",
    "    text = page.get_text().encode(\"utf8\")  # get plain text (is in UTF-8)\n",
    "   \n",
    "    out.write(text)  # write text of page\n",
    "    out.write(bytes((12,)))  # write page delimiter (form feed 0x0C)\n",
    "     print(text)\n",
    "out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
